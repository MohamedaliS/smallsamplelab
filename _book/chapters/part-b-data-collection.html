<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Part B: Data Collection and Preparation – Quantitative Analysis with Small Samples</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/part-c-analysis-methods.html" rel="next">
<link href="../chapters/part-a-foundations.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-fc52e084097f5e82659c47ea4c4460c4.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/part-b-data-collection.html">Part B: Data Collection and Preparation</a></li><li class="breadcrumb-item"><a href="../chapters/part-b-data-collection.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Part B: Data Collection and Preparation</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Quantitative Analysis with Small Samples</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Part A: Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-a-foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Part A: Foundations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Part B: Data Collection and Preparation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-b-data-collection.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Part B: Data Collection and Preparation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Part C: Analysis Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-c-analysis-methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Part C: Analysis Methods</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Part D: Reporting and Interpretation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-d-reporting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Part D: Reporting and Interpretation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Part E: Worked Projects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-e-worked-projects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Part E: Worked Projects</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Part F: Technical Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-f-technical-appendices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Part F: Technical Appendices</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Part G: Guided Lab Practicals</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-g-lab-practicals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part G: Guided Lab Practicals</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Part H: Instructor’s Manual</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-h-instructors-manual.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Part H: Instructor’s Manual</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#chapter-9.-sampling-strategies-for-small-studies" id="toc-chapter-9.-sampling-strategies-for-small-studies" class="nav-link active" data-scroll-target="#chapter-9.-sampling-strategies-for-small-studies"><span class="header-section-number">2.1</span> Chapter 9. Sampling Strategies for Small Studies</a>
  <ul class="collapse">
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link" data-scroll-target="#learning-objectives"><span class="header-section-number">2.1.1</span> Learning Objectives</a></li>
  <li><a href="#the-tension-between-ideal-and-feasible-sample-sizes" id="toc-the-tension-between-ideal-and-feasible-sample-sizes" class="nav-link" data-scroll-target="#the-tension-between-ideal-and-feasible-sample-sizes"><span class="header-section-number">2.1.2</span> The Tension Between Ideal and Feasible Sample Sizes</a></li>
  <li><a href="#probability-sampling-with-small-samples" id="toc-probability-sampling-with-small-samples" class="nav-link" data-scroll-target="#probability-sampling-with-small-samples"><span class="header-section-number">2.1.3</span> Probability Sampling with Small Samples</a></li>
  <li><a href="#sequential-and-adaptive-sampling" id="toc-sequential-and-adaptive-sampling" class="nav-link" data-scroll-target="#sequential-and-adaptive-sampling"><span class="header-section-number">2.1.4</span> Sequential and Adaptive Sampling</a></li>
  <li><a href="#example-stratified-sampling-calculation" id="toc-example-stratified-sampling-calculation" class="nav-link" data-scroll-target="#example-stratified-sampling-calculation"><span class="header-section-number">2.1.5</span> Example: Stratified Sampling Calculation</a></li>
  <li><a href="#purposive-and-convenience-sampling" id="toc-purposive-and-convenience-sampling" class="nav-link" data-scroll-target="#purposive-and-convenience-sampling"><span class="header-section-number">2.1.6</span> Purposive and Convenience Sampling</a></li>
  <li><a href="#quota-sampling" id="toc-quota-sampling" class="nav-link" data-scroll-target="#quota-sampling"><span class="header-section-number">2.1.7</span> Quota Sampling</a></li>
  <li><a href="#power-and-precision-with-small-samples" id="toc-power-and-precision-with-small-samples" class="nav-link" data-scroll-target="#power-and-precision-with-small-samples"><span class="header-section-number">2.1.8</span> Power and Precision with Small Samples</a></li>
  <li><a href="#finite-population-correction" id="toc-finite-population-correction" class="nav-link" data-scroll-target="#finite-population-correction"><span class="header-section-number">2.1.9</span> Finite Population Correction</a></li>
  <li><a href="#example-power-calculation-for-a-small-study" id="toc-example-power-calculation-for-a-small-study" class="nav-link" data-scroll-target="#example-power-calculation-for-a-small-study"><span class="header-section-number">2.1.10</span> Example: Power Calculation for a Small Study</a></li>
  <li><a href="#sample-size-planning-workflow" id="toc-sample-size-planning-workflow" class="nav-link" data-scroll-target="#sample-size-planning-workflow"><span class="header-section-number">2.1.11</span> Sample Size Planning Workflow</a></li>
  <li><a href="#justifying-small-sample-sizes" id="toc-justifying-small-sample-sizes" class="nav-link" data-scroll-target="#justifying-small-sample-sizes"><span class="header-section-number">2.1.12</span> Justifying Small Sample Sizes</a></li>
  <li><a href="#sample-size-planning-flowchart" id="toc-sample-size-planning-flowchart" class="nav-link" data-scroll-target="#sample-size-planning-flowchart"><span class="header-section-number">2.1.13</span> Sample Size Planning Flowchart</a></li>
  <li><a href="#self-assessment-quiz" id="toc-self-assessment-quiz" class="nav-link" data-scroll-target="#self-assessment-quiz"><span class="header-section-number">2.1.14</span> Self-Assessment Quiz</a></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways"><span class="header-section-number">2.1.15</span> Key Takeaways</a></li>
  <li><a href="#smoke-test" id="toc-smoke-test" class="nav-link" data-scroll-target="#smoke-test"><span class="header-section-number">2.1.16</span> Smoke Test</a></li>
  </ul></li>
  <li><a href="#chapter-10.-measurement-quality-and-scale-development" id="toc-chapter-10.-measurement-quality-and-scale-development" class="nav-link" data-scroll-target="#chapter-10.-measurement-quality-and-scale-development"><span class="header-section-number">2.2</span> Chapter 10. Measurement Quality and Scale Development</a>
  <ul class="collapse">
  <li><a href="#learning-objectives-1" id="toc-learning-objectives-1" class="nav-link" data-scroll-target="#learning-objectives-1"><span class="header-section-number">2.2.1</span> Learning Objectives</a></li>
  <li><a href="#the-challenge-of-measurement-in-small-studies" id="toc-the-challenge-of-measurement-in-small-studies" class="nav-link" data-scroll-target="#the-challenge-of-measurement-in-small-studies"><span class="header-section-number">2.2.2</span> The Challenge of Measurement in Small Studies</a></li>
  <li><a href="#content-and-face-validity" id="toc-content-and-face-validity" class="nav-link" data-scroll-target="#content-and-face-validity"><span class="header-section-number">2.2.3</span> Content and Face Validity</a></li>
  <li><a href="#steps-for-scale-development-with-small-samples" id="toc-steps-for-scale-development-with-small-samples" class="nav-link" data-scroll-target="#steps-for-scale-development-with-small-samples"><span class="header-section-number">2.2.4</span> Steps for Scale Development with Small Samples</a></li>
  <li><a href="#example-item-analysis-for-a-pilot-scale" id="toc-example-item-analysis-for-a-pilot-scale" class="nav-link" data-scroll-target="#example-item-analysis-for-a-pilot-scale"><span class="header-section-number">2.2.5</span> Example: Item Analysis for a Pilot Scale</a></li>
  <li><a href="#identifying-problematic-items" id="toc-identifying-problematic-items" class="nav-link" data-scroll-target="#identifying-problematic-items"><span class="header-section-number">2.2.6</span> Identifying Problematic Items</a></li>
  <li><a href="#refining-the-scale" id="toc-refining-the-scale" class="nav-link" data-scroll-target="#refining-the-scale"><span class="header-section-number">2.2.7</span> Refining the Scale</a></li>
  <li><a href="#qualitative-feedback-and-cognitive-interviews" id="toc-qualitative-feedback-and-cognitive-interviews" class="nav-link" data-scroll-target="#qualitative-feedback-and-cognitive-interviews"><span class="header-section-number">2.2.8</span> Qualitative Feedback and Cognitive Interviews</a></li>
  <li><a href="#self-assessment-quiz-1" id="toc-self-assessment-quiz-1" class="nav-link" data-scroll-target="#self-assessment-quiz-1"><span class="header-section-number">2.2.9</span> Self-Assessment Quiz</a></li>
  <li><a href="#key-takeaways-1" id="toc-key-takeaways-1" class="nav-link" data-scroll-target="#key-takeaways-1"><span class="header-section-number">2.2.10</span> Key Takeaways</a></li>
  <li><a href="#smoke-test-1" id="toc-smoke-test-1" class="nav-link" data-scroll-target="#smoke-test-1"><span class="header-section-number">2.2.11</span> Smoke Test</a></li>
  </ul></li>
  <li><a href="#chapter-11.-data-screening-and-diagnostic-checks" id="toc-chapter-11.-data-screening-and-diagnostic-checks" class="nav-link" data-scroll-target="#chapter-11.-data-screening-and-diagnostic-checks"><span class="header-section-number">2.3</span> Chapter 11. Data Screening and Diagnostic Checks</a>
  <ul class="collapse">
  <li><a href="#learning-objectives-2" id="toc-learning-objectives-2" class="nav-link" data-scroll-target="#learning-objectives-2"><span class="header-section-number">2.3.1</span> Learning Objectives</a></li>
  <li><a href="#why-data-screening-matters-more-with-small-samples" id="toc-why-data-screening-matters-more-with-small-samples" class="nav-link" data-scroll-target="#why-data-screening-matters-more-with-small-samples"><span class="header-section-number">2.3.2</span> Why Data Screening Matters More with Small Samples</a></li>
  <li><a href="#detecting-outliers" id="toc-detecting-outliers" class="nav-link" data-scroll-target="#detecting-outliers"><span class="header-section-number">2.3.3</span> Detecting Outliers</a></li>
  <li><a href="#example-outlier-detection-with-boxplots-and-z-scores" id="toc-example-outlier-detection-with-boxplots-and-z-scores" class="nav-link" data-scroll-target="#example-outlier-detection-with-boxplots-and-z-scores"><span class="header-section-number">2.3.4</span> Example: Outlier Detection with Boxplots and Z-Scores</a></li>
  <li><a href="#checking-normality" id="toc-checking-normality" class="nav-link" data-scroll-target="#checking-normality"><span class="header-section-number">2.3.5</span> Checking Normality</a></li>
  <li><a href="#example-q-q-plot-for-normality-assessment" id="toc-example-q-q-plot-for-normality-assessment" class="nav-link" data-scroll-target="#example-q-q-plot-for-normality-assessment"><span class="header-section-number">2.3.6</span> Example: Q-Q Plot for Normality Assessment</a></li>
  <li><a href="#linearity-and-homoscedasticity-in-regression" id="toc-linearity-and-homoscedasticity-in-regression" class="nav-link" data-scroll-target="#linearity-and-homoscedasticity-in-regression"><span class="header-section-number">2.3.7</span> Linearity and Homoscedasticity in Regression</a></li>
  <li><a href="#example-regression-diagnostics" id="toc-example-regression-diagnostics" class="nav-link" data-scroll-target="#example-regression-diagnostics"><span class="header-section-number">2.3.8</span> Example: Regression Diagnostics</a></li>
  <li><a href="#identifying-data-entry-errors" id="toc-identifying-data-entry-errors" class="nav-link" data-scroll-target="#identifying-data-entry-errors"><span class="header-section-number">2.3.9</span> Identifying Data Entry Errors</a></li>
  <li><a href="#documenting-data-cleaning" id="toc-documenting-data-cleaning" class="nav-link" data-scroll-target="#documenting-data-cleaning"><span class="header-section-number">2.3.10</span> Documenting Data Cleaning</a></li>
  <li><a href="#self-assessment-quiz-2" id="toc-self-assessment-quiz-2" class="nav-link" data-scroll-target="#self-assessment-quiz-2"><span class="header-section-number">2.3.11</span> Self-Assessment Quiz</a></li>
  <li><a href="#key-takeaways-2" id="toc-key-takeaways-2" class="nav-link" data-scroll-target="#key-takeaways-2"><span class="header-section-number">2.3.12</span> Key Takeaways</a></li>
  <li><a href="#smoke-test-2" id="toc-smoke-test-2" class="nav-link" data-scroll-target="#smoke-test-2"><span class="header-section-number">2.3.13</span> Smoke Test</a></li>
  </ul></li>
  <li><a href="#chapter-12.-handling-missing-data-in-small-samples" id="toc-chapter-12.-handling-missing-data-in-small-samples" class="nav-link" data-scroll-target="#chapter-12.-handling-missing-data-in-small-samples"><span class="header-section-number">2.4</span> Chapter 12. Handling Missing Data in Small Samples</a>
  <ul class="collapse">
  <li><a href="#learning-objectives-3" id="toc-learning-objectives-3" class="nav-link" data-scroll-target="#learning-objectives-3"><span class="header-section-number">2.4.1</span> Learning Objectives</a></li>
  <li><a href="#the-challenge-of-missing-data-in-small-samples" id="toc-the-challenge-of-missing-data-in-small-samples" class="nav-link" data-scroll-target="#the-challenge-of-missing-data-in-small-samples"><span class="header-section-number">2.4.2</span> The Challenge of Missing Data in Small Samples</a></li>
  <li><a href="#types-of-missingness" id="toc-types-of-missingness" class="nav-link" data-scroll-target="#types-of-missingness"><span class="header-section-number">2.4.3</span> Types of Missingness</a></li>
  <li><a href="#describing-missingness-patterns" id="toc-describing-missingness-patterns" class="nav-link" data-scroll-target="#describing-missingness-patterns"><span class="header-section-number">2.4.4</span> Describing Missingness Patterns</a></li>
  <li><a href="#example-dataset-for-diagnostics" id="toc-example-dataset-for-diagnostics" class="nav-link" data-scroll-target="#example-dataset-for-diagnostics"><span class="header-section-number">2.4.5</span> Example Dataset for Diagnostics</a></li>
  <li><a href="#testing-the-mcar-assumption" id="toc-testing-the-mcar-assumption" class="nav-link" data-scroll-target="#testing-the-mcar-assumption"><span class="header-section-number">2.4.6</span> Testing the MCAR Assumption</a></li>
  <li><a href="#example-summarising-missing-data" id="toc-example-summarising-missing-data" class="nav-link" data-scroll-target="#example-summarising-missing-data"><span class="header-section-number">2.4.7</span> Example: Summarising Missing Data</a></li>
  <li><a href="#complete-case-listwise-deletion-analysis" id="toc-complete-case-listwise-deletion-analysis" class="nav-link" data-scroll-target="#complete-case-listwise-deletion-analysis"><span class="header-section-number">2.4.8</span> Complete-Case (Listwise Deletion) Analysis</a></li>
  <li><a href="#mean-imputation-not-recommended" id="toc-mean-imputation-not-recommended" class="nav-link" data-scroll-target="#mean-imputation-not-recommended"><span class="header-section-number">2.4.9</span> Mean Imputation (Not Recommended)</a></li>
  <li><a href="#last-observation-carried-forward-locf" id="toc-last-observation-carried-forward-locf" class="nav-link" data-scroll-target="#last-observation-carried-forward-locf"><span class="header-section-number">2.4.10</span> Last Observation Carried Forward (LOCF)</a></li>
  <li><a href="#multiple-imputation-caution-with-small-samples" id="toc-multiple-imputation-caution-with-small-samples" class="nav-link" data-scroll-target="#multiple-imputation-caution-with-small-samples"><span class="header-section-number">2.4.11</span> Multiple Imputation (Caution with Small Samples)</a></li>
  <li><a href="#example-multiple-imputation-with-mice-caution" id="toc-example-multiple-imputation-with-mice-caution" class="nav-link" data-scroll-target="#example-multiple-imputation-with-mice-caution"><span class="header-section-number">2.4.12</span> Example: Multiple Imputation with mice (Caution)</a></li>
  <li><a href="#checking-convergence-of-multiple-imputation" id="toc-checking-convergence-of-multiple-imputation" class="nav-link" data-scroll-target="#checking-convergence-of-multiple-imputation"><span class="header-section-number">2.4.13</span> Checking Convergence of Multiple Imputation</a></li>
  <li><a href="#sensitivity-analyses" id="toc-sensitivity-analyses" class="nav-link" data-scroll-target="#sensitivity-analyses"><span class="header-section-number">2.4.14</span> Sensitivity Analyses</a></li>
  <li><a href="#preventing-missing-data" id="toc-preventing-missing-data" class="nav-link" data-scroll-target="#preventing-missing-data"><span class="header-section-number">2.4.15</span> Preventing Missing Data</a></li>
  </ul></li>
  <li><a href="#chapter-12.5.-assessing-multiple-imputation-quality" id="toc-chapter-12.5.-assessing-multiple-imputation-quality" class="nav-link" data-scroll-target="#chapter-12.5.-assessing-multiple-imputation-quality"><span class="header-section-number">2.5</span> Chapter 12.5. Assessing Multiple Imputation Quality</a>
  <ul class="collapse">
  <li><a href="#learning-objectives-4" id="toc-learning-objectives-4" class="nav-link" data-scroll-target="#learning-objectives-4"><span class="header-section-number">2.5.1</span> Learning Objectives</a></li>
  <li><a href="#why-imputation-diagnostics-matter" id="toc-why-imputation-diagnostics-matter" class="nav-link" data-scroll-target="#why-imputation-diagnostics-matter"><span class="header-section-number">2.5.2</span> Why Imputation Diagnostics Matter</a></li>
  <li><a href="#diagnostic-1-convergence-checks" id="toc-diagnostic-1-convergence-checks" class="nav-link" data-scroll-target="#diagnostic-1-convergence-checks"><span class="header-section-number">2.5.3</span> Diagnostic 1: Convergence Checks</a></li>
  <li><a href="#diagnostic-2-imputed-vs.-observed-distributions" id="toc-diagnostic-2-imputed-vs.-observed-distributions" class="nav-link" data-scroll-target="#diagnostic-2-imputed-vs.-observed-distributions"><span class="header-section-number">2.5.4</span> Diagnostic 2: Imputed vs.&nbsp;Observed Distributions</a></li>
  <li><a href="#diagnostic-3-sensitivity-to-m-number-of-imputations" id="toc-diagnostic-3-sensitivity-to-m-number-of-imputations" class="nav-link" data-scroll-target="#diagnostic-3-sensitivity-to-m-number-of-imputations"><span class="header-section-number">2.5.5</span> Diagnostic 3: Sensitivity to m (Number of Imputations)</a></li>
  <li><a href="#diagnostic-4-checking-imputation-model-assumptions" id="toc-diagnostic-4-checking-imputation-model-assumptions" class="nav-link" data-scroll-target="#diagnostic-4-checking-imputation-model-assumptions"><span class="header-section-number">2.5.6</span> Diagnostic 4: Checking Imputation Model Assumptions</a></li>
  <li><a href="#diagnostic-5-fraction-of-missing-information-fmi" id="toc-diagnostic-5-fraction-of-missing-information-fmi" class="nav-link" data-scroll-target="#diagnostic-5-fraction-of-missing-information-fmi"><span class="header-section-number">2.5.7</span> Diagnostic 5: Fraction of Missing Information (FMI)</a></li>
  <li><a href="#example-full-diagnostic-workflow" id="toc-example-full-diagnostic-workflow" class="nav-link" data-scroll-target="#example-full-diagnostic-workflow"><span class="header-section-number">2.5.8</span> Example: Full Diagnostic Workflow</a></li>
  <li><a href="#red-flags-and-troubleshooting" id="toc-red-flags-and-troubleshooting" class="nav-link" data-scroll-target="#red-flags-and-troubleshooting"><span class="header-section-number">2.5.9</span> Red Flags and Troubleshooting</a></li>
  <li><a href="#reporting-mi-diagnostics" id="toc-reporting-mi-diagnostics" class="nav-link" data-scroll-target="#reporting-mi-diagnostics"><span class="header-section-number">2.5.10</span> Reporting MI Diagnostics</a></li>
  <li><a href="#key-takeaways-3" id="toc-key-takeaways-3" class="nav-link" data-scroll-target="#key-takeaways-3"><span class="header-section-number">2.5.11</span> Key Takeaways</a></li>
  <li><a href="#self-assessment-quiz-3" id="toc-self-assessment-quiz-3" class="nav-link" data-scroll-target="#self-assessment-quiz-3"><span class="header-section-number">2.5.12</span> Self-Assessment Quiz</a></li>
  <li><a href="#key-takeaways-4" id="toc-key-takeaways-4" class="nav-link" data-scroll-target="#key-takeaways-4"><span class="header-section-number">2.5.13</span> Key Takeaways</a></li>
  <li><a href="#smoke-test-3" id="toc-smoke-test-3" class="nav-link" data-scroll-target="#smoke-test-3"><span class="header-section-number">2.5.14</span> Smoke Test</a></li>
  </ul></li>
  <li><a href="#summary-of-part-b" id="toc-summary-of-part-b" class="nav-link" data-scroll-target="#summary-of-part-b"><span class="header-section-number">2.6</span> Summary of Part B</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/part-b-data-collection.html">Part B: Data Collection and Preparation</a></li><li class="breadcrumb-item"><a href="../chapters/part-b-data-collection.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Part B: Data Collection and Preparation</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Part B: Data Collection and Preparation</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>This part addresses practical challenges in collecting and preparing data for small-sample studies. We cover sampling strategies that maximise information with limited resources, measurement quality and scale development, data screening and diagnostic checks, and handling missing data transparently.</p>
<hr>
<section id="chapter-9.-sampling-strategies-for-small-studies" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="chapter-9.-sampling-strategies-for-small-studies"><span class="header-section-number">2.1</span> Chapter 9. Sampling Strategies for Small Studies</h2>
<section id="learning-objectives" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="learning-objectives"><span class="header-section-number">2.1.1</span> Learning Objectives</h3>
<p>By the end of this chapter, you will be able to:</p>
<p><strong>Conceptual Understanding</strong> - ✓ Explain the trade-offs between probability and purposive sampling - ✓ Understand the relationship between sample size, power, and detectable effects - ✓ Recognize when small samples are sufficient vs.&nbsp;inadequate - ✓ Distinguish between sampling for generalizability vs.&nbsp;mechanism testing</p>
<p><strong>Practical Skills</strong> - ✓ Select appropriate sampling methods given resource and population constraints - ✓ Calculate minimum detectable effects for planned sample sizes - ✓ Implement stratified sampling to improve precision with small n - ✓ Design sequential and adaptive sampling strategies</p>
<p><strong>Critical Evaluation</strong> - ✓ Assess the tension between ideal and feasible sample sizes - ✓ Evaluate whether purposive sampling is appropriate for research aims - ✓ Critique sampling justifications in published small-sample studies</p>
<p><strong>Application</strong> - ✓ Justify sample sizes transparently in research proposals - ✓ Design sampling plans that maximize information with limited resources - ✓ Report sampling procedures and achieved samples with appropriate caveats</p>
</section>
<section id="the-tension-between-ideal-and-feasible-sample-sizes" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="the-tension-between-ideal-and-feasible-sample-sizes"><span class="header-section-number">2.1.2</span> The Tension Between Ideal and Feasible Sample Sizes</h3>
<p>Most power analysis guides assume that researchers can achieve conventionally adequate sample sizes (n ≥ 30 per group for t-tests, 10–15 events per predictor for regression). In practice, resource constraints, rare populations, and ethical considerations often make these targets unattainable. Rather than abandoning research in such contexts, we should adopt methods suited to smaller samples and report findings with appropriate caveats.</p>
<p>Transparent reporting of sampling rationale, achieved sample size, and power or precision estimates helps readers judge the strength of evidence. Researchers should distinguish between studies designed to test specific hypotheses (which require adequate power) and exploratory studies that generate hypotheses or provide preliminary effect estimates (which can proceed with modest samples).</p>
</section>
<section id="probability-sampling-with-small-samples" class="level3" data-number="2.1.3">
<h3 data-number="2.1.3" class="anchored" data-anchor-id="probability-sampling-with-small-samples"><span class="header-section-number">2.1.3</span> Probability Sampling with Small Samples</h3>
<p>Probability sampling (simple random sampling, stratified sampling, cluster sampling) ensures that every unit has a known, non-zero probability of selection. This supports generalisation to the target population and enables design-based inference. However, probability sampling requires a sampling frame and may be logistically complex or expensive.</p>
<p>With small samples, probability sampling can still be valuable, but estimates will have wide confidence intervals. Stratified sampling (dividing the population into strata and sampling proportionally or disproportionally from each) can improve precision by ensuring representation of key subgroups.</p>
<p><strong>When to use</strong>: Accessible sampling frame, desire for generalisability, resources permit random selection, even if total sample size is modest.</p>
</section>
<section id="sequential-and-adaptive-sampling" class="level3" data-number="2.1.4">
<h3 data-number="2.1.4" class="anchored" data-anchor-id="sequential-and-adaptive-sampling"><span class="header-section-number">2.1.4</span> Sequential and Adaptive Sampling</h3>
<p>When recruitment is costly or uncertain, sequential designs allow researchers to review interim results and decide whether to continue sampling. For example, you might pre-specify that recruitment will proceed in waves of five participants, stopping early if credible intervals for the primary outcome are sufficiently narrow or if feasibility metrics (e.g., consent rates) fall below thresholds. Adaptive sampling can also target underrepresented strata after an initial wave, improving balance without committing to a large upfront sample. Key principles:</p>
<ul>
<li><strong>Set decision rules in advance.</strong> Define stopping boundaries for efficacy, futility, or feasibility to avoid ad hoc choices.</li>
<li><strong>Maintain error control.</strong> Use exact tests, Bayesian posterior probabilities, or alpha-spending functions appropriate for small <em>n</em>.</li>
<li><strong>Document adaptations transparently.</strong> Report how the sampling plan evolved, including any changes to recruitment targets or strata weights.</li>
</ul>
<p>Sequential or response-adaptive sampling is especially valuable in rare populations, where pausing after each wave prevents over-committing resources if early data already provide actionable evidence.</p>
</section>
<section id="example-stratified-sampling-calculation" class="level3" data-number="2.1.5">
<h3 data-number="2.1.5" class="anchored" data-anchor-id="example-stratified-sampling-calculation"><span class="header-section-number">2.1.5</span> Example: Stratified Sampling Calculation</h3>
<p>Suppose we are surveying employees in a small organisation with 120 total staff: 60 in Department A, 40 in Department B, 20 in Department C. We can afford to survey 30 employees. Proportional stratified sampling ensures each department is represented in proportion to its size.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Population strata</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>strata <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">Department =</span> <span class="fu">c</span>(<span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span>),</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">Population_N =</span> <span class="fu">c</span>(<span class="dv">60</span>, <span class="dv">40</span>, <span class="dv">20</span>),</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">Proportion =</span> Population_N <span class="sc">/</span> <span class="fu">sum</span>(Population_N)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Total sample size</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>total_sample <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Allocate sample proportionally</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>strata <span class="ot">&lt;-</span> strata <span class="sc">%&gt;%</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">Sample_n =</span> <span class="fu">round</span>(Proportion <span class="sc">*</span> total_sample),</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">Sampling_Fraction =</span> Sample_n <span class="sc">/</span> Population_N</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(strata)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 5
  Department Population_N Proportion Sample_n Sampling_Fraction
  &lt;chr&gt;             &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt;
1 A                    60      0.5         15              0.25
2 B                    40      0.333       10              0.25
3 C                    20      0.167        5              0.25</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Total sample allocated:"</span>, <span class="fu">sum</span>(strata<span class="sc">$</span>Sample_n), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Total sample allocated: 30 </code></pre>
</div>
</div>
<p>Interpretation: Proportional allocation ensures that each department contributes to the sample in proportion to its population size. Department A, being the largest, provides 15 respondents; Department C, the smallest, provides 5. This approach yields unbiased estimates for the overall population. If precision for small strata is a concern, disproportionate allocation (oversampling small strata) can be used, though this requires weighting in analysis.</p>
</section>
<section id="purposive-and-convenience-sampling" class="level3" data-number="2.1.6">
<h3 data-number="2.1.6" class="anchored" data-anchor-id="purposive-and-convenience-sampling"><span class="header-section-number">2.1.6</span> Purposive and Convenience Sampling</h3>
<p>Purposive (judgmental) sampling selects units based on researcher judgement of their informativeness or representativeness. Convenience sampling selects units that are easily accessible. Neither method supports probabilistic generalisation, but both are common in small-sample research where probability sampling is infeasible.</p>
<p>Findings from purposive or convenience samples should be interpreted cautiously and presented as preliminary or context-specific. Replication in independent samples strengthens confidence.</p>
<p><strong>When to use</strong>: No sampling frame available, exploratory research, pilot studies, rare or hard-to-reach populations, tight resource constraints.</p>
</section>
<section id="quota-sampling" class="level3" data-number="2.1.7">
<h3 data-number="2.1.7" class="anchored" data-anchor-id="quota-sampling"><span class="header-section-number">2.1.7</span> Quota Sampling</h3>
<p>Quota sampling (a form of purposive sampling) selects units to match known population characteristics (such as age, gender, or occupation distribution). It mimics stratified sampling but without random selection within strata. Quota sampling can improve representativeness compared to convenience sampling, though it remains non-probabilistic.</p>
<p><strong>When to use</strong>: Known population characteristics to match, desire for balanced sample composition, probability sampling infeasible.</p>
</section>
<section id="power-and-precision-with-small-samples" class="level3" data-number="2.1.8">
<h3 data-number="2.1.8" class="anchored" data-anchor-id="power-and-precision-with-small-samples"><span class="header-section-number">2.1.8</span> Power and Precision with Small Samples</h3>
<p>Statistical power is the probability of detecting a true effect of a given size. With small samples, power is limited, meaning that even if a meaningful effect exists, the study may fail to detect it (high Type II error rate). Researchers should conduct power analyses before data collection to understand what effects are detectable given sample size constraints.</p>
<p>If the achieved sample size is smaller than desired, report the minimum detectable effect (MDE): the smallest effect the study can detect with specified power (typically 80%) and alpha (typically 0.05). This helps readers judge whether the study could have detected effects of practical importance.</p>
</section>
<section id="finite-population-correction" class="level3" data-number="2.1.9">
<h3 data-number="2.1.9" class="anchored" data-anchor-id="finite-population-correction"><span class="header-section-number">2.1.9</span> Finite Population Correction</h3>
<p>When sampling without replacement from a small, known population, the variance of estimates decreases because each sampled unit reduces remaining uncertainty. The finite population correction (FPC) adjusts the required sample size accordingly. If a power analysis suggests 30 participants are needed assuming an infinite population, but the accessible population is only 120 people, the adjusted sample size is smaller:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Finite population correction example</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>n_required_infinite <span class="ot">&lt;-</span> <span class="dv">30</span>  <span class="co"># From power analysis</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>N_population <span class="ot">&lt;-</span> <span class="dv">120</span>        <span class="co"># Size of accessible population</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>n_adjusted <span class="ot">&lt;-</span> n_required_infinite <span class="sc">/</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">1</span> <span class="sc">+</span> (n_required_infinite <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">/</span> N_population)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>n_adjusted</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 24.16</code></pre>
</div>
</div>
<p>Interpretation: Sampling without replacement from 120 individuals means that a sample of roughly 24 (instead of 30) achieves the same precision. Always report whether you applied the FPC so readers can replicate the calculation.</p>
</section>
<section id="example-power-calculation-for-a-small-study" class="level3" data-number="2.1.10">
<h3 data-number="2.1.10" class="anchored" data-anchor-id="example-power-calculation-for-a-small-study"><span class="header-section-number">2.1.10</span> Example: Power Calculation for a Small Study</h3>
<p>We plan a study comparing two groups with n = 12 per group. We compute power to detect a medium effect size (Cohen’s d = 0.5) using a two-sample t-test.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Power calculation using pwr package (if available)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># If not installed, use approximations or manual calculation</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">requireNamespace</span>(<span class="st">"pwr"</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(pwr)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  power_result <span class="ot">&lt;-</span> <span class="fu">pwr.t.test</span>(<span class="at">n =</span> <span class="dv">12</span>, <span class="at">d =</span> <span class="fl">0.5</span>, <span class="at">sig.level =</span> <span class="fl">0.05</span>, </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>                              <span class="at">type =</span> <span class="st">"two.sample"</span>, <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(power_result)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">With n = 12 per group, power to detect d = 0.5 is:"</span>, </span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>      <span class="fu">round</span>(power_result<span class="sc">$</span>power, <span class="dv">2</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># What effect size is detectable with 80% power?</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>  mde_result <span class="ot">&lt;-</span> <span class="fu">pwr.t.test</span>(<span class="at">n =</span> <span class="dv">12</span>, <span class="at">power =</span> <span class="fl">0.80</span>, <span class="at">sig.level =</span> <span class="fl">0.05</span>,</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>                           <span class="at">type =</span> <span class="st">"two.sample"</span>, <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"Minimum detectable effect (80% power):"</span>, <span class="fu">round</span>(mde_result<span class="sc">$</span>d, <span class="dv">2</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"Install 'pwr' package to run power calculations.</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
     Two-sample t test power calculation 

              n = 12
              d = 0.5
      sig.level = 0.05
          power = 0.2161
    alternative = two.sided

NOTE: n is number in *each* group


With n = 12 per group, power to detect d = 0.5 is: 0.22 
Minimum detectable effect (80% power): 1.2 </code></pre>
</div>
</div>
<p>Interpretation: With 12 participants per group, power to detect a medium effect (d = 0.5) is modest (approximately 30–40%). To achieve 80% power, we would need to detect a larger effect (d ≈ 1.2, a very large effect). This illustrates the limitation of small samples for hypothesis testing. If the true effect is small or medium, the study is underpowered. Researchers should acknowledge this limitation and interpret non-significant results cautiously (absence of evidence is not evidence of absence).</p>
</section>
<section id="sample-size-planning-workflow" class="level3" data-number="2.1.11">
<h3 data-number="2.1.11" class="anchored" data-anchor-id="sample-size-planning-workflow"><span class="header-section-number">2.1.11</span> Sample Size Planning Workflow</h3>
<p>Integrating power analysis into a broader planning conversation prevents unrealistic promises and surfaces design trade-offs early. Use the following workflow whenever you scope a small-sample study:</p>
<ol type="1">
<li><strong>Clarify the question and estimand.</strong> What parameter (difference in means, odds ratio, correlation) must the study estimate?</li>
<li><strong>Specify tolerable uncertainty.</strong> Define the minimum detectable effect or target confidence-interval width that would make the study actionable.</li>
<li><strong>Map constraints.</strong> Document recruitment limits, budget, timeline, and ethical restrictions (e.g., maximum patient burden).</li>
<li><strong>Select design and analysis.</strong> Choose the test/model, decide on one- vs two-sided inference, and note planned covariates or repeated measures.</li>
<li><strong>Compute required <em>n</em>.</strong> Use analytical power formulas, simulation, or resampling as appropriate; apply finite-population corrections if sampling without replacement.</li>
<li><strong>Assess feasibility.</strong> Compare required <em>n</em> to constraints. If infeasible, adjust expectations (e.g., shift to estimation focus, reduce assurance level, adopt sequential design).</li>
<li><strong>Document decisions.</strong> Record assumptions, software/code used, and any compromises for transparency.</li>
</ol>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
  Q[Define research question &amp; estimand] --&gt; U[Specify target effect or CI width]
  U --&gt; C[Document recruitment, budget, ethical constraints]
  C --&gt; D[Choose design &amp; analysis plan]
  D --&gt; N[Compute required sample size / MDE]
  N --&gt; F{Feasible within constraints?}
  F -- Yes --&gt; T[Lock plan &amp; preregister]
  F -- No --&gt; A[Adjust goals: revise estimand, adopt sequential design, or reframe as exploratory]
  A --&gt; C
  T --&gt; R[Record assumptions &amp; share in protocol]
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>This loop makes trade-offs explicit: if the required sample size exceeds what is feasible, researchers can justify an exploratory framing, add interim analyses, or negotiate for additional resources before data collection begins.</p>
</section>
<section id="justifying-small-sample-sizes" class="level3" data-number="2.1.12">
<h3 data-number="2.1.12" class="anchored" data-anchor-id="justifying-small-sample-sizes"><span class="header-section-number">2.1.12</span> Justifying Small Sample Sizes</h3>
<p>When sample sizes are constrained, justify them transparently:</p>
<ul>
<li>State the target population and accessible population.</li>
<li>Describe sampling method and rationale.</li>
<li>Report planned and achieved sample sizes.</li>
<li>Provide power or precision estimates (confidence interval widths).</li>
<li>Acknowledge limitations and interpret findings accordingly.</li>
<li>Frame the study as exploratory or preliminary if appropriate.</li>
</ul>
</section>
<section id="sample-size-planning-flowchart" class="level3" data-number="2.1.13">
<h3 data-number="2.1.13" class="anchored" data-anchor-id="sample-size-planning-flowchart"><span class="header-section-number">2.1.13</span> Sample Size Planning Flowchart</h3>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
  A[Define research question] --&gt; B[Specify primary outcome and test]
  B --&gt; C[Determine minimally important effect]
  C --&gt; D{Effect size from...}
  D --&gt;|Pilot data| E[Use observed effect]
  D --&gt;|Literature| F[Use meta-analytic estimate]
  D --&gt;|Stakeholder| G[Use practical threshold]
  E --&gt; H[Conduct power analysis]
  F --&gt; H
  G --&gt; H
  H --&gt; I{Achieve n for 80% power?}
  I --&gt;|Yes| J[Proceed with confirmatory study]
  I --&gt;|No| K[Consider alternatives]
  K --&gt; L[Paired/within design?]
  K --&gt; M[More sensitive outcome?]
  K --&gt; N[Continuous vs. binary?]
  K --&gt; O[Bayesian with priors?]
  K --&gt; P[Reframe as exploratory pilot]
  L --&gt; Q[Recalculate power]
  M --&gt; Q
  N --&gt; Q
  O --&gt; Q
  P --&gt; R[Document limitations]
  J --&gt; S[Pre-register plan]
  Q --&gt; I
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p><strong>Interpretation:</strong> This flowchart guides researchers through sample size planning, showing decision points and alternatives when the target sample size is not feasible.</p>
<hr>
</section>
<section id="self-assessment-quiz" class="level3" data-number="2.1.14">
<h3 data-number="2.1.14" class="anchored" data-anchor-id="self-assessment-quiz"><span class="header-section-number">2.1.14</span> Self-Assessment Quiz</h3>
<p>Test your understanding of sampling strategies from Chapter 9. Answers and explanations are provided at the end.</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Questions
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Q1.</strong> A researcher uses a “rule of thumb” of n=30 per group for all studies. What is the primary problem with this approach?</p>
<p>A. n=30 is always too small<br>
B. Sample size should depend on effect size, power, and research question—not arbitrary rules<br>
C. n=30 is always too large<br>
D. Rules of thumb are always correct</p>
<hr>
<p><strong>Q2.</strong> Stratified sampling is most useful when:</p>
<p>A. The population is homogeneous<br>
B. You want to ensure representation of key subgroups that differ on the outcome<br>
C. Random selection is impossible<br>
D. Sample size exceeds 1,000</p>
<hr>
<p><strong>Q3.</strong> Power analysis reveals you need n=50 per group, but only n=20 is feasible. What should you do?</p>
<p>A. Abandon the study<br>
B. Proceed, but report the study as exploratory/pilot and calculate minimum detectable effect (MDE)<br>
C. Proceed and claim the same statistical power<br>
D. Ignore power entirely</p>
<hr>
<p><strong>Q4.</strong> Which sampling method allows probabilistic generalization to a target population?</p>
<p>A. Convenience sampling<br>
B. Purposive sampling<br>
C. Simple random sampling<br>
D. Snowball sampling</p>
<hr>
<p><strong>Q5.</strong> Quota sampling differs from stratified sampling in that:</p>
<p>A. It uses random selection within strata<br>
B. It matches population proportions but does not use random selection<br>
C. It requires a sampling frame<br>
D. It is always more accurate</p>
<hr>
<p><strong>Q6.</strong> A study with n=15 per group has 30% power to detect d=0.5. The researcher should report:</p>
<p>A. “The study was adequately powered”<br>
B. “The study was underpowered to detect medium effects; only large effects (d≥1.0) could be reliably detected”<br>
C. “Power is irrelevant with small samples”<br>
D. “Non-significant results prove no effect exists”</p>
<hr>
<p><strong>Q7.</strong> The finite population correction (FPC) is relevant when:</p>
<p>A. Sampling with replacement from an infinite population<br>
B. Sampling without replacement from a small, known population (e.g., N=100)<br>
C. Sample size exceeds population size<br>
D. Using convenience sampling</p>
<hr>
<p><strong>Q8.</strong> Sequential sampling allows researchers to:</p>
<p>A. Collect all data simultaneously<br>
B. Stop early if interim results show sufficient precision or evidence<br>
C. Ignore power analysis<br>
D. Change hypotheses after seeing data</p>
<hr>
<p><strong>Q9.</strong> A convenience sample from one university is used to test a new teaching method. Which statement is TRUE?</p>
<p>A. Results generalize to all universities<br>
B. Results are context-specific and require replication<br>
C. Convenience sampling is never acceptable<br>
D. Results are as valid as random sampling</p>
<hr>
<p><strong>Q10.</strong> Minimum Detectable Effect (MDE) refers to:</p>
<p>A. The smallest effect that exists in the population<br>
B. The smallest effect the study can detect with specified power (e.g., 80%)<br>
C. The p-value threshold<br>
D. The confidence interval width</p>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Answers and Explanations
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Q1. Answer: B</strong><br>
<em>Explanation</em>: Sample size should depend on effect size, power, and research question—not arbitrary rules. A small effect requires larger n; a large effect can be detected with smaller n.&nbsp;The chapter emphasizes: “Rather than abandoning research in such contexts, we should adopt methods suited to smaller samples and report findings with appropriate caveats.”</p>
<p><strong>Q2. Answer: B</strong><br>
<em>Explanation</em>: Stratified sampling divides the population into strata and ensures each stratum is represented. This improves precision when strata differ on the outcome. The chapter states: “Stratified sampling (dividing the population into strata and sampling proportionally or disproportionally from each) can improve precision by ensuring representation of key subgroups.”</p>
<p><strong>Q3. Answer: B</strong><br>
<em>Explanation</em>: Proceed, but report the study as exploratory/pilot and calculate minimum detectable effect (MDE). Transparency about power limitations is essential. The chapter recommends: “If the achieved sample size is smaller than desired, report the minimum detectable effect (MDE).”</p>
<p><strong>Q4. Answer: C</strong><br>
<em>Explanation</em>: Simple random sampling (and other probability sampling methods) ensures every unit has a known, non-zero probability of selection, supporting generalization. The chapter states: “Probability sampling…ensures that every unit has a known, non-zero probability of selection. This supports generalisation to the target population.”</p>
<p><strong>Q5. Answer: B</strong><br>
<em>Explanation</em>: Quota sampling matches population proportions but does not use random selection within strata. It “mimics stratified sampling but without random selection within strata.” This makes it non-probabilistic.</p>
<p><strong>Q6. Answer: B</strong><br>
<em>Explanation</em>: With 30% power for d=0.5, the study can only reliably detect large effects (d≥1.0, which has ~80% power with n=15). The chapter emphasizes transparent reporting: “Researchers should conduct power analyses before data collection to understand what effects are detectable.”</p>
<p><strong>Q7. Answer: B</strong><br>
<em>Explanation</em>: FPC adjusts required sample size when sampling without replacement from a small, finite population. The chapter explains: “When sampling without replacement from a small, known population, the variance of estimates decreases…The finite population correction (FPC) adjusts the required sample size accordingly.”</p>
<p><strong>Q8. Answer: B</strong><br>
<em>Explanation</em>: Sequential sampling allows stopping early based on pre-specified decision rules if interim results show sufficient precision or evidence. The chapter describes: “sequential designs allow researchers to review interim results and decide whether to continue sampling.”</p>
<p><strong>Q9. Answer: B</strong><br>
<em>Explanation</em>: Convenience samples are context-specific and require replication. The chapter states: “Findings from purposive or convenience samples should be interpreted cautiously and presented as preliminary or context-specific. Replication in independent samples strengthens confidence.”</p>
<p><strong>Q10. Answer: B</strong><br>
<em>Explanation</em>: MDE is the smallest effect the study can detect with specified power (typically 80%) and alpha (typically 0.05). The chapter defines it: “the minimum detectable effect (MDE): the smallest effect the study can detect with specified power.”</p>
</div>
</div>
</div>
<hr>
</section>
<section id="key-takeaways" class="level3" data-number="2.1.15">
<h3 data-number="2.1.15" class="anchored" data-anchor-id="key-takeaways"><span class="header-section-number">2.1.15</span> Key Takeaways</h3>
<ul>
<li>Probability sampling supports generalisation but may be infeasible with small samples or rare populations.</li>
<li>Stratified sampling can improve precision by ensuring representation of key subgroups.</li>
<li>Purposive and convenience sampling are common in small-sample research but limit generalisability.</li>
<li>Quota sampling balances sample composition without requiring random selection.</li>
<li>Power analyses reveal what effects are detectable given sample size; small samples have limited power for detecting small or medium effects.</li>
<li>Transparent reporting of sampling methods, achieved sample sizes, and power or precision estimates is essential for interpreting small-sample findings.</li>
</ul>
</section>
<section id="smoke-test" class="level3" data-number="2.1.16">
<h3 data-number="2.1.16" class="anchored" data-anchor-id="smoke-test"><span class="header-section-number">2.1.16</span> Smoke Test</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run stratified allocation</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>departments <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">60</span>, <span class="dv">40</span>, <span class="dv">20</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>total_n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>allocation <span class="ot">&lt;-</span> <span class="fu">round</span>((departments <span class="sc">/</span> <span class="fu">sum</span>(departments)) <span class="sc">*</span> total_n)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(allocation)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 15 10  5</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="chapter-10.-measurement-quality-and-scale-development" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="chapter-10.-measurement-quality-and-scale-development"><span class="header-section-number">2.2</span> Chapter 10. Measurement Quality and Scale Development</h2>
<section id="learning-objectives-1" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="learning-objectives-1"><span class="header-section-number">2.2.1</span> Learning Objectives</h3>
<p>By the end of this chapter, you will be able to:</p>
<p><strong>Conceptual Understanding</strong> - ✓ Explain the distinctions between content, construct, and criterion validity - ✓ Understand reliability theory and sources of measurement error - ✓ Recognize the limitations of psychometric analyses with small samples - ✓ Distinguish quantitative vs.&nbsp;qualitative approaches to scale validation</p>
<p><strong>Practical Skills</strong> - ✓ Pilot test scales and collect qualitative feedback with small samples - ✓ Compute item-level statistics (means, SDs, correlations) in R - ✓ Calculate internal consistency (Cronbach’s α) and interpret appropriately - ✓ Identify problematic items using discrimination and ceiling/floor effects</p>
<p><strong>Critical Evaluation</strong> - ✓ Assess when sample sizes are adequate for factor analysis vs.&nbsp;when to defer - ✓ Evaluate the trade-off between brief scales (fewer items) and reliability - ✓ Critique whether items have content validity for the intended construct</p>
<p><strong>Application</strong> - ✓ Design iterative scale refinement processes with limited samples - ✓ Report scale properties transparently (including small-sample limitations) - ✓ Prioritize qualitative feedback over unstable quantitative indices when appropriate</p>
</section>
<section id="the-challenge-of-measurement-in-small-studies" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="the-challenge-of-measurement-in-small-studies"><span class="header-section-number">2.2.2</span> The Challenge of Measurement in Small Studies</h3>
<p>Many small-sample studies rely on brief, custom-developed measurement instruments. Standard scale development protocols (large pilot studies, factor analysis, item response theory) require hundreds of observations. With small samples, researchers must balance the need for reliable, valid measurement with practical constraints.</p>
<p>Short scales (3–5 items) can be internally consistent and valid if items are carefully chosen. Pilot testing with qualitative feedback (cognitive interviews, think-aloud protocols) can identify ambiguous wording, response biases, and cultural appropriateness. Quantitative pilot data (even with n ≈ 20–30) can reveal extreme floor or ceiling effects, items with no variance, and obvious inconsistencies.</p>
</section>
<section id="content-and-face-validity" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="content-and-face-validity"><span class="header-section-number">2.2.3</span> Content and Face Validity</h3>
<p>Content validity refers to whether items comprehensively and appropriately represent the construct being measured. Face validity refers to whether items appear relevant and appropriate to respondents. Both are assessed through expert review and respondent feedback, not statistical tests.</p>
<p><strong>When to assess</strong>: During scale development, before quantitative pilot testing. Involves domain experts and representatives of the target population.</p>
<section id="content-validity-ratio-cvr" class="level4" data-number="2.2.3.1">
<h4 data-number="2.2.3.1" class="anchored" data-anchor-id="content-validity-ratio-cvr"><span class="header-section-number">2.2.3.1</span> Content Validity Ratio (CVR)</h4>
<p>Lawshe’s Content Validity Ratio provides a simple index of expert agreement on whether an item is “essential” to a construct. With <em>N</em> experts and <em>N</em><sub>e</sub> rating an item as essential, the CVR is:</p>
<p>[ = ]</p>
<p>CVR ranges from −1 to +1. Positive values indicate majority agreement that the item is essential; thresholds depend on the number of experts (e.g., ≥0.75 when <em>N</em> = 8). Use CVR alongside qualitative feedback to decide which items to retain.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CVR example: 8 experts, 6 judge the item essential</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>n_experts <span class="ot">&lt;-</span> <span class="dv">8</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>n_essential <span class="ot">&lt;-</span> <span class="dv">6</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>cvr <span class="ot">&lt;-</span> (n_essential <span class="sc">-</span> n_experts <span class="sc">/</span> <span class="dv">2</span>) <span class="sc">/</span> (n_experts <span class="sc">/</span> <span class="dv">2</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>cvr</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5</code></pre>
</div>
</div>
<p>Interpretation: A CVR of 0.50 indicates that 75% of experts deemed the item essential. Consult published critical values to confirm whether the item meets the desired level of agreement for your expert panel size.</p>
</section>
</section>
<section id="steps-for-scale-development-with-small-samples" class="level3" data-number="2.2.4">
<h3 data-number="2.2.4" class="anchored" data-anchor-id="steps-for-scale-development-with-small-samples"><span class="header-section-number">2.2.4</span> Steps for Scale Development with Small Samples</h3>
<ol type="1">
<li><strong>Define the construct clearly</strong>: What are you measuring? What are its dimensions or facets?</li>
<li><strong>Generate candidate items</strong>: Write more items than needed (e.g., 10–15 items for a final 5-item scale).</li>
<li><strong>Expert review</strong>: Ask domain experts to rate item relevance, clarity, and representativeness.</li>
<li><strong>Cognitive interviews</strong>: Ask a few respondents (n = 5–10) to complete the scale and think aloud, explaining their interpretations and any confusion.</li>
<li><strong>Quantitative pilot</strong>: Administer the scale to a small sample (n = 20–40) and compute item statistics.</li>
<li><strong>Item analysis</strong>: Identify problematic items (low variance, weak correlations with total score, ceiling/floor effects).</li>
<li><strong>Refine and re-test</strong>: Remove or revise problematic items and retest if resources permit.</li>
</ol>
</section>
<section id="example-item-analysis-for-a-pilot-scale" class="level3" data-number="2.2.5">
<h3 data-number="2.2.5" class="anchored" data-anchor-id="example-item-analysis-for-a-pilot-scale"><span class="header-section-number">2.2.5</span> Example: Item Analysis for a Pilot Scale</h3>
<p>We pilot a 5-item job satisfaction scale with n = 25 employees. Each item uses a 1–7 Likert response.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated pilot data: 25 respondents, 5 items</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>pilot_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">respondent =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">25</span>,</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">item1 =</span> <span class="fu">sample</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">7</span>, <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.25</span>, <span class="fl">0.15</span>)),</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">item2 =</span> <span class="fu">sample</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>, <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.15</span>, <span class="fl">0.25</span>, <span class="fl">0.25</span>, <span class="fl">0.15</span>, <span class="fl">0.1</span>)),</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">item3 =</span> <span class="fu">sample</span>(<span class="dv">4</span><span class="sc">:</span><span class="dv">7</span>, <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.3</span>, <span class="fl">0.2</span>)),  <span class="co"># restricted range</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">item4 =</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>, <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>),</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">item5 =</span> <span class="fu">sample</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>, <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.15</span>, <span class="fl">0.2</span>, <span class="fl">0.25</span>, <span class="fl">0.2</span>, <span class="fl">0.15</span>, <span class="fl">0.05</span>))</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Item descriptive statistics</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>item_stats <span class="ot">&lt;-</span> pilot_data <span class="sc">%&gt;%</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">starts_with</span>(<span class="st">"item"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), <span class="fu">list</span>(</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">mean =</span> mean,</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd =</span> sd,</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">min =</span> min,</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">max =</span> max</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>  ))) <span class="sc">%&gt;%</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">everything</span>(), <span class="at">names_to =</span> <span class="fu">c</span>(<span class="st">"item"</span>, <span class="st">".value"</span>), <span class="at">names_sep =</span> <span class="st">"_"</span>)</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(item_stats)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 5
  item   mean    sd   min   max
  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;
1 item1  5.52 1.16      3     7
2 item2  4.44 1.66      2     7
3 item3  5.72 0.980     4     7
4 item4  4.2  1.96      1     7
5 item5  3.8  1.55      2     6</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inter-item correlations</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>items_only <span class="ot">&lt;-</span> <span class="fu">select</span>(pilot_data, <span class="fu">starts_with</span>(<span class="st">"item"</span>))</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>cor_matrix <span class="ot">&lt;-</span> <span class="fu">cor</span>(items_only)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">round</span>(cor_matrix, <span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>      item1 item2 item3 item4 item5
item1  1.00  0.24 -0.20 -0.14  0.15
item2  0.24  1.00 -0.05 -0.08  0.12
item3 -0.20 -0.05  1.00  0.07  0.04
item4 -0.14 -0.08  0.07  1.00 -0.19
item5  0.15  0.12  0.04 -0.19  1.00</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Item-total correlations (corrected for item overlap)</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>item_total <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(items_only)<span class="sc">$</span>item.stats</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Some items ( item3 item4 ) were negatively correlated with the first principal component and 
probably should be reversed.  
To do this, run the function again with the 'check.keys=TRUE' option</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(item_total)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>       n  raw.r  std.r   r.cor   r.drop mean     sd
item1 25 0.4048 0.4768  0.3271  0.05850 5.52 1.1590
item2 25 0.5818 0.5538  0.5443  0.09640 4.44 1.6603
item3 25 0.2675 0.3919 -0.1461 -0.03047 5.72 0.9798
item4 25 0.4359 0.2981 -0.5152 -0.17220 4.20 1.9579
item5 25 0.4824 0.5039  0.3391  0.01298 3.80 1.5546</code></pre>
</div>
</div>
<p>Interpretation: Examine item means and standard deviations. Items with very high or low means and small SDs may have ceiling or floor effects (most respondents give the same response). Item 3 has a restricted range (4–7), which may indicate a ceiling effect. Inter-item correlations should be positive and moderate (0.3–0.7). Very low correlations suggest an item does not measure the same construct; very high correlations suggest redundancy. The corrected item-total correlation (r.drop) indicates how well each item correlates with the total score excluding itself. Values below 0.3 suggest weak items that could be removed.</p>
</section>
<section id="identifying-problematic-items" class="level3" data-number="2.2.6">
<h3 data-number="2.2.6" class="anchored" data-anchor-id="identifying-problematic-items"><span class="header-section-number">2.2.6</span> Identifying Problematic Items</h3>
<ul>
<li><strong>Low variance</strong>: If an item has very small SD (e.g., &lt; 1.0 on a 1–7 scale), most respondents are giving the same answer. The item may be too extreme, too obvious, or poorly worded.</li>
<li><strong>Weak item-total correlation</strong>: Items with corrected item-total correlations below 0.3 do not discriminate well and may be measuring something different.</li>
<li><strong>Floor or ceiling effects</strong>: If most responses cluster at the low or high end, the item cannot differentiate among respondents.</li>
<li><strong>Negative correlations</strong>: If an item correlates negatively with the total or with other items, it may be reverse-coded incorrectly or measuring an opposite construct.</li>
</ul>
</section>
<section id="refining-the-scale" class="level3" data-number="2.2.7">
<h3 data-number="2.2.7" class="anchored" data-anchor-id="refining-the-scale"><span class="header-section-number">2.2.7</span> Refining the Scale</h3>
<p>Based on item analysis, revise or remove problematic items. For example, if Item 3 shows a ceiling effect and Item 4 has weak item-total correlation, consider removing them. Compute alpha for the revised scale.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Revised scale: remove item3 and item4</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>revised_items <span class="ot">&lt;-</span> <span class="fu">select</span>(pilot_data, item1, item2, item5)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>alpha_revised <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(revised_items)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(alpha_revised)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Reliability analysis   
Call: psych::alpha(x = revised_items)

  raw_alpha std.alpha G6(smc) average_r  S/N  ase mean   sd median_r
      0.36      0.38     0.3      0.17 0.62 0.22  4.6 0.98     0.15

    95% confidence boundaries 
         lower alpha upper
Feldt    -0.24  0.36  0.70
Duhachek -0.06  0.36  0.79

 Reliability if an item is dropped:
      raw_alpha std.alpha G6(smc) average_r  S/N alpha se var.r med.r
item1      0.21      0.21    0.12      0.12 0.26     0.32    NA  0.12
item2      0.26      0.26    0.15      0.15 0.36     0.29    NA  0.15
item5      0.37      0.39    0.24      0.24 0.65     0.23    NA  0.24

 Item statistics 
       n raw.r std.r r.cor r.drop mean  sd
item1 25  0.61  0.70  0.43   0.27  5.5 1.2
item2 25  0.72  0.68  0.39   0.22  4.4 1.7
item5 25  0.66  0.63  0.27   0.16  3.8 1.6

Non missing response frequency for each item
         2    3    4    5    6    7 miss
item1 0.00 0.04 0.20 0.16 0.40 0.20    0
item2 0.20 0.08 0.20 0.24 0.16 0.12    0
item5 0.36 0.00 0.32 0.12 0.20 0.00    0</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Cronbach's alpha for revised 3-item scale:"</span>, <span class="fu">round</span>(alpha_revised<span class="sc">$</span>total<span class="sc">$</span>raw_alpha, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Cronbach's alpha for revised 3-item scale: 0.364 </code></pre>
</div>
</div>
<p>Interpretation: The revised scale may have higher alpha if problematic items are removed. However, removing items also reduces scale length, which can lower alpha. The goal is a balance: retain enough items for adequate reliability, but remove items that degrade validity or add no information.</p>
</section>
<section id="qualitative-feedback-and-cognitive-interviews" class="level3" data-number="2.2.8">
<h3 data-number="2.2.8" class="anchored" data-anchor-id="qualitative-feedback-and-cognitive-interviews"><span class="header-section-number">2.2.8</span> Qualitative Feedback and Cognitive Interviews</h3>
<p>With very small samples (n &lt; 20), quantitative item analysis is unreliable. Qualitative methods (cognitive interviews, focus groups) are more informative. Ask respondents:</p>
<ul>
<li>What does each item mean to you?</li>
<li>Were any items confusing, ambiguous, or difficult to answer?</li>
<li>Are the response options appropriate?</li>
<li>Are any items culturally inappropriate or offensive?</li>
</ul>
<p>This feedback can prevent major problems before larger-scale data collection.</p>
</section>
<section id="self-assessment-quiz-1" class="level3" data-number="2.2.9">
<h3 data-number="2.2.9" class="anchored" data-anchor-id="self-assessment-quiz-1"><span class="header-section-number">2.2.9</span> Self-Assessment Quiz</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Chapter 10 Questions
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Q1.</strong> What is the primary advantage of using qualitative methods (cognitive interviews) over quantitative methods when pilot testing scales with very small samples (n &lt; 20)?</p>
<ol type="A">
<li>Cognitive interviews provide more statistical power<br>
</li>
<li>Qualitative feedback can identify ambiguous wording and cultural issues without requiring statistical reliability<br>
</li>
<li>Quantitative item analysis is too expensive<br>
</li>
<li>Cognitive interviews automatically calculate Cronbach’s alpha</li>
</ol>
<hr>
<p><strong>Q2.</strong> In Lawshe’s Content Validity Ratio (CVR), if 8 experts are consulted and 6 judge an item as “essential,” what is the CVR?</p>
<ol type="A">
<li>0.25<br>
</li>
<li>0.50<br>
</li>
<li>0.75<br>
</li>
<li>1.00</li>
</ol>
<hr>
<p><strong>Q3.</strong> What does a “ceiling effect” in item analysis indicate?</p>
<ol type="A">
<li>Most respondents give the lowest possible response<br>
</li>
<li>Most respondents give the highest possible response<br>
</li>
<li>The item has perfect reliability<br>
</li>
<li>The item correlates negatively with the total score</li>
</ol>
<hr>
<p><strong>Q4.</strong> Which corrected item-total correlation threshold typically indicates that an item discriminates poorly and should be considered for removal?</p>
<ol type="A">
<li>Above 0.7<br>
</li>
<li>Between 0.3 and 0.7<br>
</li>
<li>Below 0.3<br>
</li>
<li>Exactly 0.5</li>
</ol>
<hr>
<p><strong>Q5.</strong> What does content validity assess?</p>
<ol type="A">
<li>Whether items comprehensively and appropriately represent the construct being measured<br>
</li>
<li>Whether the scale has high Cronbach’s alpha<br>
</li>
<li>Whether factor analysis confirms a one-dimensional structure<br>
</li>
<li>Whether the scale predicts future behavior</li>
</ol>
<hr>
<p><strong>Q6.</strong> Why might short scales (3–5 items) have lower Cronbach’s alpha than longer scales, even if items are well-chosen?</p>
<ol type="A">
<li>Short scales always measure different constructs<br>
</li>
<li>Cronbach’s alpha is mathematically influenced by the number of items—fewer items tend to yield lower alpha<br>
</li>
<li>Short scales cannot be reliable<br>
</li>
<li>Respondents don’t take short scales seriously</li>
</ol>
<hr>
<p><strong>Q7.</strong> In pilot testing with small samples (n ≈ 20–30), what is the primary limitation of conducting factor analysis?</p>
<ol type="A">
<li>Factor analysis requires specialized software<br>
</li>
<li>Factor analysis requires hundreds of observations for stable results; small samples yield unstable loadings<br>
</li>
<li>Factor analysis only works with 7-point Likert scales<br>
</li>
<li>Factor analysis cannot handle missing data</li>
</ol>
<hr>
<p><strong>Q8.</strong> If an item correlates negatively with the total score and with other items, what is the most likely explanation?</p>
<ol type="A">
<li>The item has high content validity<br>
</li>
<li>The item may be reverse-coded incorrectly or measuring an opposite construct<br>
</li>
<li>The sample size is too large<br>
</li>
<li>The item has a ceiling effect</li>
</ol>
<hr>
<p><strong>Q9.</strong> What is the primary purpose of asking domain experts to rate item relevance and clarity during scale development?</p>
<ol type="A">
<li>To calculate test-retest reliability<br>
</li>
<li>To establish content validity by ensuring items appropriately represent the construct<br>
</li>
<li>To compute inter-item correlations<br>
</li>
<li>To determine the optimal sample size for the study</li>
</ol>
<hr>
<p><strong>Q10.</strong> In the example of the 5-item job satisfaction scale, Item 3 had a restricted range (responses only from 4–7 on a 1–7 scale). What does this suggest?</p>
<ol type="A">
<li>Item 3 has perfect reliability<br>
</li>
<li>Item 3 may have a ceiling effect, limiting its ability to differentiate among respondents<br>
</li>
<li>Item 3 should be kept because high scores are desirable<br>
</li>
<li>The sample size should be increased to 1,000</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Answers and Explanations
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>A1. B)</strong> “With very small samples (n &lt; 20), quantitative item analysis is unreliable. Qualitative methods (cognitive interviews, focus groups) are more informative.”<br>
Cognitive interviews reveal ambiguous wording and cultural issues without requiring the large samples needed for statistical reliability indices.</p>
<p><strong>A2. B)</strong> CVR = (6 - 8/2) / (8/2) = (6 - 4) / 4 = 2/4 = 0.50.<br>
“A CVR of 0.50 indicates that 75% of experts deemed the item essential.”</p>
<p><strong>A3. B)</strong> “If most responses cluster at the low or high end, the item cannot differentiate among respondents.”<br>
A ceiling effect occurs when most respondents give the highest possible response, limiting discrimination.</p>
<p><strong>A4. C)</strong> “The corrected item-total correlation (r.drop) indicates how well each item correlates with the total score excluding itself. Values below 0.3 suggest weak items that could be removed.”<br>
Items with r.drop &lt; 0.3 discriminate poorly and are candidates for removal.</p>
<p><strong>A5. A)</strong> “Content validity refers to whether items comprehensively and appropriately represent the construct being measured.”<br>
Content validity is assessed through expert review, not statistical tests.</p>
<p><strong>A6. B)</strong> “Removing items also reduces scale length, which can lower alpha.”<br>
Cronbach’s alpha is mathematically influenced by the number of items—shorter scales tend to have lower alpha even if items are equally good.</p>
<p><strong>A7. B)</strong> “Standard scale development protocols (large pilot studies, factor analysis, item response theory) require hundreds of observations.”<br>
Factor analysis requires large samples (typically 200+) for stable results; small samples yield unreliable factor loadings.</p>
<p><strong>A8. B)</strong> “If an item correlates negatively with the total or with other items, it may be reverse-coded incorrectly or measuring an opposite construct.”<br>
Negative correlations suggest coding errors or conceptual misalignment with the scale.</p>
<p><strong>A9. B)</strong> “Content validity refers to whether items comprehensively and appropriately represent the construct being measured… assessed through expert review and respondent feedback.”<br>
Expert ratings establish content validity by confirming items represent the construct appropriately.</p>
<p><strong>A10. B)</strong> “Item 3 has a restricted range (4–7), which may indicate a ceiling effect.”<br>
Restricted ranges (especially at the high end) indicate ceiling effects that limit the item’s ability to differentiate among respondents.</p>
</div>
</div>
</div>
</section>
<section id="key-takeaways-1" class="level3" data-number="2.2.10">
<h3 data-number="2.2.10" class="anchored" data-anchor-id="key-takeaways-1"><span class="header-section-number">2.2.10</span> Key Takeaways</h3>
<ul>
<li>Measurement quality is critical in small-sample research; unreliable measures reduce power and bias estimates.</li>
<li>Content and face validity are assessed through expert review and respondent feedback, not statistics.</li>
<li>Pilot testing with small samples (n ≈ 20–40) can identify problematic items through item-level descriptive statistics and inter-item correlations.</li>
<li>Items with low variance, weak item-total correlations, or ceiling/floor effects should be revised or removed.</li>
<li>Qualitative methods (cognitive interviews) are valuable when quantitative sample sizes are too small for psychometric analysis.</li>
<li>Iterative refinement and re-testing improve scale quality, even when resources are limited.</li>
</ul>
</section>
<section id="smoke-test-1" class="level3" data-number="2.2.11">
<h3 data-number="2.2.11" class="anchored" data-anchor-id="smoke-test-1"><span class="header-section-number">2.2.11</span> Smoke Test</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run item statistics</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>items_test <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">i1 =</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">15</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>),</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">i2 =</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">15</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>),</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">i3 =</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">15</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(items_test)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>       i1     i2     i3
i1 1.0000 0.2929 0.1743
i2 0.2929 1.0000 0.2581
i3 0.1743 0.2581 1.0000</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="chapter-11.-data-screening-and-diagnostic-checks" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="chapter-11.-data-screening-and-diagnostic-checks"><span class="header-section-number">2.3</span> Chapter 11. Data Screening and Diagnostic Checks</h2>
<section id="learning-objectives-2" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="learning-objectives-2"><span class="header-section-number">2.3.1</span> Learning Objectives</h3>
<p>By the end of this chapter, you will be able to:</p>
<p><strong>Conceptual Understanding</strong> - ✓ Explain how small samples amplify the impact of outliers and anomalies - ✓ Understand univariate vs.&nbsp;multivariate outlier detection approaches - ✓ Recognize the assumptions underlying common diagnostic tests - ✓ Distinguish data entry errors from legitimate extreme values</p>
<p><strong>Practical Skills</strong> - ✓ Detect outliers using z-scores, boxplots, and Mahalanobis distance in R - ✓ Assess normality with Q-Q plots, Shapiro-Wilk tests, and visual diagnostics - ✓ Check linearity and homoscedasticity in regression models - ✓ Calculate leverage and Cook’s D to identify influential observations</p>
<p><strong>Critical Evaluation</strong> - ✓ Assess when outlier removal is justified vs.&nbsp;when it constitutes manipulation - ✓ Evaluate the trade-off between retaining data vs.&nbsp;meeting assumptions - ✓ Critique data screening decisions in published small-sample studies</p>
<p><strong>Application</strong> - ✓ Document data cleaning decisions transparently with decision rules - ✓ Choose between robust methods, transformations, or outlier exclusion - ✓ Report sensitivity analyses showing results with/without outliers</p>
</section>
<section id="why-data-screening-matters-more-with-small-samples" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="why-data-screening-matters-more-with-small-samples"><span class="header-section-number">2.3.2</span> Why Data Screening Matters More with Small Samples</h3>
<p>A single outlier can dominate a mean, distort a correlation, or violate regression assumptions when samples are small. Data entry errors (typos, misplaced decimals, incorrect codes) are harder to detect with fewer observations. Distributional assumptions (normality, homoscedasticity) are harder to verify with small samples, yet violations have greater consequences.</p>
<p>Systematic data screening before analysis helps identify problems early. Document all cleaning and transformation decisions in a reproducible script. Report descriptive statistics, missingness patterns, and any deviations from planned analyses.</p>
</section>
<section id="detecting-outliers" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="detecting-outliers"><span class="header-section-number">2.3.3</span> Detecting Outliers</h3>
<p>Outliers are observations that are unusually large or small relative to the rest of the data. They may represent legitimate extreme values, data entry errors, or individuals from a different population. With small samples, outliers can have disproportionate influence on results.</p>
<p><strong>Methods for detecting outliers</strong>: - Visual inspection: boxplots, histograms, scatterplots. - Numerical criteria: values beyond 1.5 × IQR from the quartiles (Tukey’s fences), or standardised scores (z-scores) beyond ±3. - Influence diagnostics: Cook’s distance, leverage in regression.</p>
<p><strong>When to remove outliers</strong>: Only if there is clear evidence of data entry error or that the observation does not belong to the target population. Document the rationale and report results with and without outliers.</p>
<section id="multivariate-outliers-with-mahalanobis-distance" class="level4" data-number="2.3.3.1">
<h4 data-number="2.3.3.1" class="anchored" data-anchor-id="multivariate-outliers-with-mahalanobis-distance"><span class="header-section-number">2.3.3.1</span> Multivariate Outliers with Mahalanobis Distance</h4>
<p>Univariate rules may miss cases that are unusual only when variables are considered jointly. Mahalanobis distance measures how far an observation lies from the multivariate centre, accounting for covariances among variables. Distances can be compared to a chi-square threshold with degrees of freedom equal to the number of variables.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated bivariate data with one multivariate outlier</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>multi_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">satisfaction =</span> <span class="fu">rnorm</span>(<span class="dv">14</span>, <span class="at">mean =</span> <span class="dv">6</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">wait_time =</span> <span class="fu">rnorm</span>(<span class="dv">14</span>, <span class="at">mean =</span> <span class="dv">10</span>, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(<span class="fu">tibble</span>(<span class="at">satisfaction =</span> <span class="dv">2</span>, <span class="at">wait_time =</span> <span class="dv">18</span>))  <span class="co"># potential outlier</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>center <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(multi_data)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>cov_mat <span class="ot">&lt;-</span> <span class="fu">cov</span>(multi_data)</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>multi_data <span class="ot">&lt;-</span> multi_data <span class="sc">%&gt;%</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">mahal =</span> <span class="fu">mahalanobis</span>(., center, cov_mat),</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">flag =</span> mahal <span class="sc">&gt;</span> <span class="fu">qchisq</span>(<span class="fl">0.975</span>, <span class="at">df =</span> <span class="fu">ncol</span>(multi_data))</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>multi_data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 15 × 4
   satisfaction wait_time   mahal flag 
          &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;lgl&gt;
 1         6.62     12.1   0.838  FALSE
 2         6.04      9.61  0.240  FALSE
 3         6.77      9.90  0.517  FALSE
 4         7.27     10.8   1.44   FALSE
 5         6.37      7.37  1.51   FALSE
 6         5.84     14.9   1.93   FALSE
 7         6.40      9.51  0.311  FALSE
 8         5.92     11.5   0.0320 FALSE
 9         5.66     15.7   2.68   FALSE
10         6.70     11.3   0.625  FALSE
11         5.60      9.77  0.375  FALSE
12         4.24      7.40  5.54   FALSE
13         5.58      8.16  1.45   FALSE
14         6.76     10.1   0.503  FALSE
15         2        18    10.0    TRUE </code></pre>
</div>
</div>
<p>Interpretation: Observations with Mahalanobis distance exceeding the chi-square cutoff (95% or 97.5% quantile) are flagged as multivariate outliers. Inspect the flagged cases individually to determine whether they reflect data errors, rare but valid combinations, or participants from a different subpopulation. Report how thresholds were chosen, as small samples make covariance estimates noisy.</p>
</section>
</section>
<section id="example-outlier-detection-with-boxplots-and-z-scores" class="level3" data-number="2.3.4">
<h3 data-number="2.3.4" class="anchored" data-anchor-id="example-outlier-detection-with-boxplots-and-z-scores"><span class="header-section-number">2.3.4</span> Example: Outlier Detection with Boxplots and Z-Scores</h3>
<p>We examine a small dataset of customer wait times (n = 20) and check for outliers.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated wait times (most between 5–15 minutes, one outlier at 45)</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>wait_times <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">8</span>, <span class="dv">11</span>, <span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">13</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">8</span>, <span class="dv">11</span>, <span class="dv">10</span>, <span class="dv">9</span>, <span class="dv">45</span>, <span class="dv">10</span>)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the data frame</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>wait_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">observation =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">wait_time =</span> wait_times)</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Boxplot</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(wait_data, <span class="fu">aes</span>(<span class="at">y =</span> wait_time)) <span class="sc">+</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_boxplot</span>(<span class="at">fill =</span> <span class="st">"lightblue"</span>) <span class="sc">+</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Boxplot of Wait Times"</span>, <span class="at">y =</span> <span class="st">"Wait Time (minutes)"</span>) <span class="sc">+</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>()</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="part-b-data-collection_files/figure-html/part-b-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Boxplot highlighting a potential customer wait-time outlier.</figcaption>
</figure>
</div>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify outliers using 1.5*IQR rule</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>Q1 <span class="ot">&lt;-</span> <span class="fu">quantile</span>(wait_times, <span class="fl">0.25</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>Q3 <span class="ot">&lt;-</span> <span class="fu">quantile</span>(wait_times, <span class="fl">0.75</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>IQR_val <span class="ot">&lt;-</span> <span class="fu">IQR</span>(wait_times)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>lower_fence <span class="ot">&lt;-</span> Q1 <span class="sc">-</span> <span class="fl">1.5</span> <span class="sc">*</span> IQR_val</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>upper_fence <span class="ot">&lt;-</span> Q3 <span class="sc">+</span> <span class="fl">1.5</span> <span class="sc">*</span> IQR_val</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter to find outliers</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>outliers <span class="ot">&lt;-</span> wait_data <span class="sc">%&gt;%</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(wait_time <span class="sc">&lt;</span> lower_fence <span class="sc">|</span> wait_time <span class="sc">&gt;</span> upper_fence)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"Outliers (1.5*IQR rule):"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Outliers (1.5*IQR rule):"</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(outliers)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
  observation wait_time
        &lt;int&gt;     &lt;dbl&gt;
1          19        45</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Z-scores for outlier identification</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>wait_data <span class="ot">&lt;-</span> wait_data <span class="sc">%&gt;%</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">z_score =</span> (wait_time <span class="sc">-</span> <span class="fu">mean</span>(wait_time)) <span class="sc">/</span> <span class="fu">sd</span>(wait_time))</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter to find extreme values (absolute z-score &gt; 3)</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>extreme <span class="ot">&lt;-</span> wait_data <span class="sc">%&gt;%</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(<span class="fu">abs</span>(z_score) <span class="sc">&gt;</span> <span class="dv">3</span>)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"Extreme values (Z-score &gt; 3):"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Extreme values (Z-score &gt; 3):"</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(extreme)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
  observation wait_time z_score
        &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;
1          19        45    4.17</code></pre>
</div>
</div>
<p>Interpretation: The boxplot visually flags observation 19 (wait time = 45 minutes) as an outlier. The IQR-based rule and z-score criterion both identify this observation. Before removing it, investigate: Is this a data entry error? Could a customer have genuinely waited 45 minutes due to an unusual circumstance? If it is an error, remove it. If it is genuine but atypical, consider reporting results with and without the outlier, or use robust methods (median, rank-based tests) that are less sensitive to extremes.</p>
</section>
<section id="checking-normality" class="level3" data-number="2.3.5">
<h3 data-number="2.3.5" class="anchored" data-anchor-id="checking-normality"><span class="header-section-number">2.3.5</span> Checking Normality</h3>
<p>Many parametric tests assume normally distributed data (or residuals). With small samples, normality is hard to verify formally. Visual checks (histograms, Q-Q plots) are more informative than statistical tests (Shapiro–Wilk), which have low power with small n.</p>
<p>If data are clearly skewed or have heavy tails, consider: - Nonparametric methods (rank-based tests). - Transformations (log, square root) to reduce skewness. - Robust methods (trimmed means, bootstrap).</p>
</section>
<section id="example-q-q-plot-for-normality-assessment" class="level3" data-number="2.3.6">
<h3 data-number="2.3.6" class="anchored" data-anchor-id="example-q-q-plot-for-normality-assessment"><span class="header-section-number">2.3.6</span> Example: Q-Q Plot for Normality Assessment</h3>
<p>We check whether a small sample of test scores (n = 18) is approximately normally distributed.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated test scores (approximately normal)</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>test_scores <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">18</span>, <span class="at">mean =</span> <span class="dv">70</span>, <span class="at">sd =</span> <span class="dv">10</span>))</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Q-Q plot</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(test_scores, <span class="at">main =</span> <span class="st">"Q-Q Plot of Test Scores"</span>)</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(test_scores, <span class="at">col =</span> <span class="st">"red"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="part-b-data-collection_files/figure-html/part-b-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Shapiro-Wilk test</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>shapiro_result <span class="ot">&lt;-</span> <span class="fu">shapiro.test</span>(test_scores)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(shapiro_result)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Shapiro-Wilk normality test

data:  test_scores
W = 0.92, p-value = 0.1</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Shapiro-Wilk p-value:"</span>, <span class="fu">round</span>(shapiro_result<span class="sc">$</span>p.value, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Shapiro-Wilk p-value: 0.147 </code></pre>
</div>
</div>
<p>Interpretation: In a Q-Q plot, points should lie approximately on the diagonal line if data are normally distributed. Deviations at the tails indicate skewness or heavy tails. The Shapiro–Wilk test provides a p-value; p &gt; 0.05 suggests no strong evidence against normality. However, with small samples, the test has low power (may not detect departures) and high variability (can reject normality by chance). Use Q-Q plots as the primary diagnostic, supplemented by the test.</p>
</section>
<section id="linearity-and-homoscedasticity-in-regression" class="level3" data-number="2.3.7">
<h3 data-number="2.3.7" class="anchored" data-anchor-id="linearity-and-homoscedasticity-in-regression"><span class="header-section-number">2.3.7</span> Linearity and Homoscedasticity in Regression</h3>
<p>Linear regression assumes a linear relationship between predictors and outcome, and constant variance of residuals (homoscedasticity). Scatterplots of residuals vs.&nbsp;fitted values help assess these assumptions.</p>
<p><strong>What to look for</strong>: - Linearity: Residuals should be randomly scattered around zero with no clear pattern. Curved patterns suggest non-linearity. - Homoscedasticity: Residual spread should be constant across fitted values. Funnel shapes suggest heteroscedasticity (variance changes with fitted values).</p>
</section>
<section id="example-regression-diagnostics" class="level3" data-number="2.3.8">
<h3 data-number="2.3.8" class="anchored" data-anchor-id="example-regression-diagnostics"><span class="header-section-number">2.3.8</span> Example: Regression Diagnostics</h3>
<p>We fit a simple linear regression (outcome ~ predictor) with n = 20 and check diagnostic plots.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated data</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>reg_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">20</span>, <span class="dv">1</span>, <span class="dv">10</span>),</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="dv">3</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">20</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear model</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> reg_data)</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x, data = reg_data)

Residuals:
   Min     1Q Median     3Q    Max 
-3.802 -0.997 -0.385  1.043  5.501 

Coefficients:
            Estimate Std. Error t value   Pr(&gt;|t|)    
(Intercept)    3.577      1.450    2.47      0.024 *  
x              1.946      0.232    8.40 0.00000012 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.36 on 18 degrees of freedom
Multiple R-squared:  0.797, Adjusted R-squared:  0.785 
F-statistic: 70.5 on 1 and 18 DF,  p-value: 0.000000122</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Diagnostic plots</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="part-b-data-collection_files/figure-html/part-b-chunk-12-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Residuals vs fitted</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model<span class="sc">$</span>fitted.values, model<span class="sc">$</span>residuals, </span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Fitted Values"</span>, <span class="at">ylab =</span> <span class="st">"Residuals"</span>,</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Residuals vs Fitted"</span>)</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="part-b-data-collection_files/figure-html/part-b-chunk-12-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Interpretation: The “Residuals vs Fitted” plot should show random scatter around zero. Patterns (curves, funnels) indicate problems. The Q-Q plot of residuals assesses normality of errors. The “Scale-Location” plot checks homoscedasticity (should be flat). The “Residuals vs Leverage” plot identifies influential observations (high Cook’s distance). With small samples, a single influential point can dominate. Consider removing it if it is an error, or report sensitivity analyses with and without it.</p>
</section>
<section id="identifying-data-entry-errors" class="level3" data-number="2.3.9">
<h3 data-number="2.3.9" class="anchored" data-anchor-id="identifying-data-entry-errors"><span class="header-section-number">2.3.9</span> Identifying Data Entry Errors</h3>
<p>Look for: - Values outside plausible ranges (e.g., age = 150, Likert response = 8 on a 1–7 scale). - Inconsistent codes (e.g., gender coded as 1/2 in some rows, M/F in others). - Duplicate records (same participant ID appearing twice). - Improbable combinations (e.g., primary school student with 20 years of work experience).</p>
<p>Cross-check data against source documents or re-contact participants if errors are suspected.</p>
</section>
<section id="documenting-data-cleaning" class="level3" data-number="2.3.10">
<h3 data-number="2.3.10" class="anchored" data-anchor-id="documenting-data-cleaning"><span class="header-section-number">2.3.10</span> Documenting Data Cleaning</h3>
<p>Maintain a data cleaning script that: - Reads raw data. - Flags potential outliers, errors, or inconsistencies. - Applies corrections or exclusions with justifications. - Produces a cleaned dataset for analysis.</p>
<p>Report the number of observations excluded and reasons. Provide summary statistics for the cleaned data.</p>
</section>
<section id="self-assessment-quiz-2" class="level3" data-number="2.3.11">
<h3 data-number="2.3.11" class="anchored" data-anchor-id="self-assessment-quiz-2"><span class="header-section-number">2.3.11</span> Self-Assessment Quiz</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Chapter 11 Questions
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Q1.</strong> Why are outliers particularly problematic in small-sample research?</p>
<ol type="A">
<li>They are easier to detect visually<br>
</li>
<li>They can have disproportionate influence on results due to the limited number of observations<br>
</li>
<li>Small samples always have more outliers than large samples<br>
</li>
<li>Outliers are impossible to detect with small samples</li>
</ol>
<hr>
<p><strong>Q2.</strong> What is the primary advantage of Mahalanobis distance over univariate outlier detection methods?</p>
<ol type="A">
<li>It is faster to compute<br>
</li>
<li>It measures how far an observation lies from the multivariate centre, accounting for covariances among variables<br>
</li>
<li>It only works with large samples<br>
</li>
<li>It automatically removes all outliers</li>
</ol>
<hr>
<p><strong>Q3.</strong> According to Tukey’s fences method, an observation is flagged as a potential outlier if it falls:</p>
<ol type="A">
<li>Within 1.5 × IQR from the quartiles<br>
</li>
<li>Beyond ±2 standard deviations from the mean<br>
</li>
<li>Beyond 1.5 × IQR from the quartiles<br>
</li>
<li>Exactly at the median</li>
</ol>
<hr>
<p><strong>Q4.</strong> Why are visual diagnostics (Q-Q plots, boxplots) preferred over formal normality tests (Shapiro–Wilk) for small samples?</p>
<ol type="A">
<li>Visual diagnostics are more statistically rigorous<br>
</li>
<li>Normality tests have low power with small samples and may not detect departures; visual checks provide more insight<br>
</li>
<li>Normality tests are too expensive<br>
</li>
<li>Visual diagnostics automatically calculate p-values</li>
</ol>
<hr>
<p><strong>Q5.</strong> In a regression diagnostic plot of “Residuals vs Fitted Values,” what does a funnel-shaped pattern indicate?</p>
<ol type="A">
<li>Perfect homoscedasticity<br>
</li>
<li>Heteroscedasticity—residual variance changes with fitted values<br>
</li>
<li>Normality of residuals<br>
</li>
<li>High collinearity among predictors</li>
</ol>
<hr>
<p><strong>Q6.</strong> What does Cook’s distance measure in regression diagnostics?</p>
<ol type="A">
<li>The distance between two data points<br>
</li>
<li>The influence of each observation on the regression coefficients; high values indicate influential observations<br>
</li>
<li>The correlation between predictors<br>
</li>
<li>The degree of multicollinearity</li>
</ol>
<hr>
<p><strong>Q7.</strong> When should an outlier be removed from analysis?</p>
<ol type="A">
<li>Always, because outliers are bad<br>
</li>
<li>Never, because all data points are valuable<br>
</li>
<li>Only if there is clear evidence of data entry error or the observation does not belong to the target population<br>
</li>
<li>Whenever it makes the results statistically significant</li>
</ol>
<hr>
<p><strong>Q8.</strong> What is an example of a data entry error that should be flagged during data screening?</p>
<ol type="A">
<li>A participant with a high test score<br>
</li>
<li>A Likert response of 8 on a 1–7 scale<br>
</li>
<li>A missing value in a survey<br>
</li>
<li>A participant who completed all questions</li>
</ol>
<hr>
<p><strong>Q9.</strong> Why is documenting data cleaning decisions in a reproducible script important?</p>
<ol type="A">
<li>It allows others to verify exclusions and understand how the cleaned dataset was produced<br>
</li>
<li>It makes the analysis run faster<br>
</li>
<li>It is required by all statistical software<br>
</li>
<li>It prevents missing data from occurring</li>
</ol>
<hr>
<p><strong>Q10.</strong> In a Q-Q plot, if the points deviate substantially from the diagonal line at the tails, what does this suggest?</p>
<ol type="A">
<li>The data are perfectly normally distributed<br>
</li>
<li>The data may have skewness or heavy tails<br>
</li>
<li>The sample size is too large<br>
</li>
<li>There are no outliers present</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Answers and Explanations
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>A1. B)</strong> “With small samples, outliers can have disproportionate influence on results.”<br>
A single extreme value in a sample of 15 can drastically shift means, correlations, and regression slopes.</p>
<p><strong>A2. B)</strong> “Mahalanobis distance measures how far an observation lies from the multivariate centre, accounting for covariances among variables.”<br>
Univariate rules may miss cases that are unusual only when variables are considered jointly.</p>
<p><strong>A3. C)</strong> “Values beyond 1.5 × IQR from the quartiles (Tukey’s fences).”<br>
The lower fence is Q1 - 1.5×IQR; the upper fence is Q3 + 1.5×IQR.</p>
<p><strong>A4. B)</strong> “With small samples, normality is hard to verify formally. Visual checks (histograms, Q-Q plots) are more informative than statistical tests (Shapiro–Wilk), which have low power with small n.”<br>
Normality tests may not detect departures or may reject normality by chance with small samples; Q-Q plots provide direct visual evidence.</p>
<p><strong>A5. B)</strong> “Funnel shapes suggest heteroscedasticity (variance changes with fitted values).”<br>
Homoscedasticity (constant variance) is violated when residual spread increases or decreases with fitted values.</p>
<p><strong>A6. B)</strong> “Cook’s distance [identifies] influential observations.”<br>
High Cook’s distance indicates that removing the observation would substantially change the regression coefficients.</p>
<p><strong>A7. C)</strong> “Only if there is clear evidence of data entry error or that the observation does not belong to the target population. Document the rationale and report results with and without outliers.”<br>
Removing outliers to achieve desired results is unethical; only remove when justified.</p>
<p><strong>A8. B)</strong> “Values outside plausible ranges (e.g., age = 150, Likert response = 8 on a 1–7 scale).”<br>
A response of 8 on a 1–7 scale is impossible and indicates a data entry error.</p>
<p><strong>A9. A)</strong> “Maintain a data cleaning script that: Reads raw data, flags potential outliers, errors, or inconsistencies, applies corrections or exclusions with justifications, produces a cleaned dataset for analysis.”<br>
Reproducible documentation allows verification and transparency.</p>
<p><strong>A10. B)</strong> “Deviations at the tails indicate skewness or heavy tails.”<br>
Points departing from the diagonal at the extremes suggest the distribution has tails that are heavier or lighter than a normal distribution.</p>
</div>
</div>
</div>
</section>
<section id="key-takeaways-2" class="level3" data-number="2.3.12">
<h3 data-number="2.3.12" class="anchored" data-anchor-id="key-takeaways-2"><span class="header-section-number">2.3.12</span> Key Takeaways</h3>
<ul>
<li>Data screening is critical with small samples, where single observations can distort results.</li>
<li>Use visual diagnostics (boxplots, scatterplots, Q-Q plots) to detect outliers, assess normality, and check regression assumptions.</li>
<li>Remove outliers only with clear justification (data entry error, out-of-scope observation); report results with and without.</li>
<li>Normality tests (Shapiro–Wilk) have limited power with small samples; rely primarily on visual checks.</li>
<li>Regression diagnostics (residual plots, leverage, Cook’s distance) identify influential observations and assumption violations.</li>
<li>Document all data cleaning decisions in reproducible scripts and report exclusions transparently.</li>
</ul>
</section>
<section id="smoke-test-2" class="level3" data-number="2.3.13">
<h3 data-number="2.3.13" class="anchored" data-anchor-id="smoke-test-2"><span class="header-section-number">2.3.13</span> Smoke Test</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run outlier detection</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">20</span>)  <span class="co"># 20 is an outlier</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>Q1 <span class="ot">&lt;-</span> <span class="fu">quantile</span>(x, <span class="fl">0.25</span>)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>Q3 <span class="ot">&lt;-</span> <span class="fu">quantile</span>(x, <span class="fl">0.75</span>)</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>IQR_val <span class="ot">&lt;-</span> <span class="fu">IQR</span>(x)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>upper_fence <span class="ot">&lt;-</span> Q3 <span class="sc">+</span> <span class="fl">1.5</span> <span class="sc">*</span> IQR_val</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>x[x <span class="sc">&gt;</span> upper_fence]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 20</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="chapter-12.-handling-missing-data-in-small-samples" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="chapter-12.-handling-missing-data-in-small-samples"><span class="header-section-number">2.4</span> Chapter 12. Handling Missing Data in Small Samples</h2>
<section id="learning-objectives-3" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="learning-objectives-3"><span class="header-section-number">2.4.1</span> Learning Objectives</h3>
<p>By the end of this chapter, you will be able to:</p>
<p><strong>Conceptual Understanding</strong> - ✓ Explain the distinctions between MCAR, MAR, and MNAR mechanisms - ✓ Understand why complete-case analysis can introduce bias - ✓ Recognize the theoretical foundations of multiple imputation (Rubin’s rules) - ✓ Understand the limitations of imputation methods with very small samples</p>
<p><strong>Practical Skills</strong> - ✓ Diagnose missingness patterns using visualization and tests in R - ✓ Implement multiple imputation using the <code>mice</code> package - ✓ Pool parameter estimates and standard errors across imputed datasets - ✓ Generate diagnostic plots (trace plots, convergence checks) for MICE</p>
<p><strong>Critical Evaluation</strong> - ✓ Assess when multiple imputation is feasible vs.&nbsp;when complete-case is preferable - ✓ Evaluate the plausibility of MAR assumptions in research contexts - ✓ Critique missing data handling approaches in published small-sample studies</p>
<p><strong>Application</strong> - ✓ Report missing data patterns and mechanisms transparently - ✓ Choose appropriate imputation strategies given sample size and missingness - ✓ Conduct sensitivity analyses comparing complete-case vs.&nbsp;imputed results</p>
</section>
<section id="the-challenge-of-missing-data-in-small-samples" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="the-challenge-of-missing-data-in-small-samples"><span class="header-section-number">2.4.2</span> The Challenge of Missing Data in Small Samples</h3>
<p>Missing data are common in applied research. Participants skip survey questions, drop out of longitudinal studies, or provide incomplete records. With large samples, modern methods (multiple imputation, full information maximum likelihood) can handle substantial missingness without excessive bias. With small samples, however, missing data pose severe problems. Even a few missing observations can substantially reduce effective sample size and statistical power.</p>
<p>Missing data methods rely on large-sample asymptotics and may be unstable or inappropriate when samples are very small (n &lt; 30) or missingness is extensive (&gt; 20%). In such cases, prevention (minimise missingness through careful design) and transparency (report missingness patterns and sensitivity analyses) are more important than sophisticated imputation.</p>
</section>
<section id="types-of-missingness" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="types-of-missingness"><span class="header-section-number">2.4.3</span> Types of Missingness</h3>
<ul>
<li><strong>MCAR (Missing Completely At Random)</strong>: Missingness is unrelated to any observed or unobserved variables. For example, a survey page is randomly skipped due to a software glitch. MCAR is rare in practice.</li>
<li><strong>MAR (Missing At Random)</strong>: Missingness is related to observed variables but not to the missing values themselves. For example, older participants are more likely to skip a technology question, but conditional on age, missingness is random. Most missing data methods assume MAR.</li>
<li><strong>MNAR (Missing Not At Random)</strong>: Missingness is related to the unobserved values themselves. For example, individuals with high depression scores are more likely to drop out of a study. MNAR is the most problematic and requires sensitivity analyses or models for the missingness mechanism.</li>
</ul>
</section>
<section id="describing-missingness-patterns" class="level3" data-number="2.4.4">
<h3 data-number="2.4.4" class="anchored" data-anchor-id="describing-missingness-patterns"><span class="header-section-number">2.4.4</span> Describing Missingness Patterns</h3>
<p>Before handling missing data, describe the pattern:</p>
<ul>
<li>How many observations have missing values on each variable?</li>
<li>Are missing values concentrated in certain individuals or certain variables?</li>
<li>Is missingness related to observed variables (compare characteristics of complete vs.&nbsp;incomplete cases)?</li>
</ul>
</section>
<section id="example-dataset-for-diagnostics" class="level3" data-number="2.4.5">
<h3 data-number="2.4.5" class="anchored" data-anchor-id="example-dataset-for-diagnostics"><span class="header-section-number">2.4.5</span> Example Dataset for Diagnostics</h3>
<p>To demonstrate the diagnostics in this chapter, we simulate a small dataset with missing values on <code>satisfaction</code> and <code>performance</code>.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>study_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">participant =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">25</span>,</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">age =</span> <span class="fu">sample</span>(<span class="dv">20</span><span class="sc">:</span><span class="dv">60</span>, <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>),</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">satisfaction =</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">7</span>, <span class="cn">NA</span>), <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.15</span>, <span class="fl">0.2</span>, <span class="fl">0.25</span>, <span class="fl">0.2</span>, <span class="fl">0.15</span>, <span class="fl">0.05</span>)),</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">performance =</span> <span class="fu">c</span>(<span class="fu">sample</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">90</span>, <span class="dv">20</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>), <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="dv">5</span>))</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(study_data)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 25
Columns: 4
$ participant  &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…
$ age          &lt;int&gt; 32, 31, 55, 45, 20, 42, 29, 32, 31, 23, 46, 42, 42, 30, 5…
$ satisfaction &lt;int&gt; 4, 7, 3, 7, NA, 7, 3, 5, 6, 6, 5, 3, 5, 5, 6, 4, 4, 6, 3,…
$ performance  &lt;int&gt; 65, 71, 67, 66, 66, 89, 74, 87, 53, 73, 54, 83, 78, 54, 6…</code></pre>
</div>
</div>
</section>
<section id="testing-the-mcar-assumption" class="level3" data-number="2.4.6">
<h3 data-number="2.4.6" class="anchored" data-anchor-id="testing-the-mcar-assumption"><span class="header-section-number">2.4.6</span> Testing the MCAR Assumption</h3>
<p>Little’s MCAR test evaluates whether missingness is consistent with the MCAR mechanism. The test compares observed means across missing-data patterns; a large p-value suggests MCAR is plausible, whereas a small p-value indicates that missingness likely depends on observed data (i.e., not MCAR).</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test if data are Missing Completely At Random (MCAR)</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(naniar)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Little's MCAR test</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mcar_test</span>(study_data)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 4
  statistic    df p.value missing.patterns
      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;            &lt;int&gt;
1      19.8     8  0.0113                4</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Interpretation:</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="co"># p &gt; 0.05: Data consistent with MCAR (missingness random)</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="co"># p &lt; 0.05: Evidence against MCAR (missingness not random)</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualise missing data patterns</span></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="fu">gg_miss_var</span>(study_data, <span class="at">show_pct =</span> <span class="cn">TRUE</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="part-b-data-collection_files/figure-html/part-b-chunk-15-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vis_miss</span>(study_data)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="part-b-data-collection_files/figure-html/part-b-chunk-15-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Little’s MCAR test assesses whether missing data patterns are completely random. However, with small samples (n &lt; 50), this test has low power and should be supplemented with:</p>
<ol type="1">
<li>Visual inspection of missingness patterns</li>
<li>Comparison of complete vs.&nbsp;incomplete cases</li>
<li>Domain knowledge about likely mechanisms</li>
</ol>
</section>
<section id="example-summarising-missing-data" class="level3" data-number="2.4.7">
<h3 data-number="2.4.7" class="anchored" data-anchor-id="example-summarising-missing-data"><span class="header-section-number">2.4.7</span> Example: Summarising Missing Data</h3>
<p>We continue working with the simulated dataset (<code>study_data</code>) created above.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Count missing values per variable</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>missing_summary <span class="ot">&lt;-</span> study_data <span class="sc">%&gt;%</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), <span class="sc">~</span> <span class="fu">sum</span>(<span class="fu">is.na</span>(.))))</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(missing_summary)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 4
  participant   age satisfaction performance
        &lt;int&gt; &lt;int&gt;        &lt;int&gt;       &lt;int&gt;
1           0     0            2           5</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Proportion missing</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>prop_missing <span class="ot">&lt;-</span> study_data <span class="sc">%&gt;%</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), <span class="sc">~</span> <span class="fu">mean</span>(<span class="fu">is.na</span>(.))))</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(prop_missing)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 4
  participant   age satisfaction performance
        &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;
1           0     0         0.08         0.2</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare complete vs incomplete cases</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>study_data <span class="ot">&lt;-</span> study_data <span class="sc">%&gt;%</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">complete =</span> <span class="fu">complete.cases</span>(study_data))</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>complete_vs_incomplete <span class="ot">&lt;-</span> study_data <span class="sc">%&gt;%</span></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(complete) <span class="sc">%&gt;%</span></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mean_age =</span> <span class="fu">mean</span>(age, <span class="at">na.rm =</span> <span class="cn">TRUE</span>), <span class="at">.groups =</span> <span class="st">"drop"</span>)</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(complete_vs_incomplete)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 2
  complete mean_age
  &lt;lgl&gt;       &lt;dbl&gt;
1 FALSE        31  
2 TRUE         40.5</code></pre>
</div>
</div>
<p>Interpretation: The summary shows that <code>satisfaction</code> has 1–2 missing values and <code>performance</code> has 5 missing values (20% of the sample). If complete and incomplete cases differ systematically (e.g., incomplete cases are older), missingness may be MAR or MNAR. If they are similar, missingness may be closer to MCAR. With 20% missingness and n = 25, only 20 cases remain in a complete-case analysis (listwise deletion), reducing power substantially.</p>
</section>
<section id="complete-case-listwise-deletion-analysis" class="level3" data-number="2.4.8">
<h3 data-number="2.4.8" class="anchored" data-anchor-id="complete-case-listwise-deletion-analysis"><span class="header-section-number">2.4.8</span> Complete-Case (Listwise Deletion) Analysis</h3>
<p>The simplest approach is to analyse only cases with complete data on all variables of interest. This is valid if missingness is MCAR and the reduction in sample size is tolerable. However, it can introduce bias if missingness is MAR or MNAR, and it wastes information.</p>
<p><strong>When to use</strong>: Missingness is minimal (&lt; 5%), or MCAR is plausible, or imputation methods are infeasible due to very small sample size.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>⚠️ Common Misconception: “Listwise Deletion Is Always Safe if Missingness Is Random”
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Myth</strong>: “If I check for MCAR and the test is non-significant, listwise deletion is unbiased.”</p>
<p><strong>Reality</strong>: Even when missingness is <strong>truly MCAR</strong>, listwise deletion <strong>loses power</strong> and can introduce bias if you have multiple variables with independent missing patterns.</p>
<p><strong>Demonstration</strong>:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate complete data: n=50, correlation between x and y = 0.6</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="dv">50</span>, <span class="dv">10</span>)</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fl">0.6</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">8</span>)</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a><span class="co"># True correlation (no missing data)</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>true_cor <span class="ot">&lt;-</span> <span class="fu">cor</span>(x, y)</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"True correlation (complete data):"</span>, <span class="fu">round</span>(true_cor, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>True correlation (complete data): 0.549 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Introduce MCAR missingness (20% on x, 20% on y, independently)</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>x_missing <span class="ot">&lt;-</span> x</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>y_missing <span class="ot">&lt;-</span> y</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>x_missing[<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="dv">10</span>)] <span class="ot">&lt;-</span> <span class="cn">NA</span>  <span class="co"># 20% missing</span></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>y_missing[<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="dv">10</span>)] <span class="ot">&lt;-</span> <span class="cn">NA</span>  <span class="co"># 20% missing</span></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Listwise deletion: only cases with both x and y</span></span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>complete_cases <span class="ot">&lt;-</span> <span class="fu">complete.cases</span>(x_missing, y_missing)</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Complete cases:"</span>, <span class="fu">sum</span>(complete_cases), <span class="st">"/"</span>, n, <span class="st">"("</span>, </span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">round</span>(<span class="dv">100</span> <span class="sc">*</span> <span class="fu">mean</span>(complete_cases), <span class="dv">1</span>), <span class="st">"%)</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Complete cases: 33 / 50 ( 66 %)</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation with listwise deletion</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>listwise_cor <span class="ot">&lt;-</span> <span class="fu">cor</span>(x_missing[complete_cases], y_missing[complete_cases])</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Correlation (listwise deletion):"</span>, <span class="fu">round</span>(listwise_cor, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Correlation (listwise deletion): 0.548 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Power loss</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">→ Lost"</span>, n <span class="sc">-</span> <span class="fu">sum</span>(complete_cases), <span class="st">"cases ("</span>, </span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">round</span>(<span class="dv">100</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">mean</span>(complete_cases)), <span class="dv">1</span>), <span class="st">"% of data)</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
→ Lost 17 cases ( 34 % of data)</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"→ Correlation estimate is based on n ="</span>, <span class="fu">sum</span>(complete_cases), </span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"instead of n = 50</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>→ Correlation estimate is based on n = 33 instead of n = 50</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"→ Standard error is"</span>, <span class="fu">round</span>(<span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">/</span><span class="fu">sum</span>(complete_cases)) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">/</span>n), <span class="dv">2</span>), </span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"times larger</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>→ Standard error is 1.23 times larger</code></pre>
</div>
</div>
<p><strong>Why this matters:</strong></p>
<ol type="1">
<li><strong>Power loss</strong>: With 20% missing on x and 20% on y (independent), you lose ~36% of cases
<ul>
<li>Formula: (1 - p_x) × (1 - p_y) = 0.8 × 0.8 = 0.64 → 64% remain, 36% lost</li>
</ul></li>
<li><strong>Multiple variables compound</strong>: With 5 variables each 15% missing, you keep only 44% of cases</li>
<li><strong>Bias can still occur</strong>: If missingness is MAR (not MCAR), listwise deletion is biased</li>
</ol>
<p><strong>Lesson</strong>:</p>
<ul>
<li><strong>MCAR does NOT mean listwise deletion is optimal</strong>—it’s still wasteful</li>
<li>Use <strong>multiple imputation</strong> even with MCAR if missingness &gt; 10%</li>
<li>With small samples (n &lt; 50), losing even 20% of cases is catastrophic for power</li>
</ul>
<p><strong>When listwise deletion is actually safe:</strong></p>
<ul>
<li>Missingness &lt; 5% on any variable</li>
<li>n is large enough that losing cases doesn’t hurt power</li>
<li>You’ve verified MCAR (not just MAR) AND documented the power loss</li>
</ul>
</div>
</div>
</section>
<section id="mean-imputation-not-recommended" class="level3" data-number="2.4.9">
<h3 data-number="2.4.9" class="anchored" data-anchor-id="mean-imputation-not-recommended"><span class="header-section-number">2.4.9</span> Mean Imputation (Not Recommended)</h3>
<p>Mean imputation replaces missing values with the variable mean. This approach artificially reduces variance and distorts correlations. It is generally not recommended, especially with small samples where each imputed value has disproportionate impact.</p>
<p><strong>When to use</strong>: Rarely. Only if missingness is trivial (1–2 values in a large dataset) and for descriptive purposes only (not inference).</p>
</section>
<section id="last-observation-carried-forward-locf" class="level3" data-number="2.4.10">
<h3 data-number="2.4.10" class="anchored" data-anchor-id="last-observation-carried-forward-locf"><span class="header-section-number">2.4.10</span> Last Observation Carried Forward (LOCF)</h3>
<p>In longitudinal studies, LOCF replaces missing follow-up values with the last observed value for that individual. This assumes no change after the last observation, which is often unrealistic. LOCF can bias estimates and is not generally recommended.</p>
<p><strong>When to use</strong>: Rarely. Only if the assumption of no change is plausible, and alternatives are infeasible.</p>
</section>
<section id="multiple-imputation-caution-with-small-samples" class="level3" data-number="2.4.11">
<h3 data-number="2.4.11" class="anchored" data-anchor-id="multiple-imputation-caution-with-small-samples"><span class="header-section-number">2.4.11</span> Multiple Imputation (Caution with Small Samples)</h3>
<p>Multiple imputation (MI) generates several plausible imputed datasets, analyses each separately, and pools results to account for imputation uncertainty. MI is the gold standard for handling missing data in large samples. However, MI requires sufficient data to estimate imputation models reliably. With very small samples (n &lt; 30) or many missing values (&gt; 20%), MI can be unstable or yield implausible imputations.</p>
<p><strong>When to use</strong>: Moderate sample sizes (n ≥ 30), missingness not too extensive (&lt; 20%), MAR assumption plausible.</p>
</section>
<section id="example-multiple-imputation-with-mice-caution" class="level3" data-number="2.4.12">
<h3 data-number="2.4.12" class="anchored" data-anchor-id="example-multiple-imputation-with-mice-caution"><span class="header-section-number">2.4.12</span> Example: Multiple Imputation with mice (Caution)</h3>
<p>We apply MI to the dataset with missing <code>satisfaction</code> and <code>performance</code> values. Given the small sample (n = 25) and 20% missingness, interpret results cautiously.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiple imputation requires the 'mice' package</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">requireNamespace</span>(<span class="st">"mice"</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(mice)</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Remove 'complete' indicator variable before imputation</span></span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>  impute_data <span class="ot">&lt;-</span> study_data <span class="sc">%&gt;%</span> <span class="fu">select</span>(participant, age, satisfaction, performance)</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Perform multiple imputation (m = 5 imputations)</span></span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>  imp <span class="ot">&lt;-</span> <span class="fu">mice</span>(impute_data, <span class="at">m =</span> <span class="dv">5</span>, <span class="at">method =</span> <span class="st">"pmm"</span>, <span class="at">printFlag =</span> <span class="cn">FALSE</span>)</span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Check imputed values</span></span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(imp)</span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Example analysis: regress performance on age and satisfaction</span></span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">with</span>(imp, <span class="fu">lm</span>(performance <span class="sc">~</span> age <span class="sc">+</span> satisfaction))</span>
<span id="cb73-17"><a href="#cb73-17" aria-hidden="true" tabindex="-1"></a>  pooled <span class="ot">&lt;-</span> <span class="fu">pool</span>(fit)</span>
<span id="cb73-18"><a href="#cb73-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>(pooled)</span>
<span id="cb73-19"><a href="#cb73-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb73-20"><a href="#cb73-20" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb73-21"><a href="#cb73-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"Install 'mice' package to run multiple imputation.</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb73-22"><a href="#cb73-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"With very small samples, MI may be unstable; consider complete-case analysis.</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb73-23"><a href="#cb73-23" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Class: mids
Number of multiple imputations:  5 
Imputation methods:
 participant          age satisfaction  performance 
          ""           ""        "pmm"        "pmm" 
PredictorMatrix:
             participant age satisfaction performance
participant            0   1            1           1
age                    1   0            1           1
satisfaction           1   1            0           1
performance            1   1            1           0</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>          term estimate std.error statistic    df   p.value
1  (Intercept) 87.84881   15.4415    5.6892 11.10 0.0001355
2          age -0.09038    0.2349   -0.3847 16.72 0.7052925
3 satisfaction -2.22444    2.0767   -1.0711 12.55 0.3042733</code></pre>
</div>
</div>
<p>Interpretation: MI generates plausible values for missing data based on observed relationships. The pooled results combine estimates across imputations, with standard errors adjusted for imputation uncertainty. However, with n = 25 and 20% missingness, the imputation model is estimated from limited data, and results may be unstable. Compare MI results to complete-case analysis; if they differ substantially, report both and acknowledge uncertainty.</p>
</section>
<section id="checking-convergence-of-multiple-imputation" class="level3" data-number="2.4.13">
<h3 data-number="2.4.13" class="anchored" data-anchor-id="checking-convergence-of-multiple-imputation"><span class="header-section-number">2.4.13</span> Checking Convergence of Multiple Imputation</h3>
<p>When using <code>mice</code>, always check whether the imputation algorithm has converged. Poor convergence means the imputed values may not be stable, especially with small samples or complex missing data patterns.</p>
<p><strong>Key diagnostics:</strong></p>
<ol type="1">
<li><strong>Trace plots</strong>: Plot imputed values across iterations for each variable. Lines should mix well without trends.</li>
<li><strong>Strip plots</strong>: Display distributions of observed (blue) vs.&nbsp;imputed (red) values. Distributions should be similar if MAR holds.</li>
</ol>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convergence diagnostics for mice imputation</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">requireNamespace</span>(<span class="st">"mice"</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>) <span class="sc">&amp;&amp;</span> <span class="fu">exists</span>(<span class="st">"imp"</span>)) {</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(mice)</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Trace plots: check convergence across iterations</span></span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Each line represents one imputed dataset; should be well-mixed</span></span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(imp, <span class="fu">c</span>(<span class="st">"satisfaction"</span>, <span class="st">"performance"</span>))</span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Strip plots: compare observed (blue) vs imputed (red) values</span></span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Distributions should be similar under MAR</span></span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stripplot</span>(imp, satisfaction <span class="sc">+</span> performance <span class="sc">~</span> .imp, <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">cex =</span> <span class="fl">1.2</span>)</span>
<span id="cb76-12"><a href="#cb76-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb76-13"><a href="#cb76-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">=== Convergence Check ===</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb76-14"><a href="#cb76-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"✓ Trace plots: Lines should mix well without systematic trends</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb76-15"><a href="#cb76-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"✓ Strip plots: Imputed (red) should resemble observed (blue) distributions</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb76-16"><a href="#cb76-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"✓ If convergence looks poor, increase iterations: mice(..., maxit = 20)</span><span class="sc">\n\n</span><span class="st">"</span>)</span>
<span id="cb76-17"><a href="#cb76-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb76-18"><a href="#cb76-18" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb76-19"><a href="#cb76-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"mice imputation object not found; run the previous chunk first.</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb76-20"><a href="#cb76-20" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
=== Convergence Check ===
✓ Trace plots: Lines should mix well without systematic trends
✓ Strip plots: Imputed (red) should resemble observed (blue) distributions
✓ If convergence looks poor, increase iterations: mice(..., maxit = 20)</code></pre>
</div>
</div>
<p><strong>What to look for:</strong></p>
<ul>
<li><strong>Trace plots</strong>: Each imputation should show relatively stable values across iterations. If you see upward or downward trends, the algorithm hasn’t converged. Solution: increase <code>maxit</code> (default is 5).</li>
<li><strong>Strip plots</strong>: The distribution of imputed values (red) should be similar to observed values (blue). Large differences suggest the imputation model may not fit well or MNAR may be present.</li>
</ul>
<p><strong>With small samples (n &lt; 30)</strong>, convergence can be slower and more sensitive to model specification. If diagnostics show problems, consider:</p>
<ul>
<li>Simplifying the imputation model (use predictive mean matching with fewer predictors)</li>
<li>Increasing iterations (<code>maxit = 20</code> or more)</li>
<li>Comparing to complete-case analysis as a sensitivity check</li>
</ul>
</section>
<section id="sensitivity-analyses" class="level3" data-number="2.4.14">
<h3 data-number="2.4.14" class="anchored" data-anchor-id="sensitivity-analyses"><span class="header-section-number">2.4.14</span> Sensitivity Analyses</h3>
<p>When missingness is substantial or MNAR is suspected, conduct sensitivity analyses:</p>
<ul>
<li>Compare complete-case results to imputed results.</li>
<li>Vary assumptions about the missing data mechanism (e.g., impute extreme values to simulate worst-case scenarios).</li>
<li>Report results under multiple scenarios and discuss implications.</li>
</ul>
</section>
<section id="preventing-missing-data" class="level3" data-number="2.4.15">
<h3 data-number="2.4.15" class="anchored" data-anchor-id="preventing-missing-data"><span class="header-section-number">2.4.15</span> Preventing Missing Data</h3>
<p>The best approach to missing data is prevention:</p>
<ul>
<li>Design clear, concise instruments.</li>
<li>Minimise respondent burden.</li>
<li>Follow up with participants who miss appointments or skip questions.</li>
<li>Pilot test procedures to identify confusing or burdensome items.</li>
<li>Build rapport and trust with participants.</li>
</ul>
<hr>
</section>
</section>
<section id="chapter-12.5.-assessing-multiple-imputation-quality" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="chapter-12.5.-assessing-multiple-imputation-quality"><span class="header-section-number">2.5</span> Chapter 12.5. Assessing Multiple Imputation Quality</h2>
<section id="learning-objectives-4" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1" class="anchored" data-anchor-id="learning-objectives-4"><span class="header-section-number">2.5.1</span> Learning Objectives</h3>
<p>By the end of this section, you will understand how to diagnose the quality of multiple imputation models. You will learn to check convergence, compare imputed vs.&nbsp;observed distributions, assess sensitivity to the number of imputations (m), and interpret diagnostic plots. These skills ensure that your imputed datasets are appropriate for downstream analyses.</p>
</section>
<section id="why-imputation-diagnostics-matter" class="level3" data-number="2.5.2">
<h3 data-number="2.5.2" class="anchored" data-anchor-id="why-imputation-diagnostics-matter"><span class="header-section-number">2.5.2</span> Why Imputation Diagnostics Matter</h3>
<p>Multiple imputation (MI) is not a “black box” procedure. The quality of imputed values depends on:</p>
<ol type="1">
<li><strong>Model specification</strong>: Are the imputation models correctly specified (e.g., predictive mean matching, logistic regression for binary variables)?</li>
<li><strong>Convergence</strong>: Have the iterative algorithms stabilised?</li>
<li><strong>Plausibility</strong>: Do imputed values resemble the observed data distribution?</li>
<li><strong>Sensitivity to m</strong>: Are pooled estimates stable across different numbers of imputations?</li>
</ol>
<p><strong>Failure to check diagnostics</strong> can lead to:</p>
<ul>
<li>Biased parameter estimates</li>
<li>Incorrect standard errors</li>
<li>Imputed values outside plausible ranges</li>
<li>Overconfidence in results</li>
</ul>
</section>
<section id="diagnostic-1-convergence-checks" class="level3" data-number="2.5.3">
<h3 data-number="2.5.3" class="anchored" data-anchor-id="diagnostic-1-convergence-checks"><span class="header-section-number">2.5.3</span> Diagnostic 1: Convergence Checks</h3>
<p>The <code>mice</code> algorithm uses <strong>iterative chained equations</strong>: it cycles through variables, updating imputations based on the current values of other variables. Convergence occurs when these iterations stabilise (no systematic trends).</p>
<section id="trace-plots" class="level4" data-number="2.5.3.1">
<h4 data-number="2.5.3.1" class="anchored" data-anchor-id="trace-plots"><span class="header-section-number">2.5.3.1</span> Trace Plots</h4>
<p>Trace plots show the mean and SD of imputed values across iterations for each variable. <strong>Good convergence</strong> looks like:</p>
<ul>
<li>Lines are “noisy” (random fluctuation)</li>
<li>No systematic trends (upward or downward drift)</li>
<li>Multiple chains (from different imputations) intermingle</li>
</ul>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mice)</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate data with missing values</span></span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>mi_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">age =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">32</span>, <span class="cn">NA</span>, <span class="dv">45</span>, <span class="dv">29</span>, <span class="cn">NA</span>, <span class="dv">38</span>, <span class="dv">41</span>, <span class="dv">27</span>, <span class="dv">35</span>, <span class="cn">NA</span>, <span class="dv">42</span>, <span class="dv">30</span>, <span class="dv">28</span>, <span class="dv">39</span>),</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">satisfaction =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="cn">NA</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="cn">NA</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="cn">NA</span>, <span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">3</span>),</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">income =</span> <span class="fu">c</span>(<span class="dv">35</span>, <span class="dv">50</span>, <span class="dv">42</span>, <span class="dv">60</span>, <span class="cn">NA</span>, <span class="dv">55</span>, <span class="dv">48</span>, <span class="cn">NA</span>, <span class="dv">40</span>, <span class="dv">52</span>, <span class="dv">45</span>, <span class="dv">58</span>, <span class="cn">NA</span>, <span class="dv">38</span>, <span class="dv">49</span>)</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiple imputation with more iterations to demonstrate convergence</span></span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a>imp <span class="ot">&lt;-</span> <span class="fu">mice</span>(mi_data, <span class="at">m =</span> <span class="dv">5</span>, <span class="at">maxit =</span> <span class="dv">20</span>, <span class="at">seed =</span> <span class="dv">2025</span>, <span class="at">print =</span> <span class="cn">FALSE</span>)</span>
<span id="cb78-14"><a href="#cb78-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-15"><a href="#cb78-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot trace lines for all variables</span></span>
<span id="cb78-16"><a href="#cb78-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(imp, <span class="fu">c</span>(<span class="st">"age"</span>, <span class="st">"satisfaction"</span>, <span class="st">"income"</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="part-b-data-collection_files/figure-html/part-b-mi-diag-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Interpretation</strong>:</p>
<ul>
<li><strong>Ideal</strong>: Lines fluctuate randomly around a stable mean (like a “fuzzy caterpillar”)</li>
<li><strong>Problem</strong>: Lines show trends (increasing or decreasing over iterations) → <strong>increase <code>maxit</code></strong></li>
<li><strong>Problem</strong>: Lines are smooth or separated by chain → <strong>check imputation model specification</strong></li>
</ul>
</section>
<section id="checking-specific-variables" class="level4" data-number="2.5.3.2">
<h4 data-number="2.5.3.2" class="anchored" data-anchor-id="checking-specific-variables"><span class="header-section-number">2.5.3.2</span> Checking Specific Variables</h4>
<p>If you have many variables, focus on those with the most missingness:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Focus on specific variables with high missingness</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(imp, <span class="st">"age"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="part-b-data-collection_files/figure-html/part-b-mi-diag-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>When to increase iterations</strong>:</p>
<ul>
<li>If you see trends in the first 10–20 iterations, try <code>maxit = 50</code> or <code>maxit = 100</code></li>
<li>Modern guidance: <code>maxit = 20–50</code> is usually sufficient for MCAR/MAR data</li>
</ul>
</section>
</section>
<section id="diagnostic-2-imputed-vs.-observed-distributions" class="level3" data-number="2.5.4">
<h3 data-number="2.5.4" class="anchored" data-anchor-id="diagnostic-2-imputed-vs.-observed-distributions"><span class="header-section-number">2.5.4</span> Diagnostic 2: Imputed vs.&nbsp;Observed Distributions</h3>
<p>Imputed values should <strong>resemble</strong> the observed data distribution (but not be identical). Large discrepancies suggest model misspecification.</p>
<section id="density-plots" class="level4" data-number="2.5.4.1">
<h4 data-number="2.5.4.1" class="anchored" data-anchor-id="density-plots"><span class="header-section-number">2.5.4.1</span> Density Plots</h4>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare density plots: blue = observed, red = imputed</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="fu">densityplot</span>(imp)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="part-b-data-collection_files/figure-html/part-b-mi-diag-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Interpretation</strong>:</p>
<ul>
<li><strong>Good</strong>: Imputed (red) and observed (blue) distributions overlap substantially</li>
<li><strong>Red flag</strong>: Imputed values are all at one value (e.g., the mean) → model too restrictive (try <code>method = "pmm"</code> for predictive mean matching)</li>
<li><strong>Red flag</strong>: Imputed values fall far outside observed range → model misspecified (e.g., using linear imputation for bounded variables)</li>
</ul>
</section>
<section id="strip-plots-univariate" class="level4" data-number="2.5.4.2">
<h4 data-number="2.5.4.2" class="anchored" data-anchor-id="strip-plots-univariate"><span class="header-section-number">2.5.4.2</span> Strip Plots (Univariate)</h4>
<p>Strip plots show individual imputed values (red) alongside observed values (blue):</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Strip plots for each variable</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="fu">stripplot</span>(imp, age <span class="sc">~</span> .imp, <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">cex =</span> <span class="fl">1.5</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="part-b-data-collection_files/figure-html/part-b-mi-diag-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Interpretation</strong>:</p>
<ul>
<li>Imputed values (red dots) should “fill in” gaps in the observed data (blue dots)</li>
<li>Look for outliers: Are any imputed values far outside the observed range?</li>
</ul>
</section>
</section>
<section id="diagnostic-3-sensitivity-to-m-number-of-imputations" class="level3" data-number="2.5.5">
<h3 data-number="2.5.5" class="anchored" data-anchor-id="diagnostic-3-sensitivity-to-m-number-of-imputations"><span class="header-section-number">2.5.5</span> Diagnostic 3: Sensitivity to m (Number of Imputations)</h3>
<p>The number of imputations (m) affects the precision of pooled estimates. With more imputations, pooled estimates become more stable and standard errors more accurate.</p>
<section id="rule-of-thumb-for-m" class="level4" data-number="2.5.5.1">
<h4 data-number="2.5.5.1" class="anchored" data-anchor-id="rule-of-thumb-for-m"><span class="header-section-number">2.5.5.1</span> Rule of Thumb for m</h4>
<ul>
<li><strong>Fraction of missing information (FMI)</strong> determines required m:
<ul>
<li>FMI &lt; 10%: m = 5–10 sufficient</li>
<li>FMI = 10–30%: m = 20 recommended</li>
<li>FMI &gt; 30%: m = 50–100 may be needed</li>
</ul></li>
<li><strong>White, Royston, and Wood (2011)</strong> suggest: <span class="math inline">\(m \geq 100 \times \text{FMI}\)</span></li>
</ul>
</section>
<section id="testing-sensitivity" class="level4" data-number="2.5.5.2">
<h4 data-number="2.5.5.2" class="anchored" data-anchor-id="testing-sensitivity"><span class="header-section-number">2.5.5.2</span> Testing Sensitivity</h4>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate larger dataset for demonstration</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>mi_data_large <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">age =</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">25</span><span class="sc">:</span><span class="dv">50</span>, <span class="cn">NA</span>), <span class="dv">50</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="fl">0.03</span>, <span class="dv">26</span>), <span class="fl">0.22</span>)),</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">income =</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">30</span><span class="sc">:</span><span class="dv">70</span>, <span class="cn">NA</span>), <span class="dv">50</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="fl">0.024</span>, <span class="dv">41</span>), <span class="fl">0.02</span>)),</span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">satisfaction =</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="cn">NA</span>), <span class="dv">50</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="fl">0.18</span>, <span class="dv">5</span>), <span class="fl">0.1</span>))</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute with varying m</span></span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a>imp_m5 <span class="ot">&lt;-</span> <span class="fu">mice</span>(mi_data_large, <span class="at">m =</span> <span class="dv">5</span>, <span class="at">maxit =</span> <span class="dv">20</span>, <span class="at">seed =</span> <span class="dv">2025</span>, <span class="at">print =</span> <span class="cn">FALSE</span>)</span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>imp_m20 <span class="ot">&lt;-</span> <span class="fu">mice</span>(mi_data_large, <span class="at">m =</span> <span class="dv">20</span>, <span class="at">maxit =</span> <span class="dv">20</span>, <span class="at">seed =</span> <span class="dv">2025</span>, <span class="at">print =</span> <span class="cn">FALSE</span>)</span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>imp_m50 <span class="ot">&lt;-</span> <span class="fu">mice</span>(mi_data_large, <span class="at">m =</span> <span class="dv">50</span>, <span class="at">maxit =</span> <span class="dv">20</span>, <span class="at">seed =</span> <span class="dv">2025</span>, <span class="at">print =</span> <span class="cn">FALSE</span>)</span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-14"><a href="#cb82-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model and pool results</span></span>
<span id="cb82-15"><a href="#cb82-15" aria-hidden="true" tabindex="-1"></a>fit_m5 <span class="ot">&lt;-</span> <span class="fu">with</span>(imp_m5, <span class="fu">lm</span>(satisfaction <span class="sc">~</span> age <span class="sc">+</span> income))</span>
<span id="cb82-16"><a href="#cb82-16" aria-hidden="true" tabindex="-1"></a>fit_m20 <span class="ot">&lt;-</span> <span class="fu">with</span>(imp_m20, <span class="fu">lm</span>(satisfaction <span class="sc">~</span> age <span class="sc">+</span> income))</span>
<span id="cb82-17"><a href="#cb82-17" aria-hidden="true" tabindex="-1"></a>fit_m50 <span class="ot">&lt;-</span> <span class="fu">with</span>(imp_m50, <span class="fu">lm</span>(satisfaction <span class="sc">~</span> age <span class="sc">+</span> income))</span>
<span id="cb82-18"><a href="#cb82-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-19"><a href="#cb82-19" aria-hidden="true" tabindex="-1"></a>pooled_m5 <span class="ot">&lt;-</span> <span class="fu">pool</span>(fit_m5)</span>
<span id="cb82-20"><a href="#cb82-20" aria-hidden="true" tabindex="-1"></a>pooled_m20 <span class="ot">&lt;-</span> <span class="fu">pool</span>(fit_m20)</span>
<span id="cb82-21"><a href="#cb82-21" aria-hidden="true" tabindex="-1"></a>pooled_m50 <span class="ot">&lt;-</span> <span class="fu">pool</span>(fit_m50)</span>
<span id="cb82-22"><a href="#cb82-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-23"><a href="#cb82-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare coefficient estimates and SEs</span></span>
<span id="cb82-24"><a href="#cb82-24" aria-hidden="true" tabindex="-1"></a>compare_m <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb82-25"><a href="#cb82-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">m =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">20</span>, <span class="dv">50</span>),</span>
<span id="cb82-26"><a href="#cb82-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">age_coef =</span> <span class="fu">c</span>(</span>
<span id="cb82-27"><a href="#cb82-27" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>(pooled_m5)<span class="sc">$</span>estimate[<span class="dv">2</span>],</span>
<span id="cb82-28"><a href="#cb82-28" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>(pooled_m20)<span class="sc">$</span>estimate[<span class="dv">2</span>],</span>
<span id="cb82-29"><a href="#cb82-29" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>(pooled_m50)<span class="sc">$</span>estimate[<span class="dv">2</span>]</span>
<span id="cb82-30"><a href="#cb82-30" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb82-31"><a href="#cb82-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">age_se =</span> <span class="fu">c</span>(</span>
<span id="cb82-32"><a href="#cb82-32" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>(pooled_m5)<span class="sc">$</span>std.error[<span class="dv">2</span>],</span>
<span id="cb82-33"><a href="#cb82-33" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>(pooled_m20)<span class="sc">$</span>std.error[<span class="dv">2</span>],</span>
<span id="cb82-34"><a href="#cb82-34" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>(pooled_m50)<span class="sc">$</span>std.error[<span class="dv">2</span>]</span>
<span id="cb82-35"><a href="#cb82-35" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb82-36"><a href="#cb82-36" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb82-37"><a href="#cb82-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-38"><a href="#cb82-38" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(compare_m)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 3
      m age_coef age_se
  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;
1     5   0.0676 0.0320
2    20   0.0723 0.0305
3    50   0.0718 0.0310</code></pre>
</div>
</div>
<p><strong>Interpretation</strong>:</p>
<ul>
<li><strong>Coefficients</strong> should be similar across m (small differences are expected due to Monte Carlo error)</li>
<li><strong>Standard errors</strong> should stabilize as m increases</li>
<li>If estimates change substantially (e.g., &gt; 10% difference in coefficients), use larger m</li>
</ul>
</section>
<section id="when-to-use-larger-m" class="level4" data-number="2.5.5.3">
<h4 data-number="2.5.5.3" class="anchored" data-anchor-id="when-to-use-larger-m"><span class="header-section-number">2.5.5.3</span> When to Use Larger m</h4>
<ul>
<li><strong>High missingness</strong> (&gt; 20%): Use m ≥ 20</li>
<li><strong>Small samples</strong> (n &lt; 50): Larger m reduces Monte Carlo error</li>
<li><strong>Sensitive analyses</strong> (e.g., clinical trials): Use m ≥ 50 for conservative inference</li>
</ul>
</section>
</section>
<section id="diagnostic-4-checking-imputation-model-assumptions" class="level3" data-number="2.5.6">
<h3 data-number="2.5.6" class="anchored" data-anchor-id="diagnostic-4-checking-imputation-model-assumptions"><span class="header-section-number">2.5.6</span> Diagnostic 4: Checking Imputation Model Assumptions</h3>
<section id="inspect-imputation-methods" class="level4" data-number="2.5.6.1">
<h4 data-number="2.5.6.1" class="anchored" data-anchor-id="inspect-imputation-methods"><span class="header-section-number">2.5.6.1</span> Inspect Imputation Methods</h4>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check which imputation methods were used</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>imp<span class="sc">$</span>method</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>         age satisfaction       income 
       "pmm"        "pmm"        "pmm" </code></pre>
</div>
</div>
<p><strong>Common methods</strong>:</p>
<ul>
<li><code>pmm</code>: Predictive mean matching (robust, preserves distribution)</li>
<li><code>norm</code>: Bayesian linear regression (assumes normality)</li>
<li><code>logreg</code>: Logistic regression (for binary variables)</li>
<li><code>polyreg</code>: Multinomial logistic regression (for categorical variables)</li>
</ul>
<p><strong>Best practice</strong>: Use <code>pmm</code> for continuous variables unless you have strong reasons to assume normality.</p>
</section>
<section id="check-predictor-matrix" class="level4" data-number="2.5.6.2">
<h4 data-number="2.5.6.2" class="anchored" data-anchor-id="check-predictor-matrix"><span class="header-section-number">2.5.6.2</span> Check Predictor Matrix</h4>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># See which variables predict each other</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>imp<span class="sc">$</span>predictorMatrix</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>             age satisfaction income
age            0            1      1
satisfaction   1            0      1
income         1            1      0</code></pre>
</div>
</div>
<p><strong>Interpretation</strong>:</p>
<ul>
<li>Rows = variables to impute</li>
<li>Columns = predictor variables</li>
<li><code>1</code> = use as predictor, <code>0</code> = do not use</li>
</ul>
<p><strong>Modify if needed</strong>:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Exclude a variable from predicting another</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> imp<span class="sc">$</span>predictorMatrix</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>pred[<span class="st">"age"</span>, <span class="st">"satisfaction"</span>] <span class="ot">&lt;-</span> <span class="dv">0</span>  <span class="co"># Don't use satisfaction to predict age</span></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run imputation with modified predictor matrix</span></span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>imp_modified <span class="ot">&lt;-</span> <span class="fu">mice</span>(mi_data, <span class="at">m =</span> <span class="dv">5</span>, <span class="at">predictorMatrix =</span> pred, <span class="at">print =</span> <span class="cn">FALSE</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="diagnostic-5-fraction-of-missing-information-fmi" class="level3" data-number="2.5.7">
<h3 data-number="2.5.7" class="anchored" data-anchor-id="diagnostic-5-fraction-of-missing-information-fmi"><span class="header-section-number">2.5.7</span> Diagnostic 5: Fraction of Missing Information (FMI)</h3>
<p>The FMI quantifies how much uncertainty is introduced by imputation. It is automatically reported by <code>pool()</code>:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb89"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pool results and examine FMI</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>pooled_result <span class="ot">&lt;-</span> <span class="fu">pool</span>(fit_m20)</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pooled_result)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>         term estimate std.error statistic    df p.value
1 (Intercept)  1.57183   1.39276     1.129 32.67 0.26730
2         age  0.07225   0.03051     2.368 35.21 0.02352
3      income -0.02782   0.01819    -1.530 37.23 0.13456</code></pre>
</div>
</div>
<p><strong>Columns to examine</strong>:</p>
<ul>
<li><strong>fmi</strong>: Fraction of missing information for each coefficient</li>
<li><strong>lambda</strong>: Proportion of total variance due to missingness</li>
</ul>
<p><strong>Interpretation</strong>:</p>
<ul>
<li><strong>FMI &lt; 0.10</strong>: Low missing information; m = 5–10 sufficient</li>
<li><strong>FMI = 0.10–0.30</strong>: Moderate; use m = 20–50</li>
<li><strong>FMI &gt; 0.30</strong>: High; consider whether MI is appropriate (may need m = 50–100)</li>
</ul>
</section>
<section id="example-full-diagnostic-workflow" class="level3" data-number="2.5.8">
<h3 data-number="2.5.8" class="anchored" data-anchor-id="example-full-diagnostic-workflow"><span class="header-section-number">2.5.8</span> Example: Full Diagnostic Workflow</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Describe missingness</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(naniar)</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="fu">miss_var_summary</span>(mi_data_large)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 3
  variable     n_miss pct_miss
  &lt;chr&gt;         &lt;int&gt;    &lt;num&gt;
1 age              10       20
2 satisfaction      6       12
3 income            1        2</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb93"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Perform MI with adequate m and maxit</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>imp_final <span class="ot">&lt;-</span> <span class="fu">mice</span>(mi_data_large, <span class="at">m =</span> <span class="dv">20</span>, <span class="at">maxit =</span> <span class="dv">30</span>, <span class="at">seed =</span> <span class="dv">2025</span>, <span class="at">print =</span> <span class="cn">FALSE</span>)</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Check convergence</span></span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(imp_final, <span class="fu">c</span>(<span class="st">"age"</span>, <span class="st">"income"</span>, <span class="st">"satisfaction"</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="part-b-data-collection_files/figure-html/part-b-mi-diag-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb94"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Compare distributions</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="fu">densityplot</span>(imp_final)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="part-b-data-collection_files/figure-html/part-b-mi-diag-10-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5: Fit model and pool</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>fit_final <span class="ot">&lt;-</span> <span class="fu">with</span>(imp_final, <span class="fu">lm</span>(satisfaction <span class="sc">~</span> age <span class="sc">+</span> income))</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>pooled_final <span class="ot">&lt;-</span> <span class="fu">pool</span>(fit_final)</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 6: Check FMI</span></span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pooled_final)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>         term estimate std.error statistic    df p.value
1 (Intercept)  1.25971   1.47860     0.852 28.51 0.40134
2         age  0.07511   0.03243     2.316 30.41 0.02748
3      income -0.02378   0.01919    -1.239 32.05 0.22438</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb97"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 7: Report results</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Pooled regression results (m = 20 imputations):</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Pooled regression results (m = 20 imputations):</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb99"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pooled_final)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>         term estimate std.error statistic    df p.value
1 (Intercept)  1.25971   1.47860     0.852 28.51 0.40134
2         age  0.07511   0.03243     2.316 30.41 0.02748
3      income -0.02378   0.01919    -1.239 32.05 0.22438</code></pre>
</div>
</div>
</section>
<section id="red-flags-and-troubleshooting" class="level3" data-number="2.5.9">
<h3 data-number="2.5.9" class="anchored" data-anchor-id="red-flags-and-troubleshooting"><span class="header-section-number">2.5.9</span> Red Flags and Troubleshooting</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 32%">
<col style="width: 32%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Problem</strong></th>
<th><strong>Symptom</strong></th>
<th><strong>Solution</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Non-convergence</strong></td>
<td>Trace plots show trends</td>
<td>Increase <code>maxit</code> (try 50–100)</td>
</tr>
<tr class="even">
<td><strong>Imputed values at one value</strong></td>
<td>Density plot shows spike</td>
<td>Use <code>method = "pmm"</code> instead of <code>norm</code></td>
</tr>
<tr class="odd">
<td><strong>Imputed values out of range</strong></td>
<td>Strip plot shows outliers</td>
<td>Check variable type (e.g., use <code>logreg</code> for binary)</td>
</tr>
<tr class="even">
<td><strong>Unstable estimates across m</strong></td>
<td>Coefficients vary &gt; 10%</td>
<td>Increase m (try 50–100)</td>
</tr>
<tr class="odd">
<td><strong>High FMI (&gt; 0.50)</strong></td>
<td>Large uncertainty</td>
<td>Consider whether MI is appropriate; may need auxiliary variables or accept wider CIs</td>
</tr>
<tr class="even">
<td><strong>Separation warnings (logistic regression)</strong></td>
<td>Model fails to converge</td>
<td>Use penalized imputation methods or increase sample size</td>
</tr>
</tbody>
</table>
</section>
<section id="reporting-mi-diagnostics" class="level3" data-number="2.5.10">
<h3 data-number="2.5.10" class="anchored" data-anchor-id="reporting-mi-diagnostics"><span class="header-section-number">2.5.10</span> Reporting MI Diagnostics</h3>
<p>When reporting MI results, include:</p>
<ol type="1">
<li><strong>Missingness pattern</strong>: “Three variables had missing data (age: 20%, income: 18%, satisfaction: 10%)”</li>
<li><strong>Imputation model</strong>: “We used predictive mean matching with m = 20 imputations and maxit = 30”</li>
<li><strong>Convergence</strong>: “Trace plots showed convergence after 20 iterations (see Supplementary Figure S1)”</li>
<li><strong>Plausibility</strong>: “Imputed values were visually consistent with observed distributions (density plots in Supplementary Figure S2)”</li>
<li><strong>Sensitivity</strong>: “Results were stable across m = 5, 20, and 50 imputations (coefficient differences &lt; 5%)”</li>
<li><strong>FMI</strong>: “Fraction of missing information ranged from 0.12 to 0.25, indicating moderate impact of missingness”</li>
</ol>
</section>
<section id="key-takeaways-3" class="level3" data-number="2.5.11">
<h3 data-number="2.5.11" class="anchored" data-anchor-id="key-takeaways-3"><span class="header-section-number">2.5.11</span> Key Takeaways</h3>
<ul>
<li><strong>Convergence checks</strong> (trace plots) ensure the imputation algorithm has stabilised; increase <code>maxit</code> if trends are visible</li>
<li><strong>Density and strip plots</strong> compare imputed vs.&nbsp;observed distributions; imputed values should resemble observed data</li>
<li><strong>Number of imputations (m)</strong> should match the fraction of missing information: m ≥ 20 for FMI = 10–30%</li>
<li><strong>Sensitivity analyses</strong> test whether results are stable across different values of m</li>
<li><strong>Fraction of Missing Information (FMI)</strong> quantifies uncertainty from imputation; FMI &gt; 0.30 suggests high impact</li>
<li><strong>Red flags</strong>: Imputed values at one value, outliers, non-convergence, unstable estimates → revise imputation model</li>
<li><strong>Transparency</strong>: Report convergence, plausibility checks, and sensitivity analyses in supplementary materials</li>
</ul>
<hr>
</section>
<section id="self-assessment-quiz-3" class="level3" data-number="2.5.12">
<h3 data-number="2.5.12" class="anchored" data-anchor-id="self-assessment-quiz-3"><span class="header-section-number">2.5.12</span> Self-Assessment Quiz</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Chapter 12 Questions
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Q1.</strong> What is the difference between MCAR (Missing Completely At Random) and MAR (Missing At Random)?</p>
<ol type="A">
<li>MCAR means no data are missing; MAR means some data are missing<br>
</li>
<li>MCAR means missingness is unrelated to any variables; MAR means missingness is related to observed variables but not the missing values themselves<br>
</li>
<li>MCAR and MAR are identical terms<br>
</li>
<li>MCAR applies to small samples; MAR applies to large samples</li>
</ol>
<hr>
<p><strong>Q2.</strong> Why is mean imputation (replacing missing values with the variable mean) generally not recommended?</p>
<ol type="A">
<li>It requires specialized software<br>
</li>
<li>It artificially reduces variance and distorts correlations<br>
</li>
<li>It only works with categorical variables<br>
</li>
<li>It is too computationally expensive</li>
</ol>
<hr>
<p><strong>Q3.</strong> If you have 20% missingness on variable X and 20% missingness on variable Y (independently), approximately what percentage of cases will be lost with listwise deletion?</p>
<ol type="A">
<li>20%<br>
</li>
<li>36%<br>
</li>
<li>40%<br>
</li>
<li>64%</li>
</ol>
<hr>
<p><strong>Q4.</strong> What does MNAR (Missing Not At Random) mean?</p>
<ol type="A">
<li>Missingness is unrelated to any variables<br>
</li>
<li>Missingness is related to observed variables only<br>
</li>
<li>Missingness is related to the unobserved (missing) values themselves<br>
</li>
<li>Missing data occur randomly due to software errors</li>
</ol>
<hr>
<p><strong>Q5.</strong> What is the primary limitation of using multiple imputation with very small samples (n &lt; 30)?</p>
<ol type="A">
<li>Multiple imputation cannot handle small samples<br>
</li>
<li>The imputation model is estimated from limited data and may be unstable or yield implausible values<br>
</li>
<li>Multiple imputation requires at least 1,000 observations<br>
</li>
<li>Multiple imputation only works with MNAR data</li>
</ol>
<hr>
<p><strong>Q6.</strong> In multiple imputation diagnostics, what do trace plots check?</p>
<ol type="A">
<li>The distribution of imputed values<br>
</li>
<li>Whether the imputation algorithm has converged (stabilized) across iterations<br>
</li>
<li>The correlation between variables<br>
</li>
<li>The sample size required for analysis</li>
</ol>
<hr>
<p><strong>Q7.</strong> When comparing imputed (red) vs.&nbsp;observed (blue) distributions in density plots, what is a “red flag”?</p>
<ol type="A">
<li>The distributions overlap substantially<br>
</li>
<li>Imputed values fall far outside the observed range or all cluster at one value<br>
</li>
<li>Both distributions are normally distributed<br>
</li>
<li>The imputed values have slightly different means</li>
</ol>
<hr>
<p><strong>Q8.</strong> What is the rule of thumb for choosing the number of imputations (m) based on the fraction of missing information (FMI)?</p>
<ol type="A">
<li>Always use m = 5 regardless of FMI<br>
</li>
<li>Use m ≥ 100 × FMI (e.g., FMI = 0.20 requires m ≥ 20)<br>
</li>
<li>Use m = 1000 for all analyses<br>
</li>
<li>m should equal the sample size</li>
</ol>
<hr>
<p><strong>Q9.</strong> What does Little’s MCAR test evaluate?</p>
<ol type="A">
<li>Whether the sample size is adequate<br>
</li>
<li>Whether missingness is consistent with the MCAR mechanism by comparing observed means across missing-data patterns<br>
</li>
<li>Whether multiple imputation has converged<br>
</li>
<li>Whether variables are normally distributed</li>
</ol>
<hr>
<p><strong>Q10.</strong> Why is prevention the best approach to missing data?</p>
<ol type="A">
<li>Prevention is cheaper than imputation software<br>
</li>
<li>Even sophisticated imputation methods have limitations and cannot fully recover information lost to missingness; prevention avoids the problem<br>
</li>
<li>Prevention is only relevant for large samples<br>
</li>
<li>Multiple imputation cannot handle any missing data</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Answers and Explanations
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>A1. B)</strong> “MCAR (Missing Completely At Random): Missingness is unrelated to any observed or unobserved variables… MAR (Missing At Random): Missingness is related to observed variables but not to the missing values themselves.”<br>
MCAR is a stricter assumption where missingness is completely random, while MAR allows missingness to depend on observed data.</p>
<p><strong>A2. B)</strong> “Mean imputation replaces missing values with the variable mean. This approach artificially reduces variance and distorts correlations.”<br>
By replacing all missing values with the mean, you reduce the variability in the data and bias correlation estimates downward.</p>
<p><strong>A3. B)</strong> “With 20% missing on x and 20% on y (independent), you lose ~36% of cases—Formula: (1 - p_x) × (1 - p_y) = 0.8 × 0.8 = 0.64 → 64% remain, 36% lost”<br>
When missingness patterns are independent, the compound effect removes (1 - 0.8 × 0.8) = 36% of cases.</p>
<p><strong>A4. C)</strong> “MNAR (Missing Not At Random): Missingness is related to the unobserved values themselves.”<br>
For example, individuals with high depression scores being more likely to drop out of a study.</p>
<p><strong>A5. B)</strong> “With very small samples (n &lt; 30) or many missing values (&gt; 20%), MI can be unstable or yield implausible imputations.”<br>
The imputation model requires sufficient data to estimate relationships reliably; very small samples provide limited information.</p>
<p><strong>A6. B)</strong> “Trace plots show the mean and SD of imputed values across iterations for each variable… Convergence occurs when these iterations stabilise.”<br>
Good convergence shows random fluctuation without systematic trends (upward or downward drift).</p>
<p><strong>A7. B)</strong> “Imputed values fall far outside observed range → model misspecified… Imputed values are all at one value (e.g., the mean) → model too restrictive.”<br>
Large discrepancies between imputed and observed distributions suggest problems with the imputation model specification.</p>
<p><strong>A8. B)</strong> “White, Royston, and Wood (2011) suggest: m ≥ 100 × FMI”<br>
For example, if FMI = 0.20 (20% missing information), you should use m ≥ 20 imputations.</p>
<p><strong>A9. B)</strong> “Little’s MCAR test evaluates whether missingness is consistent with the MCAR mechanism. The test compares observed means across missing-data patterns.”<br>
A large p-value suggests MCAR is plausible; a small p-value indicates missingness likely depends on observed data.</p>
<p><strong>A10. B)</strong> “The best approach to missing data is prevention… Pilot test procedures to identify confusing or burdensome items. Build rapport and trust with participants.”<br>
No imputation method can fully recover the information lost to missingness, so preventing missing data through good design is always preferable.</p>
</div>
</div>
</div>
</section>
<section id="key-takeaways-4" class="level3" data-number="2.5.13">
<h3 data-number="2.5.13" class="anchored" data-anchor-id="key-takeaways-4"><span class="header-section-number">2.5.13</span> Key Takeaways</h3>
<ul>
<li>Missing data reduce effective sample size and can bias estimates, particularly with small samples.</li>
<li>Describe missingness patterns (proportion missing, complete vs.&nbsp;incomplete case characteristics) before choosing a method.</li>
<li>Complete-case analysis is simple and valid if missingness is minimal or MCAR, but wastes information and loses power.</li>
<li>Mean imputation and LOCF are not recommended; they distort variance and correlations.</li>
<li>Multiple imputation is the gold standard with adequate samples (n ≥ 30, missingness &lt; 20%) but may be unstable with very small samples.</li>
<li>Sensitivity analyses compare results under different assumptions about the missing data mechanism.</li>
<li>Prevention through careful study design is the best strategy for minimising missing data.</li>
</ul>
</section>
<section id="smoke-test-3" class="level3" data-number="2.5.14">
<h3 data-number="2.5.14" class="anchored" data-anchor-id="smoke-test-3"><span class="header-section-number">2.5.14</span> Smoke Test</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb101"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run missing data summary</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">6</span>, <span class="cn">NA</span>, <span class="dv">8</span>, <span class="dv">7</span>, <span class="cn">NA</span>, <span class="dv">9</span>)</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">is.na</span>(x))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb103"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">is.na</span>(x))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2857</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="summary-of-part-b" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="summary-of-part-b"><span class="header-section-number">2.6</span> Summary of Part B</h2>
<p>In Part B, we addressed practical challenges in collecting and preparing data for small-sample studies. Chapter 9 covered sampling strategies (probability, stratified, purposive, quota sampling) and power analyses to understand detectability given sample size constraints. Chapter 10 discussed measurement quality and scale development, including item analysis, cognitive interviews, and reliability assessment with short scales. Chapter 11 presented data screening and diagnostic checks (outlier detection, normality assessment, regression diagnostics) to identify problems before analysis. Chapter 12 addressed missing data patterns, simple and advanced imputation methods, and the importance of transparency and prevention. Each chapter included learning objectives, method descriptions, runnable R examples, interpretations, key takeaways, and smoke tests. All code uses only approved packages and runs cleanly in a fresh R session. The guidance emphasises transparency, caution, and appropriate method selection given small-sample constraints.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/part-a-foundations.html" class="pagination-link" aria-label="Part A: Foundations">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Part A: Foundations</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/part-c-analysis-methods.html" class="pagination-link" aria-label="Part C: Analysis Methods">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Part C: Analysis Methods</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb105" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Part B: Data Collection and Preparation</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>This part addresses practical challenges in collecting and preparing data for small-sample studies. We cover sampling strategies that maximise information with limited resources, measurement quality and scale development, data screening and diagnostic checks, and handling missing data transparently.</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a><span class="fu">## Chapter 9. Sampling Strategies for Small Studies</span></span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a><span class="fu">### Learning Objectives</span></span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a>By the end of this chapter, you will be able to:</span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a>**Conceptual Understanding**</span>
<span id="cb105-14"><a href="#cb105-14" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Explain the trade-offs between probability and purposive sampling</span>
<span id="cb105-15"><a href="#cb105-15" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Understand the relationship between sample size, power, and detectable effects</span>
<span id="cb105-16"><a href="#cb105-16" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Recognize when small samples are sufficient vs. inadequate</span>
<span id="cb105-17"><a href="#cb105-17" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Distinguish between sampling for generalizability vs. mechanism testing</span>
<span id="cb105-18"><a href="#cb105-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-19"><a href="#cb105-19" aria-hidden="true" tabindex="-1"></a>**Practical Skills**</span>
<span id="cb105-20"><a href="#cb105-20" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Select appropriate sampling methods given resource and population constraints</span>
<span id="cb105-21"><a href="#cb105-21" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Calculate minimum detectable effects for planned sample sizes</span>
<span id="cb105-22"><a href="#cb105-22" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Implement stratified sampling to improve precision with small n</span>
<span id="cb105-23"><a href="#cb105-23" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Design sequential and adaptive sampling strategies</span>
<span id="cb105-24"><a href="#cb105-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-25"><a href="#cb105-25" aria-hidden="true" tabindex="-1"></a>**Critical Evaluation**</span>
<span id="cb105-26"><a href="#cb105-26" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Assess the tension between ideal and feasible sample sizes</span>
<span id="cb105-27"><a href="#cb105-27" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Evaluate whether purposive sampling is appropriate for research aims</span>
<span id="cb105-28"><a href="#cb105-28" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Critique sampling justifications in published small-sample studies</span>
<span id="cb105-29"><a href="#cb105-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-30"><a href="#cb105-30" aria-hidden="true" tabindex="-1"></a>**Application**</span>
<span id="cb105-31"><a href="#cb105-31" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Justify sample sizes transparently in research proposals</span>
<span id="cb105-32"><a href="#cb105-32" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Design sampling plans that maximize information with limited resources</span>
<span id="cb105-33"><a href="#cb105-33" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Report sampling procedures and achieved samples with appropriate caveats</span>
<span id="cb105-34"><a href="#cb105-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-35"><a href="#cb105-35" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Tension Between Ideal and Feasible Sample Sizes</span></span>
<span id="cb105-36"><a href="#cb105-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-37"><a href="#cb105-37" aria-hidden="true" tabindex="-1"></a>Most power analysis guides assume that researchers can achieve conventionally adequate sample sizes (n ≥ 30 per group for t-tests, 10–15 events per predictor for regression). In practice, resource constraints, rare populations, and ethical considerations often make these targets unattainable. Rather than abandoning research in such contexts, we should adopt methods suited to smaller samples and report findings with appropriate caveats.</span>
<span id="cb105-38"><a href="#cb105-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-39"><a href="#cb105-39" aria-hidden="true" tabindex="-1"></a>Transparent reporting of sampling rationale, achieved sample size, and power or precision estimates helps readers judge the strength of evidence. Researchers should distinguish between studies designed to test specific hypotheses (which require adequate power) and exploratory studies that generate hypotheses or provide preliminary effect estimates (which can proceed with modest samples).</span>
<span id="cb105-40"><a href="#cb105-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-41"><a href="#cb105-41" aria-hidden="true" tabindex="-1"></a><span class="fu">### Probability Sampling with Small Samples</span></span>
<span id="cb105-42"><a href="#cb105-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-43"><a href="#cb105-43" aria-hidden="true" tabindex="-1"></a>Probability sampling (simple random sampling, stratified sampling, cluster sampling) ensures that every unit has a known, non-zero probability of selection. This supports generalisation to the target population and enables design-based inference. However, probability sampling requires a sampling frame and may be logistically complex or expensive.</span>
<span id="cb105-44"><a href="#cb105-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-45"><a href="#cb105-45" aria-hidden="true" tabindex="-1"></a>With small samples, probability sampling can still be valuable, but estimates will have wide confidence intervals. Stratified sampling (dividing the population into strata and sampling proportionally or disproportionally from each) can improve precision by ensuring representation of key subgroups.</span>
<span id="cb105-46"><a href="#cb105-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-47"><a href="#cb105-47" aria-hidden="true" tabindex="-1"></a>**When to use**: Accessible sampling frame, desire for generalisability, resources permit random selection, even if total sample size is modest.</span>
<span id="cb105-48"><a href="#cb105-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-49"><a href="#cb105-49" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sequential and Adaptive Sampling</span></span>
<span id="cb105-50"><a href="#cb105-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-51"><a href="#cb105-51" aria-hidden="true" tabindex="-1"></a>When recruitment is costly or uncertain, sequential designs allow researchers to review interim results and decide whether to continue sampling. For example, you might pre-specify that recruitment will proceed in waves of five participants, stopping early if credible intervals for the primary outcome are sufficiently narrow or if feasibility metrics (e.g., consent rates) fall below thresholds. Adaptive sampling can also target underrepresented strata after an initial wave, improving balance without committing to a large upfront sample. Key principles:</span>
<span id="cb105-52"><a href="#cb105-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-53"><a href="#cb105-53" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Set decision rules in advance.** Define stopping boundaries for efficacy, futility, or feasibility to avoid ad hoc choices.</span>
<span id="cb105-54"><a href="#cb105-54" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Maintain error control.** Use exact tests, Bayesian posterior probabilities, or alpha-spending functions appropriate for small *n*.</span>
<span id="cb105-55"><a href="#cb105-55" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Document adaptations transparently.** Report how the sampling plan evolved, including any changes to recruitment targets or strata weights.</span>
<span id="cb105-56"><a href="#cb105-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-57"><a href="#cb105-57" aria-hidden="true" tabindex="-1"></a>Sequential or response-adaptive sampling is especially valuable in rare populations, where pausing after each wave prevents over-committing resources if early data already provide actionable evidence.</span>
<span id="cb105-58"><a href="#cb105-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-59"><a href="#cb105-59" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example: Stratified Sampling Calculation</span></span>
<span id="cb105-60"><a href="#cb105-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-61"><a href="#cb105-61" aria-hidden="true" tabindex="-1"></a>Suppose we are surveying employees in a small organisation with 120 total staff: 60 in Department A, 40 in Department B, 20 in Department C. We can afford to survey 30 employees. Proportional stratified sampling ensures each department is represented in proportion to its size.</span>
<span id="cb105-62"><a href="#cb105-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-65"><a href="#cb105-65" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-66"><a href="#cb105-66" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-01</span></span>
<span id="cb105-67"><a href="#cb105-67" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb105-68"><a href="#cb105-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-69"><a href="#cb105-69" aria-hidden="true" tabindex="-1"></a><span class="co"># Population strata</span></span>
<span id="cb105-70"><a href="#cb105-70" aria-hidden="true" tabindex="-1"></a>strata <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb105-71"><a href="#cb105-71" aria-hidden="true" tabindex="-1"></a>  <span class="at">Department =</span> <span class="fu">c</span>(<span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span>),</span>
<span id="cb105-72"><a href="#cb105-72" aria-hidden="true" tabindex="-1"></a>  <span class="at">Population_N =</span> <span class="fu">c</span>(<span class="dv">60</span>, <span class="dv">40</span>, <span class="dv">20</span>),</span>
<span id="cb105-73"><a href="#cb105-73" aria-hidden="true" tabindex="-1"></a>  <span class="at">Proportion =</span> Population_N <span class="sc">/</span> <span class="fu">sum</span>(Population_N)</span>
<span id="cb105-74"><a href="#cb105-74" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb105-75"><a href="#cb105-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-76"><a href="#cb105-76" aria-hidden="true" tabindex="-1"></a><span class="co"># Total sample size</span></span>
<span id="cb105-77"><a href="#cb105-77" aria-hidden="true" tabindex="-1"></a>total_sample <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb105-78"><a href="#cb105-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-79"><a href="#cb105-79" aria-hidden="true" tabindex="-1"></a><span class="co"># Allocate sample proportionally</span></span>
<span id="cb105-80"><a href="#cb105-80" aria-hidden="true" tabindex="-1"></a>strata <span class="ot">&lt;-</span> strata <span class="sc">%&gt;%</span></span>
<span id="cb105-81"><a href="#cb105-81" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb105-82"><a href="#cb105-82" aria-hidden="true" tabindex="-1"></a>    <span class="at">Sample_n =</span> <span class="fu">round</span>(Proportion <span class="sc">*</span> total_sample),</span>
<span id="cb105-83"><a href="#cb105-83" aria-hidden="true" tabindex="-1"></a>    <span class="at">Sampling_Fraction =</span> Sample_n <span class="sc">/</span> Population_N</span>
<span id="cb105-84"><a href="#cb105-84" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb105-85"><a href="#cb105-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-86"><a href="#cb105-86" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(strata)</span>
<span id="cb105-87"><a href="#cb105-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-88"><a href="#cb105-88" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Total sample allocated:"</span>, <span class="fu">sum</span>(strata<span class="sc">$</span>Sample_n), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-89"><a href="#cb105-89" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-90"><a href="#cb105-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-91"><a href="#cb105-91" aria-hidden="true" tabindex="-1"></a>Interpretation: Proportional allocation ensures that each department contributes to the sample in proportion to its population size. Department A, being the largest, provides 15 respondents; Department C, the smallest, provides 5. This approach yields unbiased estimates for the overall population. If precision for small strata is a concern, disproportionate allocation (oversampling small strata) can be used, though this requires weighting in analysis.</span>
<span id="cb105-92"><a href="#cb105-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-93"><a href="#cb105-93" aria-hidden="true" tabindex="-1"></a><span class="fu">### Purposive and Convenience Sampling</span></span>
<span id="cb105-94"><a href="#cb105-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-95"><a href="#cb105-95" aria-hidden="true" tabindex="-1"></a>Purposive (judgmental) sampling selects units based on researcher judgement of their informativeness or representativeness. Convenience sampling selects units that are easily accessible. Neither method supports probabilistic generalisation, but both are common in small-sample research where probability sampling is infeasible.</span>
<span id="cb105-96"><a href="#cb105-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-97"><a href="#cb105-97" aria-hidden="true" tabindex="-1"></a>Findings from purposive or convenience samples should be interpreted cautiously and presented as preliminary or context-specific. Replication in independent samples strengthens confidence.</span>
<span id="cb105-98"><a href="#cb105-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-99"><a href="#cb105-99" aria-hidden="true" tabindex="-1"></a>**When to use**: No sampling frame available, exploratory research, pilot studies, rare or hard-to-reach populations, tight resource constraints.</span>
<span id="cb105-100"><a href="#cb105-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-101"><a href="#cb105-101" aria-hidden="true" tabindex="-1"></a><span class="fu">### Quota Sampling</span></span>
<span id="cb105-102"><a href="#cb105-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-103"><a href="#cb105-103" aria-hidden="true" tabindex="-1"></a>Quota sampling (a form of purposive sampling) selects units to match known population characteristics (such as age, gender, or occupation distribution). It mimics stratified sampling but without random selection within strata. Quota sampling can improve representativeness compared to convenience sampling, though it remains non-probabilistic.</span>
<span id="cb105-104"><a href="#cb105-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-105"><a href="#cb105-105" aria-hidden="true" tabindex="-1"></a>**When to use**: Known population characteristics to match, desire for balanced sample composition, probability sampling infeasible.</span>
<span id="cb105-106"><a href="#cb105-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-107"><a href="#cb105-107" aria-hidden="true" tabindex="-1"></a><span class="fu">### Power and Precision with Small Samples</span></span>
<span id="cb105-108"><a href="#cb105-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-109"><a href="#cb105-109" aria-hidden="true" tabindex="-1"></a>Statistical power is the probability of detecting a true effect of a given size. With small samples, power is limited, meaning that even if a meaningful effect exists, the study may fail to detect it (high Type II error rate). Researchers should conduct power analyses before data collection to understand what effects are detectable given sample size constraints.</span>
<span id="cb105-110"><a href="#cb105-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-111"><a href="#cb105-111" aria-hidden="true" tabindex="-1"></a>If the achieved sample size is smaller than desired, report the minimum detectable effect (MDE): the smallest effect the study can detect with specified power (typically 80%) and alpha (typically 0.05). This helps readers judge whether the study could have detected effects of practical importance.</span>
<span id="cb105-112"><a href="#cb105-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-113"><a href="#cb105-113" aria-hidden="true" tabindex="-1"></a><span class="fu">### Finite Population Correction</span></span>
<span id="cb105-114"><a href="#cb105-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-115"><a href="#cb105-115" aria-hidden="true" tabindex="-1"></a>When sampling without replacement from a small, known population, the variance of estimates decreases because each sampled unit reduces remaining uncertainty. The finite population correction (FPC) adjusts the required sample size accordingly. If a power analysis suggests 30 participants are needed assuming an infinite population, but the accessible population is only 120 people, the adjusted sample size is smaller:</span>
<span id="cb105-116"><a href="#cb105-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-119"><a href="#cb105-119" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-120"><a href="#cb105-120" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-02</span></span>
<span id="cb105-121"><a href="#cb105-121" aria-hidden="true" tabindex="-1"></a><span class="co"># Finite population correction example</span></span>
<span id="cb105-122"><a href="#cb105-122" aria-hidden="true" tabindex="-1"></a>n_required_infinite <span class="ot">&lt;-</span> <span class="dv">30</span>  <span class="co"># From power analysis</span></span>
<span id="cb105-123"><a href="#cb105-123" aria-hidden="true" tabindex="-1"></a>N_population <span class="ot">&lt;-</span> <span class="dv">120</span>        <span class="co"># Size of accessible population</span></span>
<span id="cb105-124"><a href="#cb105-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-125"><a href="#cb105-125" aria-hidden="true" tabindex="-1"></a>n_adjusted <span class="ot">&lt;-</span> n_required_infinite <span class="sc">/</span></span>
<span id="cb105-126"><a href="#cb105-126" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">1</span> <span class="sc">+</span> (n_required_infinite <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">/</span> N_population)</span>
<span id="cb105-127"><a href="#cb105-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-128"><a href="#cb105-128" aria-hidden="true" tabindex="-1"></a>n_adjusted</span>
<span id="cb105-129"><a href="#cb105-129" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-130"><a href="#cb105-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-131"><a href="#cb105-131" aria-hidden="true" tabindex="-1"></a>Interpretation: Sampling without replacement from 120 individuals means that a sample of roughly 24 (instead of 30) achieves the same precision. Always report whether you applied the FPC so readers can replicate the calculation.</span>
<span id="cb105-132"><a href="#cb105-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-133"><a href="#cb105-133" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example: Power Calculation for a Small Study</span></span>
<span id="cb105-134"><a href="#cb105-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-135"><a href="#cb105-135" aria-hidden="true" tabindex="-1"></a>We plan a study comparing two groups with n = 12 per group. We compute power to detect a medium effect size (Cohen's d = 0.5) using a two-sample t-test.</span>
<span id="cb105-136"><a href="#cb105-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-139"><a href="#cb105-139" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-140"><a href="#cb105-140" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-03</span></span>
<span id="cb105-141"><a href="#cb105-141" aria-hidden="true" tabindex="-1"></a><span class="co"># Power calculation using pwr package (if available)</span></span>
<span id="cb105-142"><a href="#cb105-142" aria-hidden="true" tabindex="-1"></a><span class="co"># If not installed, use approximations or manual calculation</span></span>
<span id="cb105-143"><a href="#cb105-143" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">requireNamespace</span>(<span class="st">"pwr"</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb105-144"><a href="#cb105-144" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(pwr)</span>
<span id="cb105-145"><a href="#cb105-145" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-146"><a href="#cb105-146" aria-hidden="true" tabindex="-1"></a>  power_result <span class="ot">&lt;-</span> <span class="fu">pwr.t.test</span>(<span class="at">n =</span> <span class="dv">12</span>, <span class="at">d =</span> <span class="fl">0.5</span>, <span class="at">sig.level =</span> <span class="fl">0.05</span>, </span>
<span id="cb105-147"><a href="#cb105-147" aria-hidden="true" tabindex="-1"></a>                              <span class="at">type =</span> <span class="st">"two.sample"</span>, <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span>
<span id="cb105-148"><a href="#cb105-148" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(power_result)</span>
<span id="cb105-149"><a href="#cb105-149" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-150"><a href="#cb105-150" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">With n = 12 per group, power to detect d = 0.5 is:"</span>, </span>
<span id="cb105-151"><a href="#cb105-151" aria-hidden="true" tabindex="-1"></a>      <span class="fu">round</span>(power_result<span class="sc">$</span>power, <span class="dv">2</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-152"><a href="#cb105-152" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-153"><a href="#cb105-153" aria-hidden="true" tabindex="-1"></a>  <span class="co"># What effect size is detectable with 80% power?</span></span>
<span id="cb105-154"><a href="#cb105-154" aria-hidden="true" tabindex="-1"></a>  mde_result <span class="ot">&lt;-</span> <span class="fu">pwr.t.test</span>(<span class="at">n =</span> <span class="dv">12</span>, <span class="at">power =</span> <span class="fl">0.80</span>, <span class="at">sig.level =</span> <span class="fl">0.05</span>,</span>
<span id="cb105-155"><a href="#cb105-155" aria-hidden="true" tabindex="-1"></a>                           <span class="at">type =</span> <span class="st">"two.sample"</span>, <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span>
<span id="cb105-156"><a href="#cb105-156" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"Minimum detectable effect (80% power):"</span>, <span class="fu">round</span>(mde_result<span class="sc">$</span>d, <span class="dv">2</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-157"><a href="#cb105-157" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb105-158"><a href="#cb105-158" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"Install 'pwr' package to run power calculations.</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-159"><a href="#cb105-159" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb105-160"><a href="#cb105-160" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-161"><a href="#cb105-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-162"><a href="#cb105-162" aria-hidden="true" tabindex="-1"></a>Interpretation: With 12 participants per group, power to detect a medium effect (d = 0.5) is modest (approximately 30–40%). To achieve 80% power, we would need to detect a larger effect (d ≈ 1.2, a very large effect). This illustrates the limitation of small samples for hypothesis testing. If the true effect is small or medium, the study is underpowered. Researchers should acknowledge this limitation and interpret non-significant results cautiously (absence of evidence is not evidence of absence).</span>
<span id="cb105-163"><a href="#cb105-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-164"><a href="#cb105-164" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sample Size Planning Workflow</span></span>
<span id="cb105-165"><a href="#cb105-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-166"><a href="#cb105-166" aria-hidden="true" tabindex="-1"></a>Integrating power analysis into a broader planning conversation prevents unrealistic promises and surfaces design trade-offs early. Use the following workflow whenever you scope a small-sample study:</span>
<span id="cb105-167"><a href="#cb105-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-168"><a href="#cb105-168" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Clarify the question and estimand.** What parameter (difference in means, odds ratio, correlation) must the study estimate?</span>
<span id="cb105-169"><a href="#cb105-169" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Specify tolerable uncertainty.** Define the minimum detectable effect or target confidence-interval width that would make the study actionable.</span>
<span id="cb105-170"><a href="#cb105-170" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Map constraints.** Document recruitment limits, budget, timeline, and ethical restrictions (e.g., maximum patient burden).</span>
<span id="cb105-171"><a href="#cb105-171" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Select design and analysis.** Choose the test/model, decide on one- vs two-sided inference, and note planned covariates or repeated measures.</span>
<span id="cb105-172"><a href="#cb105-172" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Compute required *n*.** Use analytical power formulas, simulation, or resampling as appropriate; apply finite-population corrections if sampling without replacement.</span>
<span id="cb105-173"><a href="#cb105-173" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**Assess feasibility.** Compare required *n* to constraints. If infeasible, adjust expectations (e.g., shift to estimation focus, reduce assurance level, adopt sequential design).</span>
<span id="cb105-174"><a href="#cb105-174" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>**Document decisions.** Record assumptions, software/code used, and any compromises for transparency.</span>
<span id="cb105-175"><a href="#cb105-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-178"><a href="#cb105-178" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb105-179"><a href="#cb105-179" aria-hidden="true" tabindex="-1"></a>flowchart TD</span>
<span id="cb105-180"><a href="#cb105-180" aria-hidden="true" tabindex="-1"></a>  Q[Define research question &amp; estimand] --&gt; U[Specify target effect <span class="ot">or</span> CI width]</span>
<span id="cb105-181"><a href="#cb105-181" aria-hidden="true" tabindex="-1"></a>  U --&gt; C[Document recruitment, budget, ethical constraints]</span>
<span id="cb105-182"><a href="#cb105-182" aria-hidden="true" tabindex="-1"></a>  C --&gt; D[Choose design &amp; analysis plan]</span>
<span id="cb105-183"><a href="#cb105-183" aria-hidden="true" tabindex="-1"></a>  D --&gt; N[Compute required sample size / MDE]</span>
<span id="cb105-184"><a href="#cb105-184" aria-hidden="true" tabindex="-1"></a>  N --&gt; F{Feasible within constraints?}</span>
<span id="cb105-185"><a href="#cb105-185" aria-hidden="true" tabindex="-1"></a>  F -- Yes --&gt; T[Lock plan &amp; preregister]</span>
<span id="cb105-186"><a href="#cb105-186" aria-hidden="true" tabindex="-1"></a>  F -- No --&gt; A[Adjust goals: revise estimand, adopt sequential design, <span class="ot">or</span> reframe as exploratory]</span>
<span id="cb105-187"><a href="#cb105-187" aria-hidden="true" tabindex="-1"></a>  A --&gt; C</span>
<span id="cb105-188"><a href="#cb105-188" aria-hidden="true" tabindex="-1"></a>  T --&gt; R[Record assumptions &amp; share in protocol]</span>
<span id="cb105-189"><a href="#cb105-189" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-190"><a href="#cb105-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-191"><a href="#cb105-191" aria-hidden="true" tabindex="-1"></a>This loop makes trade-offs explicit: if the required sample size exceeds what is feasible, researchers can justify an exploratory framing, add interim analyses, or negotiate for additional resources before data collection begins.</span>
<span id="cb105-192"><a href="#cb105-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-193"><a href="#cb105-193" aria-hidden="true" tabindex="-1"></a><span class="fu">### Justifying Small Sample Sizes</span></span>
<span id="cb105-194"><a href="#cb105-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-195"><a href="#cb105-195" aria-hidden="true" tabindex="-1"></a>When sample sizes are constrained, justify them transparently:</span>
<span id="cb105-196"><a href="#cb105-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-197"><a href="#cb105-197" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>State the target population and accessible population.</span>
<span id="cb105-198"><a href="#cb105-198" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Describe sampling method and rationale.</span>
<span id="cb105-199"><a href="#cb105-199" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Report planned and achieved sample sizes.</span>
<span id="cb105-200"><a href="#cb105-200" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Provide power or precision estimates (confidence interval widths).</span>
<span id="cb105-201"><a href="#cb105-201" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Acknowledge limitations and interpret findings accordingly.</span>
<span id="cb105-202"><a href="#cb105-202" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Frame the study as exploratory or preliminary if appropriate.</span>
<span id="cb105-203"><a href="#cb105-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-204"><a href="#cb105-204" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sample Size Planning Flowchart</span></span>
<span id="cb105-205"><a href="#cb105-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-208"><a href="#cb105-208" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb105-209"><a href="#cb105-209" aria-hidden="true" tabindex="-1"></a>flowchart TD</span>
<span id="cb105-210"><a href="#cb105-210" aria-hidden="true" tabindex="-1"></a>  A[Define research question] --&gt; B[Specify primary outcome <span class="ot">and</span> test]</span>
<span id="cb105-211"><a href="#cb105-211" aria-hidden="true" tabindex="-1"></a>  B --&gt; C[Determine minimally important effect]</span>
<span id="cb105-212"><a href="#cb105-212" aria-hidden="true" tabindex="-1"></a>  C --&gt; D{Effect size from...}</span>
<span id="cb105-213"><a href="#cb105-213" aria-hidden="true" tabindex="-1"></a>  D --&gt;|Pilot data| E[Use observed effect]</span>
<span id="cb105-214"><a href="#cb105-214" aria-hidden="true" tabindex="-1"></a>  D --&gt;|Literature| F[Use meta-analytic estimate]</span>
<span id="cb105-215"><a href="#cb105-215" aria-hidden="true" tabindex="-1"></a>  D --&gt;|Stakeholder| G[Use practical threshold]</span>
<span id="cb105-216"><a href="#cb105-216" aria-hidden="true" tabindex="-1"></a>  E --&gt; H[Conduct power analysis]</span>
<span id="cb105-217"><a href="#cb105-217" aria-hidden="true" tabindex="-1"></a>  F --&gt; H</span>
<span id="cb105-218"><a href="#cb105-218" aria-hidden="true" tabindex="-1"></a>  G --&gt; H</span>
<span id="cb105-219"><a href="#cb105-219" aria-hidden="true" tabindex="-1"></a>  H --&gt; I{Achieve n <span class="kw">for</span> <span class="dv">80</span>% power?}</span>
<span id="cb105-220"><a href="#cb105-220" aria-hidden="true" tabindex="-1"></a>  I --&gt;|Yes| J[Proceed with confirmatory <span class="fu">study</span>]</span>
<span id="cb105-221"><a href="#cb105-221" aria-hidden="true" tabindex="-1"></a>  I --&gt;|No| K[Consider alternatives]</span>
<span id="cb105-222"><a href="#cb105-222" aria-hidden="true" tabindex="-1"></a>  K --&gt; L[Paired/within design?]</span>
<span id="cb105-223"><a href="#cb105-223" aria-hidden="true" tabindex="-1"></a>  K --&gt; M[More sensitive outcome?]</span>
<span id="cb105-224"><a href="#cb105-224" aria-hidden="true" tabindex="-1"></a>  K --&gt; N[Continuous vs. binary?]</span>
<span id="cb105-225"><a href="#cb105-225" aria-hidden="true" tabindex="-1"></a>  K --&gt; O[Bayesian with priors?]</span>
<span id="cb105-226"><a href="#cb105-226" aria-hidden="true" tabindex="-1"></a>  K --&gt; P[Reframe as exploratory pilot]</span>
<span id="cb105-227"><a href="#cb105-227" aria-hidden="true" tabindex="-1"></a>  L --&gt; Q[Recalculate power]</span>
<span id="cb105-228"><a href="#cb105-228" aria-hidden="true" tabindex="-1"></a>  M --&gt; Q</span>
<span id="cb105-229"><a href="#cb105-229" aria-hidden="true" tabindex="-1"></a>  N --&gt; Q</span>
<span id="cb105-230"><a href="#cb105-230" aria-hidden="true" tabindex="-1"></a>  O --&gt; Q</span>
<span id="cb105-231"><a href="#cb105-231" aria-hidden="true" tabindex="-1"></a>  P --&gt; R[Document limitations]</span>
<span id="cb105-232"><a href="#cb105-232" aria-hidden="true" tabindex="-1"></a>  J --&gt; S[Pre-register plan]</span>
<span id="cb105-233"><a href="#cb105-233" aria-hidden="true" tabindex="-1"></a>  Q --&gt; I</span>
<span id="cb105-234"><a href="#cb105-234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-235"><a href="#cb105-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-236"><a href="#cb105-236" aria-hidden="true" tabindex="-1"></a>**Interpretation:** This flowchart guides researchers through sample size planning, showing decision points and alternatives when the target sample size is not feasible.</span>
<span id="cb105-237"><a href="#cb105-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-238"><a href="#cb105-238" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-239"><a href="#cb105-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-240"><a href="#cb105-240" aria-hidden="true" tabindex="-1"></a><span class="fu">### Self-Assessment Quiz</span></span>
<span id="cb105-241"><a href="#cb105-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-242"><a href="#cb105-242" aria-hidden="true" tabindex="-1"></a>Test your understanding of sampling strategies from Chapter 9. Answers and explanations are provided at the end.</span>
<span id="cb105-243"><a href="#cb105-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-244"><a href="#cb105-244" aria-hidden="true" tabindex="-1"></a>::: {.callout-note icon=false}</span>
<span id="cb105-245"><a href="#cb105-245" aria-hidden="true" tabindex="-1"></a><span class="fu">## Questions</span></span>
<span id="cb105-246"><a href="#cb105-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-247"><a href="#cb105-247" aria-hidden="true" tabindex="-1"></a>**Q1.** A researcher uses a "rule of thumb" of n=30 per group for all studies. What is the primary problem with this approach?</span>
<span id="cb105-248"><a href="#cb105-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-249"><a href="#cb105-249" aria-hidden="true" tabindex="-1"></a>A. n=30 is always too small  </span>
<span id="cb105-250"><a href="#cb105-250" aria-hidden="true" tabindex="-1"></a>B. Sample size should depend on effect size, power, and research question—not arbitrary rules  </span>
<span id="cb105-251"><a href="#cb105-251" aria-hidden="true" tabindex="-1"></a>C. n=30 is always too large  </span>
<span id="cb105-252"><a href="#cb105-252" aria-hidden="true" tabindex="-1"></a>D. Rules of thumb are always correct</span>
<span id="cb105-253"><a href="#cb105-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-254"><a href="#cb105-254" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-255"><a href="#cb105-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-256"><a href="#cb105-256" aria-hidden="true" tabindex="-1"></a>**Q2.** Stratified sampling is most useful when:</span>
<span id="cb105-257"><a href="#cb105-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-258"><a href="#cb105-258" aria-hidden="true" tabindex="-1"></a>A. The population is homogeneous  </span>
<span id="cb105-259"><a href="#cb105-259" aria-hidden="true" tabindex="-1"></a>B. You want to ensure representation of key subgroups that differ on the outcome  </span>
<span id="cb105-260"><a href="#cb105-260" aria-hidden="true" tabindex="-1"></a>C. Random selection is impossible  </span>
<span id="cb105-261"><a href="#cb105-261" aria-hidden="true" tabindex="-1"></a>D. Sample size exceeds 1,000</span>
<span id="cb105-262"><a href="#cb105-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-263"><a href="#cb105-263" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-264"><a href="#cb105-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-265"><a href="#cb105-265" aria-hidden="true" tabindex="-1"></a>**Q3.** Power analysis reveals you need n=50 per group, but only n=20 is feasible. What should you do?</span>
<span id="cb105-266"><a href="#cb105-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-267"><a href="#cb105-267" aria-hidden="true" tabindex="-1"></a>A. Abandon the study  </span>
<span id="cb105-268"><a href="#cb105-268" aria-hidden="true" tabindex="-1"></a>B. Proceed, but report the study as exploratory/pilot and calculate minimum detectable effect (MDE)  </span>
<span id="cb105-269"><a href="#cb105-269" aria-hidden="true" tabindex="-1"></a>C. Proceed and claim the same statistical power  </span>
<span id="cb105-270"><a href="#cb105-270" aria-hidden="true" tabindex="-1"></a>D. Ignore power entirely</span>
<span id="cb105-271"><a href="#cb105-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-272"><a href="#cb105-272" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-273"><a href="#cb105-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-274"><a href="#cb105-274" aria-hidden="true" tabindex="-1"></a>**Q4.** Which sampling method allows probabilistic generalization to a target population?</span>
<span id="cb105-275"><a href="#cb105-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-276"><a href="#cb105-276" aria-hidden="true" tabindex="-1"></a>A. Convenience sampling  </span>
<span id="cb105-277"><a href="#cb105-277" aria-hidden="true" tabindex="-1"></a>B. Purposive sampling  </span>
<span id="cb105-278"><a href="#cb105-278" aria-hidden="true" tabindex="-1"></a>C. Simple random sampling  </span>
<span id="cb105-279"><a href="#cb105-279" aria-hidden="true" tabindex="-1"></a>D. Snowball sampling</span>
<span id="cb105-280"><a href="#cb105-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-281"><a href="#cb105-281" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-282"><a href="#cb105-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-283"><a href="#cb105-283" aria-hidden="true" tabindex="-1"></a>**Q5.** Quota sampling differs from stratified sampling in that:</span>
<span id="cb105-284"><a href="#cb105-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-285"><a href="#cb105-285" aria-hidden="true" tabindex="-1"></a>A. It uses random selection within strata  </span>
<span id="cb105-286"><a href="#cb105-286" aria-hidden="true" tabindex="-1"></a>B. It matches population proportions but does not use random selection  </span>
<span id="cb105-287"><a href="#cb105-287" aria-hidden="true" tabindex="-1"></a>C. It requires a sampling frame  </span>
<span id="cb105-288"><a href="#cb105-288" aria-hidden="true" tabindex="-1"></a>D. It is always more accurate</span>
<span id="cb105-289"><a href="#cb105-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-290"><a href="#cb105-290" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-291"><a href="#cb105-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-292"><a href="#cb105-292" aria-hidden="true" tabindex="-1"></a>**Q6.** A study with n=15 per group has 30% power to detect d=0.5. The researcher should report:</span>
<span id="cb105-293"><a href="#cb105-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-294"><a href="#cb105-294" aria-hidden="true" tabindex="-1"></a>A. "The study was adequately powered"  </span>
<span id="cb105-295"><a href="#cb105-295" aria-hidden="true" tabindex="-1"></a>B. "The study was underpowered to detect medium effects; only large effects (d≥1.0) could be reliably detected"  </span>
<span id="cb105-296"><a href="#cb105-296" aria-hidden="true" tabindex="-1"></a>C. "Power is irrelevant with small samples"  </span>
<span id="cb105-297"><a href="#cb105-297" aria-hidden="true" tabindex="-1"></a>D. "Non-significant results prove no effect exists"</span>
<span id="cb105-298"><a href="#cb105-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-299"><a href="#cb105-299" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-300"><a href="#cb105-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-301"><a href="#cb105-301" aria-hidden="true" tabindex="-1"></a>**Q7.** The finite population correction (FPC) is relevant when:</span>
<span id="cb105-302"><a href="#cb105-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-303"><a href="#cb105-303" aria-hidden="true" tabindex="-1"></a>A. Sampling with replacement from an infinite population  </span>
<span id="cb105-304"><a href="#cb105-304" aria-hidden="true" tabindex="-1"></a>B. Sampling without replacement from a small, known population (e.g., N=100)  </span>
<span id="cb105-305"><a href="#cb105-305" aria-hidden="true" tabindex="-1"></a>C. Sample size exceeds population size  </span>
<span id="cb105-306"><a href="#cb105-306" aria-hidden="true" tabindex="-1"></a>D. Using convenience sampling</span>
<span id="cb105-307"><a href="#cb105-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-308"><a href="#cb105-308" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-309"><a href="#cb105-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-310"><a href="#cb105-310" aria-hidden="true" tabindex="-1"></a>**Q8.** Sequential sampling allows researchers to:</span>
<span id="cb105-311"><a href="#cb105-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-312"><a href="#cb105-312" aria-hidden="true" tabindex="-1"></a>A. Collect all data simultaneously  </span>
<span id="cb105-313"><a href="#cb105-313" aria-hidden="true" tabindex="-1"></a>B. Stop early if interim results show sufficient precision or evidence  </span>
<span id="cb105-314"><a href="#cb105-314" aria-hidden="true" tabindex="-1"></a>C. Ignore power analysis  </span>
<span id="cb105-315"><a href="#cb105-315" aria-hidden="true" tabindex="-1"></a>D. Change hypotheses after seeing data</span>
<span id="cb105-316"><a href="#cb105-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-317"><a href="#cb105-317" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-318"><a href="#cb105-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-319"><a href="#cb105-319" aria-hidden="true" tabindex="-1"></a>**Q9.** A convenience sample from one university is used to test a new teaching method. Which statement is TRUE?</span>
<span id="cb105-320"><a href="#cb105-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-321"><a href="#cb105-321" aria-hidden="true" tabindex="-1"></a>A. Results generalize to all universities  </span>
<span id="cb105-322"><a href="#cb105-322" aria-hidden="true" tabindex="-1"></a>B. Results are context-specific and require replication  </span>
<span id="cb105-323"><a href="#cb105-323" aria-hidden="true" tabindex="-1"></a>C. Convenience sampling is never acceptable  </span>
<span id="cb105-324"><a href="#cb105-324" aria-hidden="true" tabindex="-1"></a>D. Results are as valid as random sampling</span>
<span id="cb105-325"><a href="#cb105-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-326"><a href="#cb105-326" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-327"><a href="#cb105-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-328"><a href="#cb105-328" aria-hidden="true" tabindex="-1"></a>**Q10.** Minimum Detectable Effect (MDE) refers to:</span>
<span id="cb105-329"><a href="#cb105-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-330"><a href="#cb105-330" aria-hidden="true" tabindex="-1"></a>A. The smallest effect that exists in the population  </span>
<span id="cb105-331"><a href="#cb105-331" aria-hidden="true" tabindex="-1"></a>B. The smallest effect the study can detect with specified power (e.g., 80%)  </span>
<span id="cb105-332"><a href="#cb105-332" aria-hidden="true" tabindex="-1"></a>C. The p-value threshold  </span>
<span id="cb105-333"><a href="#cb105-333" aria-hidden="true" tabindex="-1"></a>D. The confidence interval width</span>
<span id="cb105-334"><a href="#cb105-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-335"><a href="#cb105-335" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb105-336"><a href="#cb105-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-337"><a href="#cb105-337" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip icon=false collapse="true"}</span>
<span id="cb105-338"><a href="#cb105-338" aria-hidden="true" tabindex="-1"></a><span class="fu">## Answers and Explanations</span></span>
<span id="cb105-339"><a href="#cb105-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-340"><a href="#cb105-340" aria-hidden="true" tabindex="-1"></a>**Q1. Answer: B**  </span>
<span id="cb105-341"><a href="#cb105-341" aria-hidden="true" tabindex="-1"></a>*Explanation*: Sample size should depend on effect size, power, and research question—not arbitrary rules. A small effect requires larger n; a large effect can be detected with smaller n. The chapter emphasizes: "Rather than abandoning research in such contexts, we should adopt methods suited to smaller samples and report findings with appropriate caveats."</span>
<span id="cb105-342"><a href="#cb105-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-343"><a href="#cb105-343" aria-hidden="true" tabindex="-1"></a>**Q2. Answer: B**  </span>
<span id="cb105-344"><a href="#cb105-344" aria-hidden="true" tabindex="-1"></a>*Explanation*: Stratified sampling divides the population into strata and ensures each stratum is represented. This improves precision when strata differ on the outcome. The chapter states: "Stratified sampling (dividing the population into strata and sampling proportionally or disproportionally from each) can improve precision by ensuring representation of key subgroups."</span>
<span id="cb105-345"><a href="#cb105-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-346"><a href="#cb105-346" aria-hidden="true" tabindex="-1"></a>**Q3. Answer: B**  </span>
<span id="cb105-347"><a href="#cb105-347" aria-hidden="true" tabindex="-1"></a>*Explanation*: Proceed, but report the study as exploratory/pilot and calculate minimum detectable effect (MDE). Transparency about power limitations is essential. The chapter recommends: "If the achieved sample size is smaller than desired, report the minimum detectable effect (MDE)."</span>
<span id="cb105-348"><a href="#cb105-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-349"><a href="#cb105-349" aria-hidden="true" tabindex="-1"></a>**Q4. Answer: C**  </span>
<span id="cb105-350"><a href="#cb105-350" aria-hidden="true" tabindex="-1"></a>*Explanation*: Simple random sampling (and other probability sampling methods) ensures every unit has a known, non-zero probability of selection, supporting generalization. The chapter states: "Probability sampling...ensures that every unit has a known, non-zero probability of selection. This supports generalisation to the target population."</span>
<span id="cb105-351"><a href="#cb105-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-352"><a href="#cb105-352" aria-hidden="true" tabindex="-1"></a>**Q5. Answer: B**  </span>
<span id="cb105-353"><a href="#cb105-353" aria-hidden="true" tabindex="-1"></a>*Explanation*: Quota sampling matches population proportions but does not use random selection within strata. It "mimics stratified sampling but without random selection within strata." This makes it non-probabilistic.</span>
<span id="cb105-354"><a href="#cb105-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-355"><a href="#cb105-355" aria-hidden="true" tabindex="-1"></a>**Q6. Answer: B**  </span>
<span id="cb105-356"><a href="#cb105-356" aria-hidden="true" tabindex="-1"></a>*Explanation*: With 30% power for d=0.5, the study can only reliably detect large effects (d≥1.0, which has ~80% power with n=15). The chapter emphasizes transparent reporting: "Researchers should conduct power analyses before data collection to understand what effects are detectable."</span>
<span id="cb105-357"><a href="#cb105-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-358"><a href="#cb105-358" aria-hidden="true" tabindex="-1"></a>**Q7. Answer: B**  </span>
<span id="cb105-359"><a href="#cb105-359" aria-hidden="true" tabindex="-1"></a>*Explanation*: FPC adjusts required sample size when sampling without replacement from a small, finite population. The chapter explains: "When sampling without replacement from a small, known population, the variance of estimates decreases...The finite population correction (FPC) adjusts the required sample size accordingly."</span>
<span id="cb105-360"><a href="#cb105-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-361"><a href="#cb105-361" aria-hidden="true" tabindex="-1"></a>**Q8. Answer: B**  </span>
<span id="cb105-362"><a href="#cb105-362" aria-hidden="true" tabindex="-1"></a>*Explanation*: Sequential sampling allows stopping early based on pre-specified decision rules if interim results show sufficient precision or evidence. The chapter describes: "sequential designs allow researchers to review interim results and decide whether to continue sampling."</span>
<span id="cb105-363"><a href="#cb105-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-364"><a href="#cb105-364" aria-hidden="true" tabindex="-1"></a>**Q9. Answer: B**  </span>
<span id="cb105-365"><a href="#cb105-365" aria-hidden="true" tabindex="-1"></a>*Explanation*: Convenience samples are context-specific and require replication. The chapter states: "Findings from purposive or convenience samples should be interpreted cautiously and presented as preliminary or context-specific. Replication in independent samples strengthens confidence."</span>
<span id="cb105-366"><a href="#cb105-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-367"><a href="#cb105-367" aria-hidden="true" tabindex="-1"></a>**Q10. Answer: B**  </span>
<span id="cb105-368"><a href="#cb105-368" aria-hidden="true" tabindex="-1"></a>*Explanation*: MDE is the smallest effect the study can detect with specified power (typically 80%) and alpha (typically 0.05). The chapter defines it: "the minimum detectable effect (MDE): the smallest effect the study can detect with specified power."</span>
<span id="cb105-369"><a href="#cb105-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-370"><a href="#cb105-370" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb105-371"><a href="#cb105-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-372"><a href="#cb105-372" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-373"><a href="#cb105-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-374"><a href="#cb105-374" aria-hidden="true" tabindex="-1"></a><span class="fu">### Key Takeaways</span></span>
<span id="cb105-375"><a href="#cb105-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-376"><a href="#cb105-376" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Probability sampling supports generalisation but may be infeasible with small samples or rare populations.</span>
<span id="cb105-377"><a href="#cb105-377" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Stratified sampling can improve precision by ensuring representation of key subgroups.</span>
<span id="cb105-378"><a href="#cb105-378" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Purposive and convenience sampling are common in small-sample research but limit generalisability.</span>
<span id="cb105-379"><a href="#cb105-379" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Quota sampling balances sample composition without requiring random selection.</span>
<span id="cb105-380"><a href="#cb105-380" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Power analyses reveal what effects are detectable given sample size; small samples have limited power for detecting small or medium effects.</span>
<span id="cb105-381"><a href="#cb105-381" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Transparent reporting of sampling methods, achieved sample sizes, and power or precision estimates is essential for interpreting small-sample findings.</span>
<span id="cb105-382"><a href="#cb105-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-383"><a href="#cb105-383" aria-hidden="true" tabindex="-1"></a><span class="fu">### Smoke Test</span></span>
<span id="cb105-384"><a href="#cb105-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-387"><a href="#cb105-387" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-388"><a href="#cb105-388" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-04</span></span>
<span id="cb105-389"><a href="#cb105-389" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run stratified allocation</span></span>
<span id="cb105-390"><a href="#cb105-390" aria-hidden="true" tabindex="-1"></a>departments <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">60</span>, <span class="dv">40</span>, <span class="dv">20</span>)</span>
<span id="cb105-391"><a href="#cb105-391" aria-hidden="true" tabindex="-1"></a>total_n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb105-392"><a href="#cb105-392" aria-hidden="true" tabindex="-1"></a>allocation <span class="ot">&lt;-</span> <span class="fu">round</span>((departments <span class="sc">/</span> <span class="fu">sum</span>(departments)) <span class="sc">*</span> total_n)</span>
<span id="cb105-393"><a href="#cb105-393" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(allocation)</span>
<span id="cb105-394"><a href="#cb105-394" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-395"><a href="#cb105-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-396"><a href="#cb105-396" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-397"><a href="#cb105-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-398"><a href="#cb105-398" aria-hidden="true" tabindex="-1"></a><span class="fu">## Chapter 10. Measurement Quality and Scale Development</span></span>
<span id="cb105-399"><a href="#cb105-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-400"><a href="#cb105-400" aria-hidden="true" tabindex="-1"></a><span class="fu">### Learning Objectives</span></span>
<span id="cb105-401"><a href="#cb105-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-402"><a href="#cb105-402" aria-hidden="true" tabindex="-1"></a>By the end of this chapter, you will be able to:</span>
<span id="cb105-403"><a href="#cb105-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-404"><a href="#cb105-404" aria-hidden="true" tabindex="-1"></a>**Conceptual Understanding**</span>
<span id="cb105-405"><a href="#cb105-405" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Explain the distinctions between content, construct, and criterion validity</span>
<span id="cb105-406"><a href="#cb105-406" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Understand reliability theory and sources of measurement error</span>
<span id="cb105-407"><a href="#cb105-407" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Recognize the limitations of psychometric analyses with small samples</span>
<span id="cb105-408"><a href="#cb105-408" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Distinguish quantitative vs. qualitative approaches to scale validation</span>
<span id="cb105-409"><a href="#cb105-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-410"><a href="#cb105-410" aria-hidden="true" tabindex="-1"></a>**Practical Skills**</span>
<span id="cb105-411"><a href="#cb105-411" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Pilot test scales and collect qualitative feedback with small samples</span>
<span id="cb105-412"><a href="#cb105-412" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Compute item-level statistics (means, SDs, correlations) in R</span>
<span id="cb105-413"><a href="#cb105-413" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Calculate internal consistency (Cronbach's α) and interpret appropriately</span>
<span id="cb105-414"><a href="#cb105-414" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Identify problematic items using discrimination and ceiling/floor effects</span>
<span id="cb105-415"><a href="#cb105-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-416"><a href="#cb105-416" aria-hidden="true" tabindex="-1"></a>**Critical Evaluation**</span>
<span id="cb105-417"><a href="#cb105-417" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Assess when sample sizes are adequate for factor analysis vs. when to defer</span>
<span id="cb105-418"><a href="#cb105-418" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Evaluate the trade-off between brief scales (fewer items) and reliability</span>
<span id="cb105-419"><a href="#cb105-419" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Critique whether items have content validity for the intended construct</span>
<span id="cb105-420"><a href="#cb105-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-421"><a href="#cb105-421" aria-hidden="true" tabindex="-1"></a>**Application**</span>
<span id="cb105-422"><a href="#cb105-422" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Design iterative scale refinement processes with limited samples</span>
<span id="cb105-423"><a href="#cb105-423" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Report scale properties transparently (including small-sample limitations)</span>
<span id="cb105-424"><a href="#cb105-424" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Prioritize qualitative feedback over unstable quantitative indices when appropriate</span>
<span id="cb105-425"><a href="#cb105-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-426"><a href="#cb105-426" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Challenge of Measurement in Small Studies</span></span>
<span id="cb105-427"><a href="#cb105-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-428"><a href="#cb105-428" aria-hidden="true" tabindex="-1"></a>Many small-sample studies rely on brief, custom-developed measurement instruments. Standard scale development protocols (large pilot studies, factor analysis, item response theory) require hundreds of observations. With small samples, researchers must balance the need for reliable, valid measurement with practical constraints.</span>
<span id="cb105-429"><a href="#cb105-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-430"><a href="#cb105-430" aria-hidden="true" tabindex="-1"></a>Short scales (3–5 items) can be internally consistent and valid if items are carefully chosen. Pilot testing with qualitative feedback (cognitive interviews, think-aloud protocols) can identify ambiguous wording, response biases, and cultural appropriateness. Quantitative pilot data (even with n ≈ 20–30) can reveal extreme floor or ceiling effects, items with no variance, and obvious inconsistencies.</span>
<span id="cb105-431"><a href="#cb105-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-432"><a href="#cb105-432" aria-hidden="true" tabindex="-1"></a><span class="fu">### Content and Face Validity</span></span>
<span id="cb105-433"><a href="#cb105-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-434"><a href="#cb105-434" aria-hidden="true" tabindex="-1"></a>Content validity refers to whether items comprehensively and appropriately represent the construct being measured. Face validity refers to whether items appear relevant and appropriate to respondents. Both are assessed through expert review and respondent feedback, not statistical tests.</span>
<span id="cb105-435"><a href="#cb105-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-436"><a href="#cb105-436" aria-hidden="true" tabindex="-1"></a>**When to assess**: During scale development, before quantitative pilot testing. Involves domain experts and representatives of the target population.</span>
<span id="cb105-437"><a href="#cb105-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-438"><a href="#cb105-438" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Content Validity Ratio (CVR)</span></span>
<span id="cb105-439"><a href="#cb105-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-440"><a href="#cb105-440" aria-hidden="true" tabindex="-1"></a>Lawshe's Content Validity Ratio provides a simple index of expert agreement on whether an item is "essential" to a construct. With *N* experts and *N*<span class="dt">&lt;</span><span class="kw">sub</span><span class="dt">&gt;</span>e<span class="dt">&lt;/</span><span class="kw">sub</span><span class="dt">&gt;</span> rating an item as essential, the CVR is:</span>
<span id="cb105-441"><a href="#cb105-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-442"><a href="#cb105-442" aria-hidden="true" tabindex="-1"></a><span class="sc">\[</span></span>
<span id="cb105-443"><a href="#cb105-443" aria-hidden="true" tabindex="-1"></a>\operatorname{CVR} = \frac{N_e - N/2}{N/2}</span>
<span id="cb105-444"><a href="#cb105-444" aria-hidden="true" tabindex="-1"></a><span class="sc">\]</span></span>
<span id="cb105-445"><a href="#cb105-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-446"><a href="#cb105-446" aria-hidden="true" tabindex="-1"></a>CVR ranges from −1 to +1. Positive values indicate majority agreement that the item is essential; thresholds depend on the number of experts (e.g., ≥0.75 when *N* = 8). Use CVR alongside qualitative feedback to decide which items to retain.</span>
<span id="cb105-447"><a href="#cb105-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-450"><a href="#cb105-450" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-451"><a href="#cb105-451" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-05</span></span>
<span id="cb105-452"><a href="#cb105-452" aria-hidden="true" tabindex="-1"></a><span class="co"># CVR example: 8 experts, 6 judge the item essential</span></span>
<span id="cb105-453"><a href="#cb105-453" aria-hidden="true" tabindex="-1"></a>n_experts <span class="ot">&lt;-</span> <span class="dv">8</span></span>
<span id="cb105-454"><a href="#cb105-454" aria-hidden="true" tabindex="-1"></a>n_essential <span class="ot">&lt;-</span> <span class="dv">6</span></span>
<span id="cb105-455"><a href="#cb105-455" aria-hidden="true" tabindex="-1"></a>cvr <span class="ot">&lt;-</span> (n_essential <span class="sc">-</span> n_experts <span class="sc">/</span> <span class="dv">2</span>) <span class="sc">/</span> (n_experts <span class="sc">/</span> <span class="dv">2</span>)</span>
<span id="cb105-456"><a href="#cb105-456" aria-hidden="true" tabindex="-1"></a>cvr</span>
<span id="cb105-457"><a href="#cb105-457" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-458"><a href="#cb105-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-459"><a href="#cb105-459" aria-hidden="true" tabindex="-1"></a>Interpretation: A CVR of 0.50 indicates that 75% of experts deemed the item essential. Consult published critical values to confirm whether the item meets the desired level of agreement for your expert panel size.</span>
<span id="cb105-460"><a href="#cb105-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-461"><a href="#cb105-461" aria-hidden="true" tabindex="-1"></a><span class="fu">### Steps for Scale Development with Small Samples</span></span>
<span id="cb105-462"><a href="#cb105-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-463"><a href="#cb105-463" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Define the construct clearly**: What are you measuring? What are its dimensions or facets?</span>
<span id="cb105-464"><a href="#cb105-464" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Generate candidate items**: Write more items than needed (e.g., 10–15 items for a final 5-item scale).</span>
<span id="cb105-465"><a href="#cb105-465" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Expert review**: Ask domain experts to rate item relevance, clarity, and representativeness.</span>
<span id="cb105-466"><a href="#cb105-466" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Cognitive interviews**: Ask a few respondents (n = 5–10) to complete the scale and think aloud, explaining their interpretations and any confusion.</span>
<span id="cb105-467"><a href="#cb105-467" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Quantitative pilot**: Administer the scale to a small sample (n = 20–40) and compute item statistics.</span>
<span id="cb105-468"><a href="#cb105-468" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**Item analysis**: Identify problematic items (low variance, weak correlations with total score, ceiling/floor effects).</span>
<span id="cb105-469"><a href="#cb105-469" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>**Refine and re-test**: Remove or revise problematic items and retest if resources permit.</span>
<span id="cb105-470"><a href="#cb105-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-471"><a href="#cb105-471" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example: Item Analysis for a Pilot Scale</span></span>
<span id="cb105-472"><a href="#cb105-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-473"><a href="#cb105-473" aria-hidden="true" tabindex="-1"></a>We pilot a 5-item job satisfaction scale with n = 25 employees. Each item uses a 1–7 Likert response.</span>
<span id="cb105-474"><a href="#cb105-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-477"><a href="#cb105-477" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-478"><a href="#cb105-478" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-06</span></span>
<span id="cb105-479"><a href="#cb105-479" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb105-480"><a href="#cb105-480" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb105-481"><a href="#cb105-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-482"><a href="#cb105-482" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb105-483"><a href="#cb105-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-484"><a href="#cb105-484" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated pilot data: 25 respondents, 5 items</span></span>
<span id="cb105-485"><a href="#cb105-485" aria-hidden="true" tabindex="-1"></a>pilot_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb105-486"><a href="#cb105-486" aria-hidden="true" tabindex="-1"></a>  <span class="at">respondent =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">25</span>,</span>
<span id="cb105-487"><a href="#cb105-487" aria-hidden="true" tabindex="-1"></a>  <span class="at">item1 =</span> <span class="fu">sample</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">7</span>, <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.25</span>, <span class="fl">0.15</span>)),</span>
<span id="cb105-488"><a href="#cb105-488" aria-hidden="true" tabindex="-1"></a>  <span class="at">item2 =</span> <span class="fu">sample</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>, <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.15</span>, <span class="fl">0.25</span>, <span class="fl">0.25</span>, <span class="fl">0.15</span>, <span class="fl">0.1</span>)),</span>
<span id="cb105-489"><a href="#cb105-489" aria-hidden="true" tabindex="-1"></a>  <span class="at">item3 =</span> <span class="fu">sample</span>(<span class="dv">4</span><span class="sc">:</span><span class="dv">7</span>, <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.3</span>, <span class="fl">0.2</span>)),  <span class="co"># restricted range</span></span>
<span id="cb105-490"><a href="#cb105-490" aria-hidden="true" tabindex="-1"></a>  <span class="at">item4 =</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>, <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>),</span>
<span id="cb105-491"><a href="#cb105-491" aria-hidden="true" tabindex="-1"></a>  <span class="at">item5 =</span> <span class="fu">sample</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>, <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.15</span>, <span class="fl">0.2</span>, <span class="fl">0.25</span>, <span class="fl">0.2</span>, <span class="fl">0.15</span>, <span class="fl">0.05</span>))</span>
<span id="cb105-492"><a href="#cb105-492" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb105-493"><a href="#cb105-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-494"><a href="#cb105-494" aria-hidden="true" tabindex="-1"></a><span class="co"># Item descriptive statistics</span></span>
<span id="cb105-495"><a href="#cb105-495" aria-hidden="true" tabindex="-1"></a>item_stats <span class="ot">&lt;-</span> pilot_data <span class="sc">%&gt;%</span></span>
<span id="cb105-496"><a href="#cb105-496" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">starts_with</span>(<span class="st">"item"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb105-497"><a href="#cb105-497" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), <span class="fu">list</span>(</span>
<span id="cb105-498"><a href="#cb105-498" aria-hidden="true" tabindex="-1"></a>    <span class="at">mean =</span> mean,</span>
<span id="cb105-499"><a href="#cb105-499" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd =</span> sd,</span>
<span id="cb105-500"><a href="#cb105-500" aria-hidden="true" tabindex="-1"></a>    <span class="at">min =</span> min,</span>
<span id="cb105-501"><a href="#cb105-501" aria-hidden="true" tabindex="-1"></a>    <span class="at">max =</span> max</span>
<span id="cb105-502"><a href="#cb105-502" aria-hidden="true" tabindex="-1"></a>  ))) <span class="sc">%&gt;%</span></span>
<span id="cb105-503"><a href="#cb105-503" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">everything</span>(), <span class="at">names_to =</span> <span class="fu">c</span>(<span class="st">"item"</span>, <span class="st">".value"</span>), <span class="at">names_sep =</span> <span class="st">"_"</span>)</span>
<span id="cb105-504"><a href="#cb105-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-505"><a href="#cb105-505" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(item_stats)</span>
<span id="cb105-506"><a href="#cb105-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-507"><a href="#cb105-507" aria-hidden="true" tabindex="-1"></a><span class="co"># Inter-item correlations</span></span>
<span id="cb105-508"><a href="#cb105-508" aria-hidden="true" tabindex="-1"></a>items_only <span class="ot">&lt;-</span> <span class="fu">select</span>(pilot_data, <span class="fu">starts_with</span>(<span class="st">"item"</span>))</span>
<span id="cb105-509"><a href="#cb105-509" aria-hidden="true" tabindex="-1"></a>cor_matrix <span class="ot">&lt;-</span> <span class="fu">cor</span>(items_only)</span>
<span id="cb105-510"><a href="#cb105-510" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">round</span>(cor_matrix, <span class="dv">2</span>))</span>
<span id="cb105-511"><a href="#cb105-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-512"><a href="#cb105-512" aria-hidden="true" tabindex="-1"></a><span class="co"># Item-total correlations (corrected for item overlap)</span></span>
<span id="cb105-513"><a href="#cb105-513" aria-hidden="true" tabindex="-1"></a>item_total <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(items_only)<span class="sc">$</span>item.stats</span>
<span id="cb105-514"><a href="#cb105-514" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(item_total)</span>
<span id="cb105-515"><a href="#cb105-515" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-516"><a href="#cb105-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-517"><a href="#cb105-517" aria-hidden="true" tabindex="-1"></a>Interpretation: Examine item means and standard deviations. Items with very high or low means and small SDs may have ceiling or floor effects (most respondents give the same response). Item 3 has a restricted range (4–7), which may indicate a ceiling effect. Inter-item correlations should be positive and moderate (0.3–0.7). Very low correlations suggest an item does not measure the same construct; very high correlations suggest redundancy. The corrected item-total correlation (r.drop) indicates how well each item correlates with the total score excluding itself. Values below 0.3 suggest weak items that could be removed.</span>
<span id="cb105-518"><a href="#cb105-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-519"><a href="#cb105-519" aria-hidden="true" tabindex="-1"></a><span class="fu">### Identifying Problematic Items</span></span>
<span id="cb105-520"><a href="#cb105-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-521"><a href="#cb105-521" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Low variance**: If an item has very small SD (e.g., &lt; 1.0 on a 1–7 scale), most respondents are giving the same answer. The item may be too extreme, too obvious, or poorly worded.</span>
<span id="cb105-522"><a href="#cb105-522" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Weak item-total correlation**: Items with corrected item-total correlations below 0.3 do not discriminate well and may be measuring something different.</span>
<span id="cb105-523"><a href="#cb105-523" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Floor or ceiling effects**: If most responses cluster at the low or high end, the item cannot differentiate among respondents.</span>
<span id="cb105-524"><a href="#cb105-524" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Negative correlations**: If an item correlates negatively with the total or with other items, it may be reverse-coded incorrectly or measuring an opposite construct.</span>
<span id="cb105-525"><a href="#cb105-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-526"><a href="#cb105-526" aria-hidden="true" tabindex="-1"></a><span class="fu">### Refining the Scale</span></span>
<span id="cb105-527"><a href="#cb105-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-528"><a href="#cb105-528" aria-hidden="true" tabindex="-1"></a>Based on item analysis, revise or remove problematic items. For example, if Item 3 shows a ceiling effect and Item 4 has weak item-total correlation, consider removing them. Compute alpha for the revised scale.</span>
<span id="cb105-529"><a href="#cb105-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-532"><a href="#cb105-532" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-533"><a href="#cb105-533" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-07</span></span>
<span id="cb105-534"><a href="#cb105-534" aria-hidden="true" tabindex="-1"></a><span class="co"># Revised scale: remove item3 and item4</span></span>
<span id="cb105-535"><a href="#cb105-535" aria-hidden="true" tabindex="-1"></a>revised_items <span class="ot">&lt;-</span> <span class="fu">select</span>(pilot_data, item1, item2, item5)</span>
<span id="cb105-536"><a href="#cb105-536" aria-hidden="true" tabindex="-1"></a>alpha_revised <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(revised_items)</span>
<span id="cb105-537"><a href="#cb105-537" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(alpha_revised)</span>
<span id="cb105-538"><a href="#cb105-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-539"><a href="#cb105-539" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Cronbach's alpha for revised 3-item scale:"</span>, <span class="fu">round</span>(alpha_revised<span class="sc">$</span>total<span class="sc">$</span>raw_alpha, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-540"><a href="#cb105-540" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-541"><a href="#cb105-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-542"><a href="#cb105-542" aria-hidden="true" tabindex="-1"></a>Interpretation: The revised scale may have higher alpha if problematic items are removed. However, removing items also reduces scale length, which can lower alpha. The goal is a balance: retain enough items for adequate reliability, but remove items that degrade validity or add no information.</span>
<span id="cb105-543"><a href="#cb105-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-544"><a href="#cb105-544" aria-hidden="true" tabindex="-1"></a><span class="fu">### Qualitative Feedback and Cognitive Interviews</span></span>
<span id="cb105-545"><a href="#cb105-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-546"><a href="#cb105-546" aria-hidden="true" tabindex="-1"></a>With very small samples (n &lt; 20), quantitative item analysis is unreliable. Qualitative methods (cognitive interviews, focus groups) are more informative. Ask respondents:</span>
<span id="cb105-547"><a href="#cb105-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-548"><a href="#cb105-548" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>What does each item mean to you?</span>
<span id="cb105-549"><a href="#cb105-549" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Were any items confusing, ambiguous, or difficult to answer?</span>
<span id="cb105-550"><a href="#cb105-550" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Are the response options appropriate?</span>
<span id="cb105-551"><a href="#cb105-551" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Are any items culturally inappropriate or offensive?</span>
<span id="cb105-552"><a href="#cb105-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-553"><a href="#cb105-553" aria-hidden="true" tabindex="-1"></a>This feedback can prevent major problems before larger-scale data collection.</span>
<span id="cb105-554"><a href="#cb105-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-555"><a href="#cb105-555" aria-hidden="true" tabindex="-1"></a><span class="fu">### Self-Assessment Quiz</span></span>
<span id="cb105-556"><a href="#cb105-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-557"><a href="#cb105-557" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb105-558"><a href="#cb105-558" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Chapter 10 Questions</span></span>
<span id="cb105-559"><a href="#cb105-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-560"><a href="#cb105-560" aria-hidden="true" tabindex="-1"></a>**Q1.** What is the primary advantage of using qualitative methods (cognitive interviews) over quantitative methods when pilot testing scales with very small samples (n &lt; 20)?</span>
<span id="cb105-561"><a href="#cb105-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-562"><a href="#cb105-562" aria-hidden="true" tabindex="-1"></a>A) Cognitive interviews provide more statistical power  </span>
<span id="cb105-563"><a href="#cb105-563" aria-hidden="true" tabindex="-1"></a>B) Qualitative feedback can identify ambiguous wording and cultural issues without requiring statistical reliability  </span>
<span id="cb105-564"><a href="#cb105-564" aria-hidden="true" tabindex="-1"></a>C) Quantitative item analysis is too expensive  </span>
<span id="cb105-565"><a href="#cb105-565" aria-hidden="true" tabindex="-1"></a>D) Cognitive interviews automatically calculate Cronbach's alpha</span>
<span id="cb105-566"><a href="#cb105-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-567"><a href="#cb105-567" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-568"><a href="#cb105-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-569"><a href="#cb105-569" aria-hidden="true" tabindex="-1"></a>**Q2.** In Lawshe's Content Validity Ratio (CVR), if 8 experts are consulted and 6 judge an item as "essential," what is the CVR?</span>
<span id="cb105-570"><a href="#cb105-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-571"><a href="#cb105-571" aria-hidden="true" tabindex="-1"></a>A) 0.25  </span>
<span id="cb105-572"><a href="#cb105-572" aria-hidden="true" tabindex="-1"></a>B) 0.50  </span>
<span id="cb105-573"><a href="#cb105-573" aria-hidden="true" tabindex="-1"></a>C) 0.75  </span>
<span id="cb105-574"><a href="#cb105-574" aria-hidden="true" tabindex="-1"></a>D) 1.00</span>
<span id="cb105-575"><a href="#cb105-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-576"><a href="#cb105-576" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-577"><a href="#cb105-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-578"><a href="#cb105-578" aria-hidden="true" tabindex="-1"></a>**Q3.** What does a "ceiling effect" in item analysis indicate?</span>
<span id="cb105-579"><a href="#cb105-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-580"><a href="#cb105-580" aria-hidden="true" tabindex="-1"></a>A) Most respondents give the lowest possible response  </span>
<span id="cb105-581"><a href="#cb105-581" aria-hidden="true" tabindex="-1"></a>B) Most respondents give the highest possible response  </span>
<span id="cb105-582"><a href="#cb105-582" aria-hidden="true" tabindex="-1"></a>C) The item has perfect reliability  </span>
<span id="cb105-583"><a href="#cb105-583" aria-hidden="true" tabindex="-1"></a>D) The item correlates negatively with the total score</span>
<span id="cb105-584"><a href="#cb105-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-585"><a href="#cb105-585" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-586"><a href="#cb105-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-587"><a href="#cb105-587" aria-hidden="true" tabindex="-1"></a>**Q4.** Which corrected item-total correlation threshold typically indicates that an item discriminates poorly and should be considered for removal?</span>
<span id="cb105-588"><a href="#cb105-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-589"><a href="#cb105-589" aria-hidden="true" tabindex="-1"></a>A) Above 0.7  </span>
<span id="cb105-590"><a href="#cb105-590" aria-hidden="true" tabindex="-1"></a>B) Between 0.3 and 0.7  </span>
<span id="cb105-591"><a href="#cb105-591" aria-hidden="true" tabindex="-1"></a>C) Below 0.3  </span>
<span id="cb105-592"><a href="#cb105-592" aria-hidden="true" tabindex="-1"></a>D) Exactly 0.5</span>
<span id="cb105-593"><a href="#cb105-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-594"><a href="#cb105-594" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-595"><a href="#cb105-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-596"><a href="#cb105-596" aria-hidden="true" tabindex="-1"></a>**Q5.** What does content validity assess?</span>
<span id="cb105-597"><a href="#cb105-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-598"><a href="#cb105-598" aria-hidden="true" tabindex="-1"></a>A) Whether items comprehensively and appropriately represent the construct being measured  </span>
<span id="cb105-599"><a href="#cb105-599" aria-hidden="true" tabindex="-1"></a>B) Whether the scale has high Cronbach's alpha  </span>
<span id="cb105-600"><a href="#cb105-600" aria-hidden="true" tabindex="-1"></a>C) Whether factor analysis confirms a one-dimensional structure  </span>
<span id="cb105-601"><a href="#cb105-601" aria-hidden="true" tabindex="-1"></a>D) Whether the scale predicts future behavior</span>
<span id="cb105-602"><a href="#cb105-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-603"><a href="#cb105-603" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-604"><a href="#cb105-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-605"><a href="#cb105-605" aria-hidden="true" tabindex="-1"></a>**Q6.** Why might short scales (3–5 items) have lower Cronbach's alpha than longer scales, even if items are well-chosen?</span>
<span id="cb105-606"><a href="#cb105-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-607"><a href="#cb105-607" aria-hidden="true" tabindex="-1"></a>A) Short scales always measure different constructs  </span>
<span id="cb105-608"><a href="#cb105-608" aria-hidden="true" tabindex="-1"></a>B) Cronbach's alpha is mathematically influenced by the number of items—fewer items tend to yield lower alpha  </span>
<span id="cb105-609"><a href="#cb105-609" aria-hidden="true" tabindex="-1"></a>C) Short scales cannot be reliable  </span>
<span id="cb105-610"><a href="#cb105-610" aria-hidden="true" tabindex="-1"></a>D) Respondents don't take short scales seriously</span>
<span id="cb105-611"><a href="#cb105-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-612"><a href="#cb105-612" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-613"><a href="#cb105-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-614"><a href="#cb105-614" aria-hidden="true" tabindex="-1"></a>**Q7.** In pilot testing with small samples (n ≈ 20–30), what is the primary limitation of conducting factor analysis?</span>
<span id="cb105-615"><a href="#cb105-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-616"><a href="#cb105-616" aria-hidden="true" tabindex="-1"></a>A) Factor analysis requires specialized software  </span>
<span id="cb105-617"><a href="#cb105-617" aria-hidden="true" tabindex="-1"></a>B) Factor analysis requires hundreds of observations for stable results; small samples yield unstable loadings  </span>
<span id="cb105-618"><a href="#cb105-618" aria-hidden="true" tabindex="-1"></a>C) Factor analysis only works with 7-point Likert scales  </span>
<span id="cb105-619"><a href="#cb105-619" aria-hidden="true" tabindex="-1"></a>D) Factor analysis cannot handle missing data</span>
<span id="cb105-620"><a href="#cb105-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-621"><a href="#cb105-621" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-622"><a href="#cb105-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-623"><a href="#cb105-623" aria-hidden="true" tabindex="-1"></a>**Q8.** If an item correlates negatively with the total score and with other items, what is the most likely explanation?</span>
<span id="cb105-624"><a href="#cb105-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-625"><a href="#cb105-625" aria-hidden="true" tabindex="-1"></a>A) The item has high content validity  </span>
<span id="cb105-626"><a href="#cb105-626" aria-hidden="true" tabindex="-1"></a>B) The item may be reverse-coded incorrectly or measuring an opposite construct  </span>
<span id="cb105-627"><a href="#cb105-627" aria-hidden="true" tabindex="-1"></a>C) The sample size is too large  </span>
<span id="cb105-628"><a href="#cb105-628" aria-hidden="true" tabindex="-1"></a>D) The item has a ceiling effect</span>
<span id="cb105-629"><a href="#cb105-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-630"><a href="#cb105-630" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-631"><a href="#cb105-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-632"><a href="#cb105-632" aria-hidden="true" tabindex="-1"></a>**Q9.** What is the primary purpose of asking domain experts to rate item relevance and clarity during scale development?</span>
<span id="cb105-633"><a href="#cb105-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-634"><a href="#cb105-634" aria-hidden="true" tabindex="-1"></a>A) To calculate test-retest reliability  </span>
<span id="cb105-635"><a href="#cb105-635" aria-hidden="true" tabindex="-1"></a>B) To establish content validity by ensuring items appropriately represent the construct  </span>
<span id="cb105-636"><a href="#cb105-636" aria-hidden="true" tabindex="-1"></a>C) To compute inter-item correlations  </span>
<span id="cb105-637"><a href="#cb105-637" aria-hidden="true" tabindex="-1"></a>D) To determine the optimal sample size for the study</span>
<span id="cb105-638"><a href="#cb105-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-639"><a href="#cb105-639" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-640"><a href="#cb105-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-641"><a href="#cb105-641" aria-hidden="true" tabindex="-1"></a>**Q10.** In the example of the 5-item job satisfaction scale, Item 3 had a restricted range (responses only from 4–7 on a 1–7 scale). What does this suggest?</span>
<span id="cb105-642"><a href="#cb105-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-643"><a href="#cb105-643" aria-hidden="true" tabindex="-1"></a>A) Item 3 has perfect reliability  </span>
<span id="cb105-644"><a href="#cb105-644" aria-hidden="true" tabindex="-1"></a>B) Item 3 may have a ceiling effect, limiting its ability to differentiate among respondents  </span>
<span id="cb105-645"><a href="#cb105-645" aria-hidden="true" tabindex="-1"></a>C) Item 3 should be kept because high scores are desirable  </span>
<span id="cb105-646"><a href="#cb105-646" aria-hidden="true" tabindex="-1"></a>D) The sample size should be increased to 1,000</span>
<span id="cb105-647"><a href="#cb105-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-648"><a href="#cb105-648" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb105-649"><a href="#cb105-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-650"><a href="#cb105-650" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb105-651"><a href="#cb105-651" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Answers and Explanations</span></span>
<span id="cb105-652"><a href="#cb105-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-653"><a href="#cb105-653" aria-hidden="true" tabindex="-1"></a>**A1. B)** "With very small samples (n &lt; 20), quantitative item analysis is unreliable. Qualitative methods (cognitive interviews, focus groups) are more informative."  </span>
<span id="cb105-654"><a href="#cb105-654" aria-hidden="true" tabindex="-1"></a>Cognitive interviews reveal ambiguous wording and cultural issues without requiring the large samples needed for statistical reliability indices.</span>
<span id="cb105-655"><a href="#cb105-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-656"><a href="#cb105-656" aria-hidden="true" tabindex="-1"></a>**A2. B)** CVR = (6 - 8/2) / (8/2) = (6 - 4) / 4 = 2/4 = 0.50.  </span>
<span id="cb105-657"><a href="#cb105-657" aria-hidden="true" tabindex="-1"></a>"A CVR of 0.50 indicates that 75% of experts deemed the item essential."</span>
<span id="cb105-658"><a href="#cb105-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-659"><a href="#cb105-659" aria-hidden="true" tabindex="-1"></a>**A3. B)** "If most responses cluster at the low or high end, the item cannot differentiate among respondents."  </span>
<span id="cb105-660"><a href="#cb105-660" aria-hidden="true" tabindex="-1"></a>A ceiling effect occurs when most respondents give the highest possible response, limiting discrimination.</span>
<span id="cb105-661"><a href="#cb105-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-662"><a href="#cb105-662" aria-hidden="true" tabindex="-1"></a>**A4. C)** "The corrected item-total correlation (r.drop) indicates how well each item correlates with the total score excluding itself. Values below 0.3 suggest weak items that could be removed."  </span>
<span id="cb105-663"><a href="#cb105-663" aria-hidden="true" tabindex="-1"></a>Items with r.drop &lt; 0.3 discriminate poorly and are candidates for removal.</span>
<span id="cb105-664"><a href="#cb105-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-665"><a href="#cb105-665" aria-hidden="true" tabindex="-1"></a>**A5. A)** "Content validity refers to whether items comprehensively and appropriately represent the construct being measured."  </span>
<span id="cb105-666"><a href="#cb105-666" aria-hidden="true" tabindex="-1"></a>Content validity is assessed through expert review, not statistical tests.</span>
<span id="cb105-667"><a href="#cb105-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-668"><a href="#cb105-668" aria-hidden="true" tabindex="-1"></a>**A6. B)** "Removing items also reduces scale length, which can lower alpha."  </span>
<span id="cb105-669"><a href="#cb105-669" aria-hidden="true" tabindex="-1"></a>Cronbach's alpha is mathematically influenced by the number of items—shorter scales tend to have lower alpha even if items are equally good.</span>
<span id="cb105-670"><a href="#cb105-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-671"><a href="#cb105-671" aria-hidden="true" tabindex="-1"></a>**A7. B)** "Standard scale development protocols (large pilot studies, factor analysis, item response theory) require hundreds of observations."  </span>
<span id="cb105-672"><a href="#cb105-672" aria-hidden="true" tabindex="-1"></a>Factor analysis requires large samples (typically 200+) for stable results; small samples yield unreliable factor loadings.</span>
<span id="cb105-673"><a href="#cb105-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-674"><a href="#cb105-674" aria-hidden="true" tabindex="-1"></a>**A8. B)** "If an item correlates negatively with the total or with other items, it may be reverse-coded incorrectly or measuring an opposite construct."  </span>
<span id="cb105-675"><a href="#cb105-675" aria-hidden="true" tabindex="-1"></a>Negative correlations suggest coding errors or conceptual misalignment with the scale.</span>
<span id="cb105-676"><a href="#cb105-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-677"><a href="#cb105-677" aria-hidden="true" tabindex="-1"></a>**A9. B)** "Content validity refers to whether items comprehensively and appropriately represent the construct being measured... assessed through expert review and respondent feedback."  </span>
<span id="cb105-678"><a href="#cb105-678" aria-hidden="true" tabindex="-1"></a>Expert ratings establish content validity by confirming items represent the construct appropriately.</span>
<span id="cb105-679"><a href="#cb105-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-680"><a href="#cb105-680" aria-hidden="true" tabindex="-1"></a>**A10. B)** "Item 3 has a restricted range (4–7), which may indicate a ceiling effect."  </span>
<span id="cb105-681"><a href="#cb105-681" aria-hidden="true" tabindex="-1"></a>Restricted ranges (especially at the high end) indicate ceiling effects that limit the item's ability to differentiate among respondents.</span>
<span id="cb105-682"><a href="#cb105-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-683"><a href="#cb105-683" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb105-684"><a href="#cb105-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-685"><a href="#cb105-685" aria-hidden="true" tabindex="-1"></a><span class="fu">### Key Takeaways</span></span>
<span id="cb105-686"><a href="#cb105-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-687"><a href="#cb105-687" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Measurement quality is critical in small-sample research; unreliable measures reduce power and bias estimates.</span>
<span id="cb105-688"><a href="#cb105-688" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Content and face validity are assessed through expert review and respondent feedback, not statistics.</span>
<span id="cb105-689"><a href="#cb105-689" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Pilot testing with small samples (n ≈ 20–40) can identify problematic items through item-level descriptive statistics and inter-item correlations.</span>
<span id="cb105-690"><a href="#cb105-690" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Items with low variance, weak item-total correlations, or ceiling/floor effects should be revised or removed.</span>
<span id="cb105-691"><a href="#cb105-691" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Qualitative methods (cognitive interviews) are valuable when quantitative sample sizes are too small for psychometric analysis.</span>
<span id="cb105-692"><a href="#cb105-692" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Iterative refinement and re-testing improve scale quality, even when resources are limited.</span>
<span id="cb105-693"><a href="#cb105-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-694"><a href="#cb105-694" aria-hidden="true" tabindex="-1"></a><span class="fu">### Smoke Test</span></span>
<span id="cb105-695"><a href="#cb105-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-698"><a href="#cb105-698" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-699"><a href="#cb105-699" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-08</span></span>
<span id="cb105-700"><a href="#cb105-700" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run item statistics</span></span>
<span id="cb105-701"><a href="#cb105-701" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb105-702"><a href="#cb105-702" aria-hidden="true" tabindex="-1"></a>items_test <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb105-703"><a href="#cb105-703" aria-hidden="true" tabindex="-1"></a>  <span class="at">i1 =</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">15</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>),</span>
<span id="cb105-704"><a href="#cb105-704" aria-hidden="true" tabindex="-1"></a>  <span class="at">i2 =</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">15</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>),</span>
<span id="cb105-705"><a href="#cb105-705" aria-hidden="true" tabindex="-1"></a>  <span class="at">i3 =</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">15</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb105-706"><a href="#cb105-706" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb105-707"><a href="#cb105-707" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(items_test)</span>
<span id="cb105-708"><a href="#cb105-708" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-709"><a href="#cb105-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-710"><a href="#cb105-710" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-711"><a href="#cb105-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-712"><a href="#cb105-712" aria-hidden="true" tabindex="-1"></a><span class="fu">## Chapter 11. Data Screening and Diagnostic Checks</span></span>
<span id="cb105-713"><a href="#cb105-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-714"><a href="#cb105-714" aria-hidden="true" tabindex="-1"></a><span class="fu">### Learning Objectives</span></span>
<span id="cb105-715"><a href="#cb105-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-716"><a href="#cb105-716" aria-hidden="true" tabindex="-1"></a>By the end of this chapter, you will be able to:</span>
<span id="cb105-717"><a href="#cb105-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-718"><a href="#cb105-718" aria-hidden="true" tabindex="-1"></a>**Conceptual Understanding**</span>
<span id="cb105-719"><a href="#cb105-719" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Explain how small samples amplify the impact of outliers and anomalies</span>
<span id="cb105-720"><a href="#cb105-720" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Understand univariate vs. multivariate outlier detection approaches</span>
<span id="cb105-721"><a href="#cb105-721" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Recognize the assumptions underlying common diagnostic tests</span>
<span id="cb105-722"><a href="#cb105-722" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Distinguish data entry errors from legitimate extreme values</span>
<span id="cb105-723"><a href="#cb105-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-724"><a href="#cb105-724" aria-hidden="true" tabindex="-1"></a>**Practical Skills**</span>
<span id="cb105-725"><a href="#cb105-725" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Detect outliers using z-scores, boxplots, and Mahalanobis distance in R</span>
<span id="cb105-726"><a href="#cb105-726" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Assess normality with Q-Q plots, Shapiro-Wilk tests, and visual diagnostics</span>
<span id="cb105-727"><a href="#cb105-727" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Check linearity and homoscedasticity in regression models</span>
<span id="cb105-728"><a href="#cb105-728" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Calculate leverage and Cook's D to identify influential observations</span>
<span id="cb105-729"><a href="#cb105-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-730"><a href="#cb105-730" aria-hidden="true" tabindex="-1"></a>**Critical Evaluation**</span>
<span id="cb105-731"><a href="#cb105-731" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Assess when outlier removal is justified vs. when it constitutes manipulation</span>
<span id="cb105-732"><a href="#cb105-732" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Evaluate the trade-off between retaining data vs. meeting assumptions</span>
<span id="cb105-733"><a href="#cb105-733" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Critique data screening decisions in published small-sample studies</span>
<span id="cb105-734"><a href="#cb105-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-735"><a href="#cb105-735" aria-hidden="true" tabindex="-1"></a>**Application**</span>
<span id="cb105-736"><a href="#cb105-736" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Document data cleaning decisions transparently with decision rules</span>
<span id="cb105-737"><a href="#cb105-737" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Choose between robust methods, transformations, or outlier exclusion</span>
<span id="cb105-738"><a href="#cb105-738" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Report sensitivity analyses showing results with/without outliers</span>
<span id="cb105-739"><a href="#cb105-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-740"><a href="#cb105-740" aria-hidden="true" tabindex="-1"></a><span class="fu">### Why Data Screening Matters More with Small Samples</span></span>
<span id="cb105-741"><a href="#cb105-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-742"><a href="#cb105-742" aria-hidden="true" tabindex="-1"></a>A single outlier can dominate a mean, distort a correlation, or violate regression assumptions when samples are small. Data entry errors (typos, misplaced decimals, incorrect codes) are harder to detect with fewer observations. Distributional assumptions (normality, homoscedasticity) are harder to verify with small samples, yet violations have greater consequences.</span>
<span id="cb105-743"><a href="#cb105-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-744"><a href="#cb105-744" aria-hidden="true" tabindex="-1"></a>Systematic data screening before analysis helps identify problems early. Document all cleaning and transformation decisions in a reproducible script. Report descriptive statistics, missingness patterns, and any deviations from planned analyses.</span>
<span id="cb105-745"><a href="#cb105-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-746"><a href="#cb105-746" aria-hidden="true" tabindex="-1"></a><span class="fu">### Detecting Outliers</span></span>
<span id="cb105-747"><a href="#cb105-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-748"><a href="#cb105-748" aria-hidden="true" tabindex="-1"></a>Outliers are observations that are unusually large or small relative to the rest of the data. They may represent legitimate extreme values, data entry errors, or individuals from a different population. With small samples, outliers can have disproportionate influence on results.</span>
<span id="cb105-749"><a href="#cb105-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-750"><a href="#cb105-750" aria-hidden="true" tabindex="-1"></a>**Methods for detecting outliers**:</span>
<span id="cb105-751"><a href="#cb105-751" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Visual inspection: boxplots, histograms, scatterplots.</span>
<span id="cb105-752"><a href="#cb105-752" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Numerical criteria: values beyond 1.5 × IQR from the quartiles (Tukey's fences), or standardised scores (z-scores) beyond ±3.</span>
<span id="cb105-753"><a href="#cb105-753" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Influence diagnostics: Cook's distance, leverage in regression.</span>
<span id="cb105-754"><a href="#cb105-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-755"><a href="#cb105-755" aria-hidden="true" tabindex="-1"></a>**When to remove outliers**: Only if there is clear evidence of data entry error or that the observation does not belong to the target population. Document the rationale and report results with and without outliers.</span>
<span id="cb105-756"><a href="#cb105-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-757"><a href="#cb105-757" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Multivariate Outliers with Mahalanobis Distance</span></span>
<span id="cb105-758"><a href="#cb105-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-759"><a href="#cb105-759" aria-hidden="true" tabindex="-1"></a>Univariate rules may miss cases that are unusual only when variables are considered jointly. Mahalanobis distance measures how far an observation lies from the multivariate centre, accounting for covariances among variables. Distances can be compared to a chi-square threshold with degrees of freedom equal to the number of variables.</span>
<span id="cb105-760"><a href="#cb105-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-763"><a href="#cb105-763" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-764"><a href="#cb105-764" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-09</span></span>
<span id="cb105-765"><a href="#cb105-765" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb105-766"><a href="#cb105-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-767"><a href="#cb105-767" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb105-768"><a href="#cb105-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-769"><a href="#cb105-769" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated bivariate data with one multivariate outlier</span></span>
<span id="cb105-770"><a href="#cb105-770" aria-hidden="true" tabindex="-1"></a>multi_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb105-771"><a href="#cb105-771" aria-hidden="true" tabindex="-1"></a>  <span class="at">satisfaction =</span> <span class="fu">rnorm</span>(<span class="dv">14</span>, <span class="at">mean =</span> <span class="dv">6</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb105-772"><a href="#cb105-772" aria-hidden="true" tabindex="-1"></a>  <span class="at">wait_time =</span> <span class="fu">rnorm</span>(<span class="dv">14</span>, <span class="at">mean =</span> <span class="dv">10</span>, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb105-773"><a href="#cb105-773" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb105-774"><a href="#cb105-774" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(<span class="fu">tibble</span>(<span class="at">satisfaction =</span> <span class="dv">2</span>, <span class="at">wait_time =</span> <span class="dv">18</span>))  <span class="co"># potential outlier</span></span>
<span id="cb105-775"><a href="#cb105-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-776"><a href="#cb105-776" aria-hidden="true" tabindex="-1"></a>center <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(multi_data)</span>
<span id="cb105-777"><a href="#cb105-777" aria-hidden="true" tabindex="-1"></a>cov_mat <span class="ot">&lt;-</span> <span class="fu">cov</span>(multi_data)</span>
<span id="cb105-778"><a href="#cb105-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-779"><a href="#cb105-779" aria-hidden="true" tabindex="-1"></a>multi_data <span class="ot">&lt;-</span> multi_data <span class="sc">%&gt;%</span></span>
<span id="cb105-780"><a href="#cb105-780" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb105-781"><a href="#cb105-781" aria-hidden="true" tabindex="-1"></a>    <span class="at">mahal =</span> <span class="fu">mahalanobis</span>(., center, cov_mat),</span>
<span id="cb105-782"><a href="#cb105-782" aria-hidden="true" tabindex="-1"></a>    <span class="at">flag =</span> mahal <span class="sc">&gt;</span> <span class="fu">qchisq</span>(<span class="fl">0.975</span>, <span class="at">df =</span> <span class="fu">ncol</span>(multi_data))</span>
<span id="cb105-783"><a href="#cb105-783" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb105-784"><a href="#cb105-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-785"><a href="#cb105-785" aria-hidden="true" tabindex="-1"></a>multi_data</span>
<span id="cb105-786"><a href="#cb105-786" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-787"><a href="#cb105-787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-788"><a href="#cb105-788" aria-hidden="true" tabindex="-1"></a>Interpretation: Observations with Mahalanobis distance exceeding the chi-square cutoff (95% or 97.5% quantile) are flagged as multivariate outliers. Inspect the flagged cases individually to determine whether they reflect data errors, rare but valid combinations, or participants from a different subpopulation. Report how thresholds were chosen, as small samples make covariance estimates noisy.</span>
<span id="cb105-789"><a href="#cb105-789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-790"><a href="#cb105-790" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example: Outlier Detection with Boxplots and Z-Scores</span></span>
<span id="cb105-791"><a href="#cb105-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-792"><a href="#cb105-792" aria-hidden="true" tabindex="-1"></a>We examine a small dataset of customer wait times (n = 20) and check for outliers.</span>
<span id="cb105-793"><a href="#cb105-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-796"><a href="#cb105-796" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-797"><a href="#cb105-797" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-10</span></span>
<span id="cb105-798"><a href="#cb105-798" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Boxplot highlighting a potential customer wait-time outlier."</span></span>
<span id="cb105-799"><a href="#cb105-799" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb105-800"><a href="#cb105-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-801"><a href="#cb105-801" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb105-802"><a href="#cb105-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-803"><a href="#cb105-803" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated wait times (most between 5–15 minutes, one outlier at 45)</span></span>
<span id="cb105-804"><a href="#cb105-804" aria-hidden="true" tabindex="-1"></a>wait_times <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">8</span>, <span class="dv">11</span>, <span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">13</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">8</span>, <span class="dv">11</span>, <span class="dv">10</span>, <span class="dv">9</span>, <span class="dv">45</span>, <span class="dv">10</span>)</span>
<span id="cb105-805"><a href="#cb105-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-806"><a href="#cb105-806" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the data frame</span></span>
<span id="cb105-807"><a href="#cb105-807" aria-hidden="true" tabindex="-1"></a>wait_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">observation =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">wait_time =</span> wait_times)</span>
<span id="cb105-808"><a href="#cb105-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-809"><a href="#cb105-809" aria-hidden="true" tabindex="-1"></a><span class="co"># Boxplot</span></span>
<span id="cb105-810"><a href="#cb105-810" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(</span>
<span id="cb105-811"><a href="#cb105-811" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(wait_data, <span class="fu">aes</span>(<span class="at">y =</span> wait_time)) <span class="sc">+</span></span>
<span id="cb105-812"><a href="#cb105-812" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_boxplot</span>(<span class="at">fill =</span> <span class="st">"lightblue"</span>) <span class="sc">+</span></span>
<span id="cb105-813"><a href="#cb105-813" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Boxplot of Wait Times"</span>, <span class="at">y =</span> <span class="st">"Wait Time (minutes)"</span>) <span class="sc">+</span></span>
<span id="cb105-814"><a href="#cb105-814" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>()</span>
<span id="cb105-815"><a href="#cb105-815" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb105-816"><a href="#cb105-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-817"><a href="#cb105-817" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify outliers using 1.5*IQR rule</span></span>
<span id="cb105-818"><a href="#cb105-818" aria-hidden="true" tabindex="-1"></a>Q1 <span class="ot">&lt;-</span> <span class="fu">quantile</span>(wait_times, <span class="fl">0.25</span>)</span>
<span id="cb105-819"><a href="#cb105-819" aria-hidden="true" tabindex="-1"></a>Q3 <span class="ot">&lt;-</span> <span class="fu">quantile</span>(wait_times, <span class="fl">0.75</span>)</span>
<span id="cb105-820"><a href="#cb105-820" aria-hidden="true" tabindex="-1"></a>IQR_val <span class="ot">&lt;-</span> <span class="fu">IQR</span>(wait_times)</span>
<span id="cb105-821"><a href="#cb105-821" aria-hidden="true" tabindex="-1"></a>lower_fence <span class="ot">&lt;-</span> Q1 <span class="sc">-</span> <span class="fl">1.5</span> <span class="sc">*</span> IQR_val</span>
<span id="cb105-822"><a href="#cb105-822" aria-hidden="true" tabindex="-1"></a>upper_fence <span class="ot">&lt;-</span> Q3 <span class="sc">+</span> <span class="fl">1.5</span> <span class="sc">*</span> IQR_val</span>
<span id="cb105-823"><a href="#cb105-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-824"><a href="#cb105-824" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter to find outliers</span></span>
<span id="cb105-825"><a href="#cb105-825" aria-hidden="true" tabindex="-1"></a>outliers <span class="ot">&lt;-</span> wait_data <span class="sc">%&gt;%</span></span>
<span id="cb105-826"><a href="#cb105-826" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(wait_time <span class="sc">&lt;</span> lower_fence <span class="sc">|</span> wait_time <span class="sc">&gt;</span> upper_fence)</span>
<span id="cb105-827"><a href="#cb105-827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-828"><a href="#cb105-828" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"Outliers (1.5*IQR rule):"</span>)</span>
<span id="cb105-829"><a href="#cb105-829" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(outliers)</span>
<span id="cb105-830"><a href="#cb105-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-831"><a href="#cb105-831" aria-hidden="true" tabindex="-1"></a><span class="co"># Z-scores for outlier identification</span></span>
<span id="cb105-832"><a href="#cb105-832" aria-hidden="true" tabindex="-1"></a>wait_data <span class="ot">&lt;-</span> wait_data <span class="sc">%&gt;%</span></span>
<span id="cb105-833"><a href="#cb105-833" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">z_score =</span> (wait_time <span class="sc">-</span> <span class="fu">mean</span>(wait_time)) <span class="sc">/</span> <span class="fu">sd</span>(wait_time))</span>
<span id="cb105-834"><a href="#cb105-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-835"><a href="#cb105-835" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter to find extreme values (absolute z-score &gt; 3)</span></span>
<span id="cb105-836"><a href="#cb105-836" aria-hidden="true" tabindex="-1"></a>extreme <span class="ot">&lt;-</span> wait_data <span class="sc">%&gt;%</span></span>
<span id="cb105-837"><a href="#cb105-837" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(<span class="fu">abs</span>(z_score) <span class="sc">&gt;</span> <span class="dv">3</span>)</span>
<span id="cb105-838"><a href="#cb105-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-839"><a href="#cb105-839" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"Extreme values (Z-score &gt; 3):"</span>)</span>
<span id="cb105-840"><a href="#cb105-840" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(extreme)</span>
<span id="cb105-841"><a href="#cb105-841" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-842"><a href="#cb105-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-843"><a href="#cb105-843" aria-hidden="true" tabindex="-1"></a>Interpretation: The boxplot visually flags observation 19 (wait time = 45 minutes) as an outlier. The IQR-based rule and z-score criterion both identify this observation. Before removing it, investigate: Is this a data entry error? Could a customer have genuinely waited 45 minutes due to an unusual circumstance? If it is an error, remove it. If it is genuine but atypical, consider reporting results with and without the outlier, or use robust methods (median, rank-based tests) that are less sensitive to extremes.</span>
<span id="cb105-844"><a href="#cb105-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-845"><a href="#cb105-845" aria-hidden="true" tabindex="-1"></a><span class="fu">### Checking Normality</span></span>
<span id="cb105-846"><a href="#cb105-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-847"><a href="#cb105-847" aria-hidden="true" tabindex="-1"></a>Many parametric tests assume normally distributed data (or residuals). With small samples, normality is hard to verify formally. Visual checks (histograms, Q-Q plots) are more informative than statistical tests (Shapiro–Wilk), which have low power with small n.</span>
<span id="cb105-848"><a href="#cb105-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-849"><a href="#cb105-849" aria-hidden="true" tabindex="-1"></a>If data are clearly skewed or have heavy tails, consider:</span>
<span id="cb105-850"><a href="#cb105-850" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Nonparametric methods (rank-based tests).</span>
<span id="cb105-851"><a href="#cb105-851" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Transformations (log, square root) to reduce skewness.</span>
<span id="cb105-852"><a href="#cb105-852" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Robust methods (trimmed means, bootstrap).</span>
<span id="cb105-853"><a href="#cb105-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-854"><a href="#cb105-854" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example: Q-Q Plot for Normality Assessment</span></span>
<span id="cb105-855"><a href="#cb105-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-856"><a href="#cb105-856" aria-hidden="true" tabindex="-1"></a>We check whether a small sample of test scores (n = 18) is approximately normally distributed.</span>
<span id="cb105-857"><a href="#cb105-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-860"><a href="#cb105-860" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-861"><a href="#cb105-861" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-11</span></span>
<span id="cb105-862"><a href="#cb105-862" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb105-863"><a href="#cb105-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-864"><a href="#cb105-864" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb105-865"><a href="#cb105-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-866"><a href="#cb105-866" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated test scores (approximately normal)</span></span>
<span id="cb105-867"><a href="#cb105-867" aria-hidden="true" tabindex="-1"></a>test_scores <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">18</span>, <span class="at">mean =</span> <span class="dv">70</span>, <span class="at">sd =</span> <span class="dv">10</span>))</span>
<span id="cb105-868"><a href="#cb105-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-869"><a href="#cb105-869" aria-hidden="true" tabindex="-1"></a><span class="co"># Q-Q plot</span></span>
<span id="cb105-870"><a href="#cb105-870" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(test_scores, <span class="at">main =</span> <span class="st">"Q-Q Plot of Test Scores"</span>)</span>
<span id="cb105-871"><a href="#cb105-871" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(test_scores, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb105-872"><a href="#cb105-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-873"><a href="#cb105-873" aria-hidden="true" tabindex="-1"></a><span class="co"># Shapiro-Wilk test</span></span>
<span id="cb105-874"><a href="#cb105-874" aria-hidden="true" tabindex="-1"></a>shapiro_result <span class="ot">&lt;-</span> <span class="fu">shapiro.test</span>(test_scores)</span>
<span id="cb105-875"><a href="#cb105-875" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(shapiro_result)</span>
<span id="cb105-876"><a href="#cb105-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-877"><a href="#cb105-877" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Shapiro-Wilk p-value:"</span>, <span class="fu">round</span>(shapiro_result<span class="sc">$</span>p.value, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-878"><a href="#cb105-878" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-879"><a href="#cb105-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-880"><a href="#cb105-880" aria-hidden="true" tabindex="-1"></a>Interpretation: In a Q-Q plot, points should lie approximately on the diagonal line if data are normally distributed. Deviations at the tails indicate skewness or heavy tails. The Shapiro–Wilk test provides a p-value; p &gt; 0.05 suggests no strong evidence against normality. However, with small samples, the test has low power (may not detect departures) and high variability (can reject normality by chance). Use Q-Q plots as the primary diagnostic, supplemented by the test.</span>
<span id="cb105-881"><a href="#cb105-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-882"><a href="#cb105-882" aria-hidden="true" tabindex="-1"></a><span class="fu">### Linearity and Homoscedasticity in Regression</span></span>
<span id="cb105-883"><a href="#cb105-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-884"><a href="#cb105-884" aria-hidden="true" tabindex="-1"></a>Linear regression assumes a linear relationship between predictors and outcome, and constant variance of residuals (homoscedasticity). Scatterplots of residuals vs. fitted values help assess these assumptions.</span>
<span id="cb105-885"><a href="#cb105-885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-886"><a href="#cb105-886" aria-hidden="true" tabindex="-1"></a>**What to look for**:</span>
<span id="cb105-887"><a href="#cb105-887" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Linearity: Residuals should be randomly scattered around zero with no clear pattern. Curved patterns suggest non-linearity.</span>
<span id="cb105-888"><a href="#cb105-888" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Homoscedasticity: Residual spread should be constant across fitted values. Funnel shapes suggest heteroscedasticity (variance changes with fitted values).</span>
<span id="cb105-889"><a href="#cb105-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-890"><a href="#cb105-890" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example: Regression Diagnostics</span></span>
<span id="cb105-891"><a href="#cb105-891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-892"><a href="#cb105-892" aria-hidden="true" tabindex="-1"></a>We fit a simple linear regression (outcome ~ predictor) with n = 20 and check diagnostic plots.</span>
<span id="cb105-893"><a href="#cb105-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-896"><a href="#cb105-896" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-897"><a href="#cb105-897" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-12</span></span>
<span id="cb105-898"><a href="#cb105-898" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb105-899"><a href="#cb105-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-900"><a href="#cb105-900" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb105-901"><a href="#cb105-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-902"><a href="#cb105-902" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated data</span></span>
<span id="cb105-903"><a href="#cb105-903" aria-hidden="true" tabindex="-1"></a>reg_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb105-904"><a href="#cb105-904" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">20</span>, <span class="dv">1</span>, <span class="dv">10</span>),</span>
<span id="cb105-905"><a href="#cb105-905" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="dv">3</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">20</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb105-906"><a href="#cb105-906" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb105-907"><a href="#cb105-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-908"><a href="#cb105-908" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear model</span></span>
<span id="cb105-909"><a href="#cb105-909" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> reg_data)</span>
<span id="cb105-910"><a href="#cb105-910" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span>
<span id="cb105-911"><a href="#cb105-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-912"><a href="#cb105-912" aria-hidden="true" tabindex="-1"></a><span class="co"># Diagnostic plots</span></span>
<span id="cb105-913"><a href="#cb105-913" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb105-914"><a href="#cb105-914" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model)</span>
<span id="cb105-915"><a href="#cb105-915" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb105-916"><a href="#cb105-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-917"><a href="#cb105-917" aria-hidden="true" tabindex="-1"></a><span class="co"># Residuals vs fitted</span></span>
<span id="cb105-918"><a href="#cb105-918" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model<span class="sc">$</span>fitted.values, model<span class="sc">$</span>residuals, </span>
<span id="cb105-919"><a href="#cb105-919" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Fitted Values"</span>, <span class="at">ylab =</span> <span class="st">"Residuals"</span>,</span>
<span id="cb105-920"><a href="#cb105-920" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Residuals vs Fitted"</span>)</span>
<span id="cb105-921"><a href="#cb105-921" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb105-922"><a href="#cb105-922" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-923"><a href="#cb105-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-924"><a href="#cb105-924" aria-hidden="true" tabindex="-1"></a>Interpretation: The "Residuals vs Fitted" plot should show random scatter around zero. Patterns (curves, funnels) indicate problems. The Q-Q plot of residuals assesses normality of errors. The "Scale-Location" plot checks homoscedasticity (should be flat). The "Residuals vs Leverage" plot identifies influential observations (high Cook's distance). With small samples, a single influential point can dominate. Consider removing it if it is an error, or report sensitivity analyses with and without it.</span>
<span id="cb105-925"><a href="#cb105-925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-926"><a href="#cb105-926" aria-hidden="true" tabindex="-1"></a><span class="fu">### Identifying Data Entry Errors</span></span>
<span id="cb105-927"><a href="#cb105-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-928"><a href="#cb105-928" aria-hidden="true" tabindex="-1"></a>Look for:</span>
<span id="cb105-929"><a href="#cb105-929" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Values outside plausible ranges (e.g., age = 150, Likert response = 8 on a 1–7 scale).</span>
<span id="cb105-930"><a href="#cb105-930" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Inconsistent codes (e.g., gender coded as 1/2 in some rows, M/F in others).</span>
<span id="cb105-931"><a href="#cb105-931" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Duplicate records (same participant ID appearing twice).</span>
<span id="cb105-932"><a href="#cb105-932" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Improbable combinations (e.g., primary school student with 20 years of work experience).</span>
<span id="cb105-933"><a href="#cb105-933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-934"><a href="#cb105-934" aria-hidden="true" tabindex="-1"></a>Cross-check data against source documents or re-contact participants if errors are suspected.</span>
<span id="cb105-935"><a href="#cb105-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-936"><a href="#cb105-936" aria-hidden="true" tabindex="-1"></a><span class="fu">### Documenting Data Cleaning</span></span>
<span id="cb105-937"><a href="#cb105-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-938"><a href="#cb105-938" aria-hidden="true" tabindex="-1"></a>Maintain a data cleaning script that:</span>
<span id="cb105-939"><a href="#cb105-939" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Reads raw data.</span>
<span id="cb105-940"><a href="#cb105-940" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Flags potential outliers, errors, or inconsistencies.</span>
<span id="cb105-941"><a href="#cb105-941" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Applies corrections or exclusions with justifications.</span>
<span id="cb105-942"><a href="#cb105-942" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Produces a cleaned dataset for analysis.</span>
<span id="cb105-943"><a href="#cb105-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-944"><a href="#cb105-944" aria-hidden="true" tabindex="-1"></a>Report the number of observations excluded and reasons. Provide summary statistics for the cleaned data.</span>
<span id="cb105-945"><a href="#cb105-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-946"><a href="#cb105-946" aria-hidden="true" tabindex="-1"></a><span class="fu">### Self-Assessment Quiz</span></span>
<span id="cb105-947"><a href="#cb105-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-948"><a href="#cb105-948" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb105-949"><a href="#cb105-949" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Chapter 11 Questions</span></span>
<span id="cb105-950"><a href="#cb105-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-951"><a href="#cb105-951" aria-hidden="true" tabindex="-1"></a>**Q1.** Why are outliers particularly problematic in small-sample research?</span>
<span id="cb105-952"><a href="#cb105-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-953"><a href="#cb105-953" aria-hidden="true" tabindex="-1"></a>A) They are easier to detect visually  </span>
<span id="cb105-954"><a href="#cb105-954" aria-hidden="true" tabindex="-1"></a>B) They can have disproportionate influence on results due to the limited number of observations  </span>
<span id="cb105-955"><a href="#cb105-955" aria-hidden="true" tabindex="-1"></a>C) Small samples always have more outliers than large samples  </span>
<span id="cb105-956"><a href="#cb105-956" aria-hidden="true" tabindex="-1"></a>D) Outliers are impossible to detect with small samples</span>
<span id="cb105-957"><a href="#cb105-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-958"><a href="#cb105-958" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-959"><a href="#cb105-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-960"><a href="#cb105-960" aria-hidden="true" tabindex="-1"></a>**Q2.** What is the primary advantage of Mahalanobis distance over univariate outlier detection methods?</span>
<span id="cb105-961"><a href="#cb105-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-962"><a href="#cb105-962" aria-hidden="true" tabindex="-1"></a>A) It is faster to compute  </span>
<span id="cb105-963"><a href="#cb105-963" aria-hidden="true" tabindex="-1"></a>B) It measures how far an observation lies from the multivariate centre, accounting for covariances among variables  </span>
<span id="cb105-964"><a href="#cb105-964" aria-hidden="true" tabindex="-1"></a>C) It only works with large samples  </span>
<span id="cb105-965"><a href="#cb105-965" aria-hidden="true" tabindex="-1"></a>D) It automatically removes all outliers</span>
<span id="cb105-966"><a href="#cb105-966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-967"><a href="#cb105-967" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-968"><a href="#cb105-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-969"><a href="#cb105-969" aria-hidden="true" tabindex="-1"></a>**Q3.** According to Tukey's fences method, an observation is flagged as a potential outlier if it falls:</span>
<span id="cb105-970"><a href="#cb105-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-971"><a href="#cb105-971" aria-hidden="true" tabindex="-1"></a>A) Within 1.5 × IQR from the quartiles  </span>
<span id="cb105-972"><a href="#cb105-972" aria-hidden="true" tabindex="-1"></a>B) Beyond ±2 standard deviations from the mean  </span>
<span id="cb105-973"><a href="#cb105-973" aria-hidden="true" tabindex="-1"></a>C) Beyond 1.5 × IQR from the quartiles  </span>
<span id="cb105-974"><a href="#cb105-974" aria-hidden="true" tabindex="-1"></a>D) Exactly at the median</span>
<span id="cb105-975"><a href="#cb105-975" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-976"><a href="#cb105-976" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-977"><a href="#cb105-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-978"><a href="#cb105-978" aria-hidden="true" tabindex="-1"></a>**Q4.** Why are visual diagnostics (Q-Q plots, boxplots) preferred over formal normality tests (Shapiro–Wilk) for small samples?</span>
<span id="cb105-979"><a href="#cb105-979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-980"><a href="#cb105-980" aria-hidden="true" tabindex="-1"></a>A) Visual diagnostics are more statistically rigorous  </span>
<span id="cb105-981"><a href="#cb105-981" aria-hidden="true" tabindex="-1"></a>B) Normality tests have low power with small samples and may not detect departures; visual checks provide more insight  </span>
<span id="cb105-982"><a href="#cb105-982" aria-hidden="true" tabindex="-1"></a>C) Normality tests are too expensive  </span>
<span id="cb105-983"><a href="#cb105-983" aria-hidden="true" tabindex="-1"></a>D) Visual diagnostics automatically calculate p-values</span>
<span id="cb105-984"><a href="#cb105-984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-985"><a href="#cb105-985" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-986"><a href="#cb105-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-987"><a href="#cb105-987" aria-hidden="true" tabindex="-1"></a>**Q5.** In a regression diagnostic plot of "Residuals vs Fitted Values," what does a funnel-shaped pattern indicate?</span>
<span id="cb105-988"><a href="#cb105-988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-989"><a href="#cb105-989" aria-hidden="true" tabindex="-1"></a>A) Perfect homoscedasticity  </span>
<span id="cb105-990"><a href="#cb105-990" aria-hidden="true" tabindex="-1"></a>B) Heteroscedasticity—residual variance changes with fitted values  </span>
<span id="cb105-991"><a href="#cb105-991" aria-hidden="true" tabindex="-1"></a>C) Normality of residuals  </span>
<span id="cb105-992"><a href="#cb105-992" aria-hidden="true" tabindex="-1"></a>D) High collinearity among predictors</span>
<span id="cb105-993"><a href="#cb105-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-994"><a href="#cb105-994" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-995"><a href="#cb105-995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-996"><a href="#cb105-996" aria-hidden="true" tabindex="-1"></a>**Q6.** What does Cook's distance measure in regression diagnostics?</span>
<span id="cb105-997"><a href="#cb105-997" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-998"><a href="#cb105-998" aria-hidden="true" tabindex="-1"></a>A) The distance between two data points  </span>
<span id="cb105-999"><a href="#cb105-999" aria-hidden="true" tabindex="-1"></a>B) The influence of each observation on the regression coefficients; high values indicate influential observations  </span>
<span id="cb105-1000"><a href="#cb105-1000" aria-hidden="true" tabindex="-1"></a>C) The correlation between predictors  </span>
<span id="cb105-1001"><a href="#cb105-1001" aria-hidden="true" tabindex="-1"></a>D) The degree of multicollinearity</span>
<span id="cb105-1002"><a href="#cb105-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1003"><a href="#cb105-1003" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1004"><a href="#cb105-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1005"><a href="#cb105-1005" aria-hidden="true" tabindex="-1"></a>**Q7.** When should an outlier be removed from analysis?</span>
<span id="cb105-1006"><a href="#cb105-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1007"><a href="#cb105-1007" aria-hidden="true" tabindex="-1"></a>A) Always, because outliers are bad  </span>
<span id="cb105-1008"><a href="#cb105-1008" aria-hidden="true" tabindex="-1"></a>B) Never, because all data points are valuable  </span>
<span id="cb105-1009"><a href="#cb105-1009" aria-hidden="true" tabindex="-1"></a>C) Only if there is clear evidence of data entry error or the observation does not belong to the target population  </span>
<span id="cb105-1010"><a href="#cb105-1010" aria-hidden="true" tabindex="-1"></a>D) Whenever it makes the results statistically significant</span>
<span id="cb105-1011"><a href="#cb105-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1012"><a href="#cb105-1012" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1013"><a href="#cb105-1013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1014"><a href="#cb105-1014" aria-hidden="true" tabindex="-1"></a>**Q8.** What is an example of a data entry error that should be flagged during data screening?</span>
<span id="cb105-1015"><a href="#cb105-1015" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1016"><a href="#cb105-1016" aria-hidden="true" tabindex="-1"></a>A) A participant with a high test score  </span>
<span id="cb105-1017"><a href="#cb105-1017" aria-hidden="true" tabindex="-1"></a>B) A Likert response of 8 on a 1–7 scale  </span>
<span id="cb105-1018"><a href="#cb105-1018" aria-hidden="true" tabindex="-1"></a>C) A missing value in a survey  </span>
<span id="cb105-1019"><a href="#cb105-1019" aria-hidden="true" tabindex="-1"></a>D) A participant who completed all questions</span>
<span id="cb105-1020"><a href="#cb105-1020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1021"><a href="#cb105-1021" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1022"><a href="#cb105-1022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1023"><a href="#cb105-1023" aria-hidden="true" tabindex="-1"></a>**Q9.** Why is documenting data cleaning decisions in a reproducible script important?</span>
<span id="cb105-1024"><a href="#cb105-1024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1025"><a href="#cb105-1025" aria-hidden="true" tabindex="-1"></a>A) It allows others to verify exclusions and understand how the cleaned dataset was produced  </span>
<span id="cb105-1026"><a href="#cb105-1026" aria-hidden="true" tabindex="-1"></a>B) It makes the analysis run faster  </span>
<span id="cb105-1027"><a href="#cb105-1027" aria-hidden="true" tabindex="-1"></a>C) It is required by all statistical software  </span>
<span id="cb105-1028"><a href="#cb105-1028" aria-hidden="true" tabindex="-1"></a>D) It prevents missing data from occurring</span>
<span id="cb105-1029"><a href="#cb105-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1030"><a href="#cb105-1030" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1031"><a href="#cb105-1031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1032"><a href="#cb105-1032" aria-hidden="true" tabindex="-1"></a>**Q10.** In a Q-Q plot, if the points deviate substantially from the diagonal line at the tails, what does this suggest?</span>
<span id="cb105-1033"><a href="#cb105-1033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1034"><a href="#cb105-1034" aria-hidden="true" tabindex="-1"></a>A) The data are perfectly normally distributed  </span>
<span id="cb105-1035"><a href="#cb105-1035" aria-hidden="true" tabindex="-1"></a>B) The data may have skewness or heavy tails  </span>
<span id="cb105-1036"><a href="#cb105-1036" aria-hidden="true" tabindex="-1"></a>C) The sample size is too large  </span>
<span id="cb105-1037"><a href="#cb105-1037" aria-hidden="true" tabindex="-1"></a>D) There are no outliers present</span>
<span id="cb105-1038"><a href="#cb105-1038" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1039"><a href="#cb105-1039" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb105-1040"><a href="#cb105-1040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1041"><a href="#cb105-1041" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb105-1042"><a href="#cb105-1042" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Answers and Explanations</span></span>
<span id="cb105-1043"><a href="#cb105-1043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1044"><a href="#cb105-1044" aria-hidden="true" tabindex="-1"></a>**A1. B)** "With small samples, outliers can have disproportionate influence on results."  </span>
<span id="cb105-1045"><a href="#cb105-1045" aria-hidden="true" tabindex="-1"></a>A single extreme value in a sample of 15 can drastically shift means, correlations, and regression slopes.</span>
<span id="cb105-1046"><a href="#cb105-1046" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1047"><a href="#cb105-1047" aria-hidden="true" tabindex="-1"></a>**A2. B)** "Mahalanobis distance measures how far an observation lies from the multivariate centre, accounting for covariances among variables."  </span>
<span id="cb105-1048"><a href="#cb105-1048" aria-hidden="true" tabindex="-1"></a>Univariate rules may miss cases that are unusual only when variables are considered jointly.</span>
<span id="cb105-1049"><a href="#cb105-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1050"><a href="#cb105-1050" aria-hidden="true" tabindex="-1"></a>**A3. C)** "Values beyond 1.5 × IQR from the quartiles (Tukey's fences)."  </span>
<span id="cb105-1051"><a href="#cb105-1051" aria-hidden="true" tabindex="-1"></a>The lower fence is Q1 - 1.5×IQR; the upper fence is Q3 + 1.5×IQR.</span>
<span id="cb105-1052"><a href="#cb105-1052" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1053"><a href="#cb105-1053" aria-hidden="true" tabindex="-1"></a>**A4. B)** "With small samples, normality is hard to verify formally. Visual checks (histograms, Q-Q plots) are more informative than statistical tests (Shapiro–Wilk), which have low power with small n."  </span>
<span id="cb105-1054"><a href="#cb105-1054" aria-hidden="true" tabindex="-1"></a>Normality tests may not detect departures or may reject normality by chance with small samples; Q-Q plots provide direct visual evidence.</span>
<span id="cb105-1055"><a href="#cb105-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1056"><a href="#cb105-1056" aria-hidden="true" tabindex="-1"></a>**A5. B)** "Funnel shapes suggest heteroscedasticity (variance changes with fitted values)."  </span>
<span id="cb105-1057"><a href="#cb105-1057" aria-hidden="true" tabindex="-1"></a>Homoscedasticity (constant variance) is violated when residual spread increases or decreases with fitted values.</span>
<span id="cb105-1058"><a href="#cb105-1058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1059"><a href="#cb105-1059" aria-hidden="true" tabindex="-1"></a>**A6. B)** "Cook's distance <span class="co">[</span><span class="ot">identifies</span><span class="co">]</span> influential observations."  </span>
<span id="cb105-1060"><a href="#cb105-1060" aria-hidden="true" tabindex="-1"></a>High Cook's distance indicates that removing the observation would substantially change the regression coefficients.</span>
<span id="cb105-1061"><a href="#cb105-1061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1062"><a href="#cb105-1062" aria-hidden="true" tabindex="-1"></a>**A7. C)** "Only if there is clear evidence of data entry error or that the observation does not belong to the target population. Document the rationale and report results with and without outliers."  </span>
<span id="cb105-1063"><a href="#cb105-1063" aria-hidden="true" tabindex="-1"></a>Removing outliers to achieve desired results is unethical; only remove when justified.</span>
<span id="cb105-1064"><a href="#cb105-1064" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1065"><a href="#cb105-1065" aria-hidden="true" tabindex="-1"></a>**A8. B)** "Values outside plausible ranges (e.g., age = 150, Likert response = 8 on a 1–7 scale)."  </span>
<span id="cb105-1066"><a href="#cb105-1066" aria-hidden="true" tabindex="-1"></a>A response of 8 on a 1–7 scale is impossible and indicates a data entry error.</span>
<span id="cb105-1067"><a href="#cb105-1067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1068"><a href="#cb105-1068" aria-hidden="true" tabindex="-1"></a>**A9. A)** "Maintain a data cleaning script that: Reads raw data, flags potential outliers, errors, or inconsistencies, applies corrections or exclusions with justifications, produces a cleaned dataset for analysis."  </span>
<span id="cb105-1069"><a href="#cb105-1069" aria-hidden="true" tabindex="-1"></a>Reproducible documentation allows verification and transparency.</span>
<span id="cb105-1070"><a href="#cb105-1070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1071"><a href="#cb105-1071" aria-hidden="true" tabindex="-1"></a>**A10. B)** "Deviations at the tails indicate skewness or heavy tails."  </span>
<span id="cb105-1072"><a href="#cb105-1072" aria-hidden="true" tabindex="-1"></a>Points departing from the diagonal at the extremes suggest the distribution has tails that are heavier or lighter than a normal distribution.</span>
<span id="cb105-1073"><a href="#cb105-1073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1074"><a href="#cb105-1074" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb105-1075"><a href="#cb105-1075" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1076"><a href="#cb105-1076" aria-hidden="true" tabindex="-1"></a><span class="fu">### Key Takeaways</span></span>
<span id="cb105-1077"><a href="#cb105-1077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1078"><a href="#cb105-1078" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Data screening is critical with small samples, where single observations can distort results.</span>
<span id="cb105-1079"><a href="#cb105-1079" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use visual diagnostics (boxplots, scatterplots, Q-Q plots) to detect outliers, assess normality, and check regression assumptions.</span>
<span id="cb105-1080"><a href="#cb105-1080" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Remove outliers only with clear justification (data entry error, out-of-scope observation); report results with and without.</span>
<span id="cb105-1081"><a href="#cb105-1081" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Normality tests (Shapiro–Wilk) have limited power with small samples; rely primarily on visual checks.</span>
<span id="cb105-1082"><a href="#cb105-1082" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Regression diagnostics (residual plots, leverage, Cook's distance) identify influential observations and assumption violations.</span>
<span id="cb105-1083"><a href="#cb105-1083" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Document all data cleaning decisions in reproducible scripts and report exclusions transparently.</span>
<span id="cb105-1084"><a href="#cb105-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1085"><a href="#cb105-1085" aria-hidden="true" tabindex="-1"></a><span class="fu">### Smoke Test</span></span>
<span id="cb105-1086"><a href="#cb105-1086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1089"><a href="#cb105-1089" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1090"><a href="#cb105-1090" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-13</span></span>
<span id="cb105-1091"><a href="#cb105-1091" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run outlier detection</span></span>
<span id="cb105-1092"><a href="#cb105-1092" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb105-1093"><a href="#cb105-1093" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">20</span>)  <span class="co"># 20 is an outlier</span></span>
<span id="cb105-1094"><a href="#cb105-1094" aria-hidden="true" tabindex="-1"></a>Q1 <span class="ot">&lt;-</span> <span class="fu">quantile</span>(x, <span class="fl">0.25</span>)</span>
<span id="cb105-1095"><a href="#cb105-1095" aria-hidden="true" tabindex="-1"></a>Q3 <span class="ot">&lt;-</span> <span class="fu">quantile</span>(x, <span class="fl">0.75</span>)</span>
<span id="cb105-1096"><a href="#cb105-1096" aria-hidden="true" tabindex="-1"></a>IQR_val <span class="ot">&lt;-</span> <span class="fu">IQR</span>(x)</span>
<span id="cb105-1097"><a href="#cb105-1097" aria-hidden="true" tabindex="-1"></a>upper_fence <span class="ot">&lt;-</span> Q3 <span class="sc">+</span> <span class="fl">1.5</span> <span class="sc">*</span> IQR_val</span>
<span id="cb105-1098"><a href="#cb105-1098" aria-hidden="true" tabindex="-1"></a>x[x <span class="sc">&gt;</span> upper_fence]</span>
<span id="cb105-1099"><a href="#cb105-1099" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1100"><a href="#cb105-1100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1101"><a href="#cb105-1101" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1102"><a href="#cb105-1102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1103"><a href="#cb105-1103" aria-hidden="true" tabindex="-1"></a><span class="fu">## Chapter 12. Handling Missing Data in Small Samples</span></span>
<span id="cb105-1104"><a href="#cb105-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1105"><a href="#cb105-1105" aria-hidden="true" tabindex="-1"></a><span class="fu">### Learning Objectives</span></span>
<span id="cb105-1106"><a href="#cb105-1106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1107"><a href="#cb105-1107" aria-hidden="true" tabindex="-1"></a>By the end of this chapter, you will be able to:</span>
<span id="cb105-1108"><a href="#cb105-1108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1109"><a href="#cb105-1109" aria-hidden="true" tabindex="-1"></a>**Conceptual Understanding**</span>
<span id="cb105-1110"><a href="#cb105-1110" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Explain the distinctions between MCAR, MAR, and MNAR mechanisms</span>
<span id="cb105-1111"><a href="#cb105-1111" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Understand why complete-case analysis can introduce bias</span>
<span id="cb105-1112"><a href="#cb105-1112" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Recognize the theoretical foundations of multiple imputation (Rubin's rules)</span>
<span id="cb105-1113"><a href="#cb105-1113" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Understand the limitations of imputation methods with very small samples</span>
<span id="cb105-1114"><a href="#cb105-1114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1115"><a href="#cb105-1115" aria-hidden="true" tabindex="-1"></a>**Practical Skills**</span>
<span id="cb105-1116"><a href="#cb105-1116" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Diagnose missingness patterns using visualization and tests in R</span>
<span id="cb105-1117"><a href="#cb105-1117" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Implement multiple imputation using the <span class="in">`mice`</span> package</span>
<span id="cb105-1118"><a href="#cb105-1118" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Pool parameter estimates and standard errors across imputed datasets</span>
<span id="cb105-1119"><a href="#cb105-1119" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Generate diagnostic plots (trace plots, convergence checks) for MICE</span>
<span id="cb105-1120"><a href="#cb105-1120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1121"><a href="#cb105-1121" aria-hidden="true" tabindex="-1"></a>**Critical Evaluation**</span>
<span id="cb105-1122"><a href="#cb105-1122" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Assess when multiple imputation is feasible vs. when complete-case is preferable</span>
<span id="cb105-1123"><a href="#cb105-1123" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Evaluate the plausibility of MAR assumptions in research contexts</span>
<span id="cb105-1124"><a href="#cb105-1124" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Critique missing data handling approaches in published small-sample studies</span>
<span id="cb105-1125"><a href="#cb105-1125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1126"><a href="#cb105-1126" aria-hidden="true" tabindex="-1"></a>**Application**</span>
<span id="cb105-1127"><a href="#cb105-1127" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Report missing data patterns and mechanisms transparently</span>
<span id="cb105-1128"><a href="#cb105-1128" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Choose appropriate imputation strategies given sample size and missingness</span>
<span id="cb105-1129"><a href="#cb105-1129" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Conduct sensitivity analyses comparing complete-case vs. imputed results</span>
<span id="cb105-1130"><a href="#cb105-1130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1131"><a href="#cb105-1131" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Challenge of Missing Data in Small Samples</span></span>
<span id="cb105-1132"><a href="#cb105-1132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1133"><a href="#cb105-1133" aria-hidden="true" tabindex="-1"></a>Missing data are common in applied research. Participants skip survey questions, drop out of longitudinal studies, or provide incomplete records. With large samples, modern methods (multiple imputation, full information maximum likelihood) can handle substantial missingness without excessive bias. With small samples, however, missing data pose severe problems. Even a few missing observations can substantially reduce effective sample size and statistical power.</span>
<span id="cb105-1134"><a href="#cb105-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1135"><a href="#cb105-1135" aria-hidden="true" tabindex="-1"></a>Missing data methods rely on large-sample asymptotics and may be unstable or inappropriate when samples are very small (n &lt; 30) or missingness is extensive (&gt; 20%). In such cases, prevention (minimise missingness through careful design) and transparency (report missingness patterns and sensitivity analyses) are more important than sophisticated imputation.</span>
<span id="cb105-1136"><a href="#cb105-1136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1137"><a href="#cb105-1137" aria-hidden="true" tabindex="-1"></a><span class="fu">### Types of Missingness</span></span>
<span id="cb105-1138"><a href="#cb105-1138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1139"><a href="#cb105-1139" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**MCAR (Missing Completely At Random)**: Missingness is unrelated to any observed or unobserved variables. For example, a survey page is randomly skipped due to a software glitch. MCAR is rare in practice.</span>
<span id="cb105-1140"><a href="#cb105-1140" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**MAR (Missing At Random)**: Missingness is related to observed variables but not to the missing values themselves. For example, older participants are more likely to skip a technology question, but conditional on age, missingness is random. Most missing data methods assume MAR.</span>
<span id="cb105-1141"><a href="#cb105-1141" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**MNAR (Missing Not At Random)**: Missingness is related to the unobserved values themselves. For example, individuals with high depression scores are more likely to drop out of a study. MNAR is the most problematic and requires sensitivity analyses or models for the missingness mechanism.</span>
<span id="cb105-1142"><a href="#cb105-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1143"><a href="#cb105-1143" aria-hidden="true" tabindex="-1"></a><span class="fu">### Describing Missingness Patterns</span></span>
<span id="cb105-1144"><a href="#cb105-1144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1145"><a href="#cb105-1145" aria-hidden="true" tabindex="-1"></a>Before handling missing data, describe the pattern:</span>
<span id="cb105-1146"><a href="#cb105-1146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1147"><a href="#cb105-1147" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How many observations have missing values on each variable?</span>
<span id="cb105-1148"><a href="#cb105-1148" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Are missing values concentrated in certain individuals or certain variables?</span>
<span id="cb105-1149"><a href="#cb105-1149" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Is missingness related to observed variables (compare characteristics of complete vs. incomplete cases)?</span>
<span id="cb105-1150"><a href="#cb105-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1151"><a href="#cb105-1151" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example Dataset for Diagnostics</span></span>
<span id="cb105-1152"><a href="#cb105-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1153"><a href="#cb105-1153" aria-hidden="true" tabindex="-1"></a>To demonstrate the diagnostics in this chapter, we simulate a small dataset with missing values on <span class="in">`satisfaction`</span> and <span class="in">`performance`</span>.</span>
<span id="cb105-1154"><a href="#cb105-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1157"><a href="#cb105-1157" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1158"><a href="#cb105-1158" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-14</span></span>
<span id="cb105-1159"><a href="#cb105-1159" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb105-1160"><a href="#cb105-1160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1161"><a href="#cb105-1161" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb105-1162"><a href="#cb105-1162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1163"><a href="#cb105-1163" aria-hidden="true" tabindex="-1"></a>study_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb105-1164"><a href="#cb105-1164" aria-hidden="true" tabindex="-1"></a>  <span class="at">participant =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">25</span>,</span>
<span id="cb105-1165"><a href="#cb105-1165" aria-hidden="true" tabindex="-1"></a>  <span class="at">age =</span> <span class="fu">sample</span>(<span class="dv">20</span><span class="sc">:</span><span class="dv">60</span>, <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>),</span>
<span id="cb105-1166"><a href="#cb105-1166" aria-hidden="true" tabindex="-1"></a>  <span class="at">satisfaction =</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">7</span>, <span class="cn">NA</span>), <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.15</span>, <span class="fl">0.2</span>, <span class="fl">0.25</span>, <span class="fl">0.2</span>, <span class="fl">0.15</span>, <span class="fl">0.05</span>)),</span>
<span id="cb105-1167"><a href="#cb105-1167" aria-hidden="true" tabindex="-1"></a>  <span class="at">performance =</span> <span class="fu">c</span>(<span class="fu">sample</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">90</span>, <span class="dv">20</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>), <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="dv">5</span>))</span>
<span id="cb105-1168"><a href="#cb105-1168" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb105-1169"><a href="#cb105-1169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1170"><a href="#cb105-1170" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(study_data)</span>
<span id="cb105-1171"><a href="#cb105-1171" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1172"><a href="#cb105-1172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1173"><a href="#cb105-1173" aria-hidden="true" tabindex="-1"></a><span class="fu">### Testing the MCAR Assumption</span></span>
<span id="cb105-1174"><a href="#cb105-1174" aria-hidden="true" tabindex="-1"></a>Little's MCAR test evaluates whether missingness is consistent with the MCAR mechanism. The test compares observed means across missing-data patterns; a large p-value suggests MCAR is plausible, whereas a small p-value indicates that missingness likely depends on observed data (i.e., not MCAR).</span>
<span id="cb105-1175"><a href="#cb105-1175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1178"><a href="#cb105-1178" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1179"><a href="#cb105-1179" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-15</span></span>
<span id="cb105-1180"><a href="#cb105-1180" aria-hidden="true" tabindex="-1"></a><span class="co"># Test if data are Missing Completely At Random (MCAR)</span></span>
<span id="cb105-1181"><a href="#cb105-1181" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(naniar)</span>
<span id="cb105-1182"><a href="#cb105-1182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1183"><a href="#cb105-1183" aria-hidden="true" tabindex="-1"></a><span class="co"># Little's MCAR test</span></span>
<span id="cb105-1184"><a href="#cb105-1184" aria-hidden="true" tabindex="-1"></a><span class="fu">mcar_test</span>(study_data)</span>
<span id="cb105-1185"><a href="#cb105-1185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1186"><a href="#cb105-1186" aria-hidden="true" tabindex="-1"></a><span class="co"># Interpretation:</span></span>
<span id="cb105-1187"><a href="#cb105-1187" aria-hidden="true" tabindex="-1"></a><span class="co"># p &gt; 0.05: Data consistent with MCAR (missingness random)</span></span>
<span id="cb105-1188"><a href="#cb105-1188" aria-hidden="true" tabindex="-1"></a><span class="co"># p &lt; 0.05: Evidence against MCAR (missingness not random)</span></span>
<span id="cb105-1189"><a href="#cb105-1189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1190"><a href="#cb105-1190" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualise missing data patterns</span></span>
<span id="cb105-1191"><a href="#cb105-1191" aria-hidden="true" tabindex="-1"></a><span class="fu">gg_miss_var</span>(study_data, <span class="at">show_pct =</span> <span class="cn">TRUE</span>)</span>
<span id="cb105-1192"><a href="#cb105-1192" aria-hidden="true" tabindex="-1"></a><span class="fu">vis_miss</span>(study_data)</span>
<span id="cb105-1193"><a href="#cb105-1193" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1194"><a href="#cb105-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1195"><a href="#cb105-1195" aria-hidden="true" tabindex="-1"></a>Little's MCAR test assesses whether missing data patterns are completely random. However, with small samples (n &lt; 50), this test has low power and should be supplemented with:</span>
<span id="cb105-1196"><a href="#cb105-1196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1197"><a href="#cb105-1197" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Visual inspection of missingness patterns</span>
<span id="cb105-1198"><a href="#cb105-1198" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Comparison of complete vs. incomplete cases</span>
<span id="cb105-1199"><a href="#cb105-1199" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Domain knowledge about likely mechanisms</span>
<span id="cb105-1200"><a href="#cb105-1200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1201"><a href="#cb105-1201" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example: Summarising Missing Data</span></span>
<span id="cb105-1202"><a href="#cb105-1202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1203"><a href="#cb105-1203" aria-hidden="true" tabindex="-1"></a>We continue working with the simulated dataset (<span class="in">`study_data`</span>) created above.</span>
<span id="cb105-1204"><a href="#cb105-1204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1207"><a href="#cb105-1207" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1208"><a href="#cb105-1208" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-16</span></span>
<span id="cb105-1209"><a href="#cb105-1209" aria-hidden="true" tabindex="-1"></a><span class="co"># Count missing values per variable</span></span>
<span id="cb105-1210"><a href="#cb105-1210" aria-hidden="true" tabindex="-1"></a>missing_summary <span class="ot">&lt;-</span> study_data <span class="sc">%&gt;%</span></span>
<span id="cb105-1211"><a href="#cb105-1211" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), <span class="sc">~</span> <span class="fu">sum</span>(<span class="fu">is.na</span>(.))))</span>
<span id="cb105-1212"><a href="#cb105-1212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1213"><a href="#cb105-1213" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(missing_summary)</span>
<span id="cb105-1214"><a href="#cb105-1214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1215"><a href="#cb105-1215" aria-hidden="true" tabindex="-1"></a><span class="co"># Proportion missing</span></span>
<span id="cb105-1216"><a href="#cb105-1216" aria-hidden="true" tabindex="-1"></a>prop_missing <span class="ot">&lt;-</span> study_data <span class="sc">%&gt;%</span></span>
<span id="cb105-1217"><a href="#cb105-1217" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), <span class="sc">~</span> <span class="fu">mean</span>(<span class="fu">is.na</span>(.))))</span>
<span id="cb105-1218"><a href="#cb105-1218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1219"><a href="#cb105-1219" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(prop_missing)</span>
<span id="cb105-1220"><a href="#cb105-1220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1221"><a href="#cb105-1221" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare complete vs incomplete cases</span></span>
<span id="cb105-1222"><a href="#cb105-1222" aria-hidden="true" tabindex="-1"></a>study_data <span class="ot">&lt;-</span> study_data <span class="sc">%&gt;%</span></span>
<span id="cb105-1223"><a href="#cb105-1223" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">complete =</span> <span class="fu">complete.cases</span>(study_data))</span>
<span id="cb105-1224"><a href="#cb105-1224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1225"><a href="#cb105-1225" aria-hidden="true" tabindex="-1"></a>complete_vs_incomplete <span class="ot">&lt;-</span> study_data <span class="sc">%&gt;%</span></span>
<span id="cb105-1226"><a href="#cb105-1226" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(complete) <span class="sc">%&gt;%</span></span>
<span id="cb105-1227"><a href="#cb105-1227" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mean_age =</span> <span class="fu">mean</span>(age, <span class="at">na.rm =</span> <span class="cn">TRUE</span>), <span class="at">.groups =</span> <span class="st">"drop"</span>)</span>
<span id="cb105-1228"><a href="#cb105-1228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1229"><a href="#cb105-1229" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(complete_vs_incomplete)</span>
<span id="cb105-1230"><a href="#cb105-1230" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1231"><a href="#cb105-1231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1232"><a href="#cb105-1232" aria-hidden="true" tabindex="-1"></a>Interpretation: The summary shows that <span class="in">`satisfaction`</span> has 1–2 missing values and <span class="in">`performance`</span> has 5 missing values (20% of the sample). If complete and incomplete cases differ systematically (e.g., incomplete cases are older), missingness may be MAR or MNAR. If they are similar, missingness may be closer to MCAR. With 20% missingness and n = 25, only 20 cases remain in a complete-case analysis (listwise deletion), reducing power substantially.</span>
<span id="cb105-1233"><a href="#cb105-1233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1234"><a href="#cb105-1234" aria-hidden="true" tabindex="-1"></a><span class="fu">### Complete-Case (Listwise Deletion) Analysis</span></span>
<span id="cb105-1235"><a href="#cb105-1235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1236"><a href="#cb105-1236" aria-hidden="true" tabindex="-1"></a>The simplest approach is to analyse only cases with complete data on all variables of interest. This is valid if missingness is MCAR and the reduction in sample size is tolerable. However, it can introduce bias if missingness is MAR or MNAR, and it wastes information.</span>
<span id="cb105-1237"><a href="#cb105-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1238"><a href="#cb105-1238" aria-hidden="true" tabindex="-1"></a>**When to use**: Missingness is minimal (&lt; 5%), or MCAR is plausible, or imputation methods are infeasible due to very small sample size.</span>
<span id="cb105-1239"><a href="#cb105-1239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1240"><a href="#cb105-1240" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb105-1241"><a href="#cb105-1241" aria-hidden="true" tabindex="-1"></a><span class="fu">## ⚠️ Common Misconception: "Listwise Deletion Is Always Safe if Missingness Is Random"</span></span>
<span id="cb105-1242"><a href="#cb105-1242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1243"><a href="#cb105-1243" aria-hidden="true" tabindex="-1"></a>**Myth**: "If I check for MCAR and the test is non-significant, listwise deletion is unbiased."</span>
<span id="cb105-1244"><a href="#cb105-1244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1245"><a href="#cb105-1245" aria-hidden="true" tabindex="-1"></a>**Reality**: Even when missingness is **truly MCAR**, listwise deletion **loses power** and can introduce bias if you have multiple variables with independent missing patterns.</span>
<span id="cb105-1246"><a href="#cb105-1246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1247"><a href="#cb105-1247" aria-hidden="true" tabindex="-1"></a>**Demonstration**:</span>
<span id="cb105-1250"><a href="#cb105-1250" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1251"><a href="#cb105-1251" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-misconception-1</span></span>
<span id="cb105-1252"><a href="#cb105-1252" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb105-1253"><a href="#cb105-1253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1254"><a href="#cb105-1254" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate complete data: n=50, correlation between x and y = 0.6</span></span>
<span id="cb105-1255"><a href="#cb105-1255" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb105-1256"><a href="#cb105-1256" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="dv">50</span>, <span class="dv">10</span>)</span>
<span id="cb105-1257"><a href="#cb105-1257" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fl">0.6</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">8</span>)</span>
<span id="cb105-1258"><a href="#cb105-1258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1259"><a href="#cb105-1259" aria-hidden="true" tabindex="-1"></a><span class="co"># True correlation (no missing data)</span></span>
<span id="cb105-1260"><a href="#cb105-1260" aria-hidden="true" tabindex="-1"></a>true_cor <span class="ot">&lt;-</span> <span class="fu">cor</span>(x, y)</span>
<span id="cb105-1261"><a href="#cb105-1261" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"True correlation (complete data):"</span>, <span class="fu">round</span>(true_cor, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span>
<span id="cb105-1262"><a href="#cb105-1262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1263"><a href="#cb105-1263" aria-hidden="true" tabindex="-1"></a><span class="co"># Introduce MCAR missingness (20% on x, 20% on y, independently)</span></span>
<span id="cb105-1264"><a href="#cb105-1264" aria-hidden="true" tabindex="-1"></a>x_missing <span class="ot">&lt;-</span> x</span>
<span id="cb105-1265"><a href="#cb105-1265" aria-hidden="true" tabindex="-1"></a>y_missing <span class="ot">&lt;-</span> y</span>
<span id="cb105-1266"><a href="#cb105-1266" aria-hidden="true" tabindex="-1"></a>x_missing[<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="dv">10</span>)] <span class="ot">&lt;-</span> <span class="cn">NA</span>  <span class="co"># 20% missing</span></span>
<span id="cb105-1267"><a href="#cb105-1267" aria-hidden="true" tabindex="-1"></a>y_missing[<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="dv">10</span>)] <span class="ot">&lt;-</span> <span class="cn">NA</span>  <span class="co"># 20% missing</span></span>
<span id="cb105-1268"><a href="#cb105-1268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1269"><a href="#cb105-1269" aria-hidden="true" tabindex="-1"></a><span class="co"># Listwise deletion: only cases with both x and y</span></span>
<span id="cb105-1270"><a href="#cb105-1270" aria-hidden="true" tabindex="-1"></a>complete_cases <span class="ot">&lt;-</span> <span class="fu">complete.cases</span>(x_missing, y_missing)</span>
<span id="cb105-1271"><a href="#cb105-1271" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Complete cases:"</span>, <span class="fu">sum</span>(complete_cases), <span class="st">"/"</span>, n, <span class="st">"("</span>, </span>
<span id="cb105-1272"><a href="#cb105-1272" aria-hidden="true" tabindex="-1"></a>    <span class="fu">round</span>(<span class="dv">100</span> <span class="sc">*</span> <span class="fu">mean</span>(complete_cases), <span class="dv">1</span>), <span class="st">"%)</span><span class="sc">\n\n</span><span class="st">"</span>)</span>
<span id="cb105-1273"><a href="#cb105-1273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1274"><a href="#cb105-1274" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation with listwise deletion</span></span>
<span id="cb105-1275"><a href="#cb105-1275" aria-hidden="true" tabindex="-1"></a>listwise_cor <span class="ot">&lt;-</span> <span class="fu">cor</span>(x_missing[complete_cases], y_missing[complete_cases])</span>
<span id="cb105-1276"><a href="#cb105-1276" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Correlation (listwise deletion):"</span>, <span class="fu">round</span>(listwise_cor, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-1277"><a href="#cb105-1277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1278"><a href="#cb105-1278" aria-hidden="true" tabindex="-1"></a><span class="co"># Power loss</span></span>
<span id="cb105-1279"><a href="#cb105-1279" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">→ Lost"</span>, n <span class="sc">-</span> <span class="fu">sum</span>(complete_cases), <span class="st">"cases ("</span>, </span>
<span id="cb105-1280"><a href="#cb105-1280" aria-hidden="true" tabindex="-1"></a>    <span class="fu">round</span>(<span class="dv">100</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">mean</span>(complete_cases)), <span class="dv">1</span>), <span class="st">"% of data)</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-1281"><a href="#cb105-1281" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"→ Correlation estimate is based on n ="</span>, <span class="fu">sum</span>(complete_cases), </span>
<span id="cb105-1282"><a href="#cb105-1282" aria-hidden="true" tabindex="-1"></a>    <span class="st">"instead of n = 50</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-1283"><a href="#cb105-1283" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"→ Standard error is"</span>, <span class="fu">round</span>(<span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">/</span><span class="fu">sum</span>(complete_cases)) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">/</span>n), <span class="dv">2</span>), </span>
<span id="cb105-1284"><a href="#cb105-1284" aria-hidden="true" tabindex="-1"></a>    <span class="st">"times larger</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-1285"><a href="#cb105-1285" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1286"><a href="#cb105-1286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1287"><a href="#cb105-1287" aria-hidden="true" tabindex="-1"></a>**Why this matters:**</span>
<span id="cb105-1288"><a href="#cb105-1288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1289"><a href="#cb105-1289" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Power loss**: With 20% missing on x and 20% on y (independent), you lose ~36% of cases</span>
<span id="cb105-1290"><a href="#cb105-1290" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Formula: (1 - p_x) × (1 - p_y) = 0.8 × 0.8 = 0.64 → 64% remain, 36% lost</span>
<span id="cb105-1291"><a href="#cb105-1291" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Multiple variables compound**: With 5 variables each 15% missing, you keep only 44% of cases</span>
<span id="cb105-1292"><a href="#cb105-1292" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Bias can still occur**: If missingness is MAR (not MCAR), listwise deletion is biased</span>
<span id="cb105-1293"><a href="#cb105-1293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1294"><a href="#cb105-1294" aria-hidden="true" tabindex="-1"></a>**Lesson**: </span>
<span id="cb105-1295"><a href="#cb105-1295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1296"><a href="#cb105-1296" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**MCAR does NOT mean listwise deletion is optimal**—it's still wasteful</span>
<span id="cb105-1297"><a href="#cb105-1297" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use **multiple imputation** even with MCAR if missingness &gt; 10%</span>
<span id="cb105-1298"><a href="#cb105-1298" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>With small samples (n &lt; 50), losing even 20% of cases is catastrophic for power</span>
<span id="cb105-1299"><a href="#cb105-1299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1300"><a href="#cb105-1300" aria-hidden="true" tabindex="-1"></a>**When listwise deletion is actually safe:**</span>
<span id="cb105-1301"><a href="#cb105-1301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1302"><a href="#cb105-1302" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Missingness &lt; 5% on any variable</span>
<span id="cb105-1303"><a href="#cb105-1303" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>n is large enough that losing cases doesn't hurt power</span>
<span id="cb105-1304"><a href="#cb105-1304" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>You've verified MCAR (not just MAR) AND documented the power loss</span>
<span id="cb105-1305"><a href="#cb105-1305" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb105-1306"><a href="#cb105-1306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1307"><a href="#cb105-1307" aria-hidden="true" tabindex="-1"></a><span class="fu">### Mean Imputation (Not Recommended)</span></span>
<span id="cb105-1308"><a href="#cb105-1308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1309"><a href="#cb105-1309" aria-hidden="true" tabindex="-1"></a>Mean imputation replaces missing values with the variable mean. This approach artificially reduces variance and distorts correlations. It is generally not recommended, especially with small samples where each imputed value has disproportionate impact.</span>
<span id="cb105-1310"><a href="#cb105-1310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1311"><a href="#cb105-1311" aria-hidden="true" tabindex="-1"></a>**When to use**: Rarely. Only if missingness is trivial (1–2 values in a large dataset) and for descriptive purposes only (not inference).</span>
<span id="cb105-1312"><a href="#cb105-1312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1313"><a href="#cb105-1313" aria-hidden="true" tabindex="-1"></a><span class="fu">### Last Observation Carried Forward (LOCF)</span></span>
<span id="cb105-1314"><a href="#cb105-1314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1315"><a href="#cb105-1315" aria-hidden="true" tabindex="-1"></a>In longitudinal studies, LOCF replaces missing follow-up values with the last observed value for that individual. This assumes no change after the last observation, which is often unrealistic. LOCF can bias estimates and is not generally recommended.</span>
<span id="cb105-1316"><a href="#cb105-1316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1317"><a href="#cb105-1317" aria-hidden="true" tabindex="-1"></a>**When to use**: Rarely. Only if the assumption of no change is plausible, and alternatives are infeasible.</span>
<span id="cb105-1318"><a href="#cb105-1318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1319"><a href="#cb105-1319" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multiple Imputation (Caution with Small Samples)</span></span>
<span id="cb105-1320"><a href="#cb105-1320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1321"><a href="#cb105-1321" aria-hidden="true" tabindex="-1"></a>Multiple imputation (MI) generates several plausible imputed datasets, analyses each separately, and pools results to account for imputation uncertainty. MI is the gold standard for handling missing data in large samples. However, MI requires sufficient data to estimate imputation models reliably. With very small samples (n &lt; 30) or many missing values (&gt; 20%), MI can be unstable or yield implausible imputations.</span>
<span id="cb105-1322"><a href="#cb105-1322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1323"><a href="#cb105-1323" aria-hidden="true" tabindex="-1"></a>**When to use**: Moderate sample sizes (n ≥ 30), missingness not too extensive (&lt; 20%), MAR assumption plausible.</span>
<span id="cb105-1324"><a href="#cb105-1324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1325"><a href="#cb105-1325" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example: Multiple Imputation with mice (Caution)</span></span>
<span id="cb105-1326"><a href="#cb105-1326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1327"><a href="#cb105-1327" aria-hidden="true" tabindex="-1"></a>We apply MI to the dataset with missing <span class="in">`satisfaction`</span> and <span class="in">`performance`</span> values. Given the small sample (n = 25) and 20% missingness, interpret results cautiously.</span>
<span id="cb105-1328"><a href="#cb105-1328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1331"><a href="#cb105-1331" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1332"><a href="#cb105-1332" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-17</span></span>
<span id="cb105-1333"><a href="#cb105-1333" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiple imputation requires the 'mice' package</span></span>
<span id="cb105-1334"><a href="#cb105-1334" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">requireNamespace</span>(<span class="st">"mice"</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb105-1335"><a href="#cb105-1335" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(mice)</span>
<span id="cb105-1336"><a href="#cb105-1336" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-1337"><a href="#cb105-1337" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Remove 'complete' indicator variable before imputation</span></span>
<span id="cb105-1338"><a href="#cb105-1338" aria-hidden="true" tabindex="-1"></a>  impute_data <span class="ot">&lt;-</span> study_data <span class="sc">%&gt;%</span> <span class="fu">select</span>(participant, age, satisfaction, performance)</span>
<span id="cb105-1339"><a href="#cb105-1339" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-1340"><a href="#cb105-1340" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Perform multiple imputation (m = 5 imputations)</span></span>
<span id="cb105-1341"><a href="#cb105-1341" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb105-1342"><a href="#cb105-1342" aria-hidden="true" tabindex="-1"></a>  imp <span class="ot">&lt;-</span> <span class="fu">mice</span>(impute_data, <span class="at">m =</span> <span class="dv">5</span>, <span class="at">method =</span> <span class="st">"pmm"</span>, <span class="at">printFlag =</span> <span class="cn">FALSE</span>)</span>
<span id="cb105-1343"><a href="#cb105-1343" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-1344"><a href="#cb105-1344" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Check imputed values</span></span>
<span id="cb105-1345"><a href="#cb105-1345" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(imp)</span>
<span id="cb105-1346"><a href="#cb105-1346" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-1347"><a href="#cb105-1347" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Example analysis: regress performance on age and satisfaction</span></span>
<span id="cb105-1348"><a href="#cb105-1348" aria-hidden="true" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">with</span>(imp, <span class="fu">lm</span>(performance <span class="sc">~</span> age <span class="sc">+</span> satisfaction))</span>
<span id="cb105-1349"><a href="#cb105-1349" aria-hidden="true" tabindex="-1"></a>  pooled <span class="ot">&lt;-</span> <span class="fu">pool</span>(fit)</span>
<span id="cb105-1350"><a href="#cb105-1350" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>(pooled)</span>
<span id="cb105-1351"><a href="#cb105-1351" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-1352"><a href="#cb105-1352" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb105-1353"><a href="#cb105-1353" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"Install 'mice' package to run multiple imputation.</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-1354"><a href="#cb105-1354" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"With very small samples, MI may be unstable; consider complete-case analysis.</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-1355"><a href="#cb105-1355" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb105-1356"><a href="#cb105-1356" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1357"><a href="#cb105-1357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1358"><a href="#cb105-1358" aria-hidden="true" tabindex="-1"></a>Interpretation: MI generates plausible values for missing data based on observed relationships. The pooled results combine estimates across imputations, with standard errors adjusted for imputation uncertainty. However, with n = 25 and 20% missingness, the imputation model is estimated from limited data, and results may be unstable. Compare MI results to complete-case analysis; if they differ substantially, report both and acknowledge uncertainty.</span>
<span id="cb105-1359"><a href="#cb105-1359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1360"><a href="#cb105-1360" aria-hidden="true" tabindex="-1"></a><span class="fu">### Checking Convergence of Multiple Imputation</span></span>
<span id="cb105-1361"><a href="#cb105-1361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1362"><a href="#cb105-1362" aria-hidden="true" tabindex="-1"></a>When using <span class="in">`mice`</span>, always check whether the imputation algorithm has converged. Poor convergence means the imputed values may not be stable, especially with small samples or complex missing data patterns.</span>
<span id="cb105-1363"><a href="#cb105-1363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1364"><a href="#cb105-1364" aria-hidden="true" tabindex="-1"></a>**Key diagnostics:**</span>
<span id="cb105-1365"><a href="#cb105-1365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1366"><a href="#cb105-1366" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Trace plots**: Plot imputed values across iterations for each variable. Lines should mix well without trends.</span>
<span id="cb105-1367"><a href="#cb105-1367" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Strip plots**: Display distributions of observed (blue) vs. imputed (red) values. Distributions should be similar if MAR holds.</span>
<span id="cb105-1368"><a href="#cb105-1368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1371"><a href="#cb105-1371" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1372"><a href="#cb105-1372" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-17-diagnostics</span></span>
<span id="cb105-1373"><a href="#cb105-1373" aria-hidden="true" tabindex="-1"></a><span class="co"># Convergence diagnostics for mice imputation</span></span>
<span id="cb105-1374"><a href="#cb105-1374" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">requireNamespace</span>(<span class="st">"mice"</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>) <span class="sc">&amp;&amp;</span> <span class="fu">exists</span>(<span class="st">"imp"</span>)) {</span>
<span id="cb105-1375"><a href="#cb105-1375" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(mice)</span>
<span id="cb105-1376"><a href="#cb105-1376" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-1377"><a href="#cb105-1377" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Trace plots: check convergence across iterations</span></span>
<span id="cb105-1378"><a href="#cb105-1378" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Each line represents one imputed dataset; should be well-mixed</span></span>
<span id="cb105-1379"><a href="#cb105-1379" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(imp, <span class="fu">c</span>(<span class="st">"satisfaction"</span>, <span class="st">"performance"</span>))</span>
<span id="cb105-1380"><a href="#cb105-1380" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-1381"><a href="#cb105-1381" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Strip plots: compare observed (blue) vs imputed (red) values</span></span>
<span id="cb105-1382"><a href="#cb105-1382" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Distributions should be similar under MAR</span></span>
<span id="cb105-1383"><a href="#cb105-1383" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stripplot</span>(imp, satisfaction <span class="sc">+</span> performance <span class="sc">~</span> .imp, <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">cex =</span> <span class="fl">1.2</span>)</span>
<span id="cb105-1384"><a href="#cb105-1384" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-1385"><a href="#cb105-1385" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">=== Convergence Check ===</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-1386"><a href="#cb105-1386" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"✓ Trace plots: Lines should mix well without systematic trends</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-1387"><a href="#cb105-1387" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"✓ Strip plots: Imputed (red) should resemble observed (blue) distributions</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-1388"><a href="#cb105-1388" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"✓ If convergence looks poor, increase iterations: mice(..., maxit = 20)</span><span class="sc">\n\n</span><span class="st">"</span>)</span>
<span id="cb105-1389"><a href="#cb105-1389" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-1390"><a href="#cb105-1390" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb105-1391"><a href="#cb105-1391" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"mice imputation object not found; run the previous chunk first.</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-1392"><a href="#cb105-1392" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb105-1393"><a href="#cb105-1393" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1394"><a href="#cb105-1394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1395"><a href="#cb105-1395" aria-hidden="true" tabindex="-1"></a>**What to look for:**</span>
<span id="cb105-1396"><a href="#cb105-1396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1397"><a href="#cb105-1397" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Trace plots**: Each imputation should show relatively stable values across iterations. If you see upward or downward trends, the algorithm hasn't converged. Solution: increase <span class="in">`maxit`</span> (default is 5).</span>
<span id="cb105-1398"><a href="#cb105-1398" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Strip plots**: The distribution of imputed values (red) should be similar to observed values (blue). Large differences suggest the imputation model may not fit well or MNAR may be present.</span>
<span id="cb105-1399"><a href="#cb105-1399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1400"><a href="#cb105-1400" aria-hidden="true" tabindex="-1"></a>**With small samples (n &lt; 30)**, convergence can be slower and more sensitive to model specification. If diagnostics show problems, consider:</span>
<span id="cb105-1401"><a href="#cb105-1401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1402"><a href="#cb105-1402" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Simplifying the imputation model (use predictive mean matching with fewer predictors)</span>
<span id="cb105-1403"><a href="#cb105-1403" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Increasing iterations (<span class="in">`maxit = 20`</span> or more)</span>
<span id="cb105-1404"><a href="#cb105-1404" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Comparing to complete-case analysis as a sensitivity check</span>
<span id="cb105-1405"><a href="#cb105-1405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1406"><a href="#cb105-1406" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sensitivity Analyses</span></span>
<span id="cb105-1407"><a href="#cb105-1407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1408"><a href="#cb105-1408" aria-hidden="true" tabindex="-1"></a>When missingness is substantial or MNAR is suspected, conduct sensitivity analyses:</span>
<span id="cb105-1409"><a href="#cb105-1409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1410"><a href="#cb105-1410" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Compare complete-case results to imputed results.</span>
<span id="cb105-1411"><a href="#cb105-1411" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Vary assumptions about the missing data mechanism (e.g., impute extreme values to simulate worst-case scenarios).</span>
<span id="cb105-1412"><a href="#cb105-1412" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Report results under multiple scenarios and discuss implications.</span>
<span id="cb105-1413"><a href="#cb105-1413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1414"><a href="#cb105-1414" aria-hidden="true" tabindex="-1"></a><span class="fu">### Preventing Missing Data</span></span>
<span id="cb105-1415"><a href="#cb105-1415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1416"><a href="#cb105-1416" aria-hidden="true" tabindex="-1"></a>The best approach to missing data is prevention:</span>
<span id="cb105-1417"><a href="#cb105-1417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1418"><a href="#cb105-1418" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Design clear, concise instruments.</span>
<span id="cb105-1419"><a href="#cb105-1419" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Minimise respondent burden.</span>
<span id="cb105-1420"><a href="#cb105-1420" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Follow up with participants who miss appointments or skip questions.</span>
<span id="cb105-1421"><a href="#cb105-1421" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Pilot test procedures to identify confusing or burdensome items.</span>
<span id="cb105-1422"><a href="#cb105-1422" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Build rapport and trust with participants.</span>
<span id="cb105-1423"><a href="#cb105-1423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1424"><a href="#cb105-1424" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1425"><a href="#cb105-1425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1426"><a href="#cb105-1426" aria-hidden="true" tabindex="-1"></a><span class="fu">## Chapter 12.5. Assessing Multiple Imputation Quality</span></span>
<span id="cb105-1427"><a href="#cb105-1427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1428"><a href="#cb105-1428" aria-hidden="true" tabindex="-1"></a><span class="fu">### Learning Objectives</span></span>
<span id="cb105-1429"><a href="#cb105-1429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1430"><a href="#cb105-1430" aria-hidden="true" tabindex="-1"></a>By the end of this section, you will understand how to diagnose the quality of multiple imputation models. You will learn to check convergence, compare imputed vs. observed distributions, assess sensitivity to the number of imputations (m), and interpret diagnostic plots. These skills ensure that your imputed datasets are appropriate for downstream analyses.</span>
<span id="cb105-1431"><a href="#cb105-1431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1432"><a href="#cb105-1432" aria-hidden="true" tabindex="-1"></a><span class="fu">### Why Imputation Diagnostics Matter</span></span>
<span id="cb105-1433"><a href="#cb105-1433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1434"><a href="#cb105-1434" aria-hidden="true" tabindex="-1"></a>Multiple imputation (MI) is not a "black box" procedure. The quality of imputed values depends on:</span>
<span id="cb105-1435"><a href="#cb105-1435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1436"><a href="#cb105-1436" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Model specification**: Are the imputation models correctly specified (e.g., predictive mean matching, logistic regression for binary variables)?</span>
<span id="cb105-1437"><a href="#cb105-1437" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Convergence**: Have the iterative algorithms stabilised?</span>
<span id="cb105-1438"><a href="#cb105-1438" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Plausibility**: Do imputed values resemble the observed data distribution?</span>
<span id="cb105-1439"><a href="#cb105-1439" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Sensitivity to m**: Are pooled estimates stable across different numbers of imputations?</span>
<span id="cb105-1440"><a href="#cb105-1440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1441"><a href="#cb105-1441" aria-hidden="true" tabindex="-1"></a>**Failure to check diagnostics** can lead to:</span>
<span id="cb105-1442"><a href="#cb105-1442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1443"><a href="#cb105-1443" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Biased parameter estimates</span>
<span id="cb105-1444"><a href="#cb105-1444" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Incorrect standard errors</span>
<span id="cb105-1445"><a href="#cb105-1445" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Imputed values outside plausible ranges</span>
<span id="cb105-1446"><a href="#cb105-1446" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Overconfidence in results</span>
<span id="cb105-1447"><a href="#cb105-1447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1448"><a href="#cb105-1448" aria-hidden="true" tabindex="-1"></a><span class="fu">### Diagnostic 1: Convergence Checks</span></span>
<span id="cb105-1449"><a href="#cb105-1449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1450"><a href="#cb105-1450" aria-hidden="true" tabindex="-1"></a>The <span class="in">`mice`</span> algorithm uses **iterative chained equations**: it cycles through variables, updating imputations based on the current values of other variables. Convergence occurs when these iterations stabilise (no systematic trends).</span>
<span id="cb105-1451"><a href="#cb105-1451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1452"><a href="#cb105-1452" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Trace Plots</span></span>
<span id="cb105-1453"><a href="#cb105-1453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1454"><a href="#cb105-1454" aria-hidden="true" tabindex="-1"></a>Trace plots show the mean and SD of imputed values across iterations for each variable. **Good convergence** looks like:</span>
<span id="cb105-1455"><a href="#cb105-1455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1456"><a href="#cb105-1456" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Lines are "noisy" (random fluctuation)</span>
<span id="cb105-1457"><a href="#cb105-1457" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>No systematic trends (upward or downward drift)</span>
<span id="cb105-1458"><a href="#cb105-1458" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Multiple chains (from different imputations) intermingle</span>
<span id="cb105-1459"><a href="#cb105-1459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1462"><a href="#cb105-1462" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1463"><a href="#cb105-1463" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-mi-diag-1</span></span>
<span id="cb105-1464"><a href="#cb105-1464" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mice)</span>
<span id="cb105-1465"><a href="#cb105-1465" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb105-1466"><a href="#cb105-1466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1467"><a href="#cb105-1467" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate data with missing values</span></span>
<span id="cb105-1468"><a href="#cb105-1468" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb105-1469"><a href="#cb105-1469" aria-hidden="true" tabindex="-1"></a>mi_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb105-1470"><a href="#cb105-1470" aria-hidden="true" tabindex="-1"></a>  <span class="at">age =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">32</span>, <span class="cn">NA</span>, <span class="dv">45</span>, <span class="dv">29</span>, <span class="cn">NA</span>, <span class="dv">38</span>, <span class="dv">41</span>, <span class="dv">27</span>, <span class="dv">35</span>, <span class="cn">NA</span>, <span class="dv">42</span>, <span class="dv">30</span>, <span class="dv">28</span>, <span class="dv">39</span>),</span>
<span id="cb105-1471"><a href="#cb105-1471" aria-hidden="true" tabindex="-1"></a>  <span class="at">satisfaction =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="cn">NA</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="cn">NA</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="cn">NA</span>, <span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">3</span>),</span>
<span id="cb105-1472"><a href="#cb105-1472" aria-hidden="true" tabindex="-1"></a>  <span class="at">income =</span> <span class="fu">c</span>(<span class="dv">35</span>, <span class="dv">50</span>, <span class="dv">42</span>, <span class="dv">60</span>, <span class="cn">NA</span>, <span class="dv">55</span>, <span class="dv">48</span>, <span class="cn">NA</span>, <span class="dv">40</span>, <span class="dv">52</span>, <span class="dv">45</span>, <span class="dv">58</span>, <span class="cn">NA</span>, <span class="dv">38</span>, <span class="dv">49</span>)</span>
<span id="cb105-1473"><a href="#cb105-1473" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb105-1474"><a href="#cb105-1474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1475"><a href="#cb105-1475" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiple imputation with more iterations to demonstrate convergence</span></span>
<span id="cb105-1476"><a href="#cb105-1476" aria-hidden="true" tabindex="-1"></a>imp <span class="ot">&lt;-</span> <span class="fu">mice</span>(mi_data, <span class="at">m =</span> <span class="dv">5</span>, <span class="at">maxit =</span> <span class="dv">20</span>, <span class="at">seed =</span> <span class="dv">2025</span>, <span class="at">print =</span> <span class="cn">FALSE</span>)</span>
<span id="cb105-1477"><a href="#cb105-1477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1478"><a href="#cb105-1478" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot trace lines for all variables</span></span>
<span id="cb105-1479"><a href="#cb105-1479" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(imp, <span class="fu">c</span>(<span class="st">"age"</span>, <span class="st">"satisfaction"</span>, <span class="st">"income"</span>))</span>
<span id="cb105-1480"><a href="#cb105-1480" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1481"><a href="#cb105-1481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1482"><a href="#cb105-1482" aria-hidden="true" tabindex="-1"></a>**Interpretation**:</span>
<span id="cb105-1483"><a href="#cb105-1483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1484"><a href="#cb105-1484" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Ideal**: Lines fluctuate randomly around a stable mean (like a "fuzzy caterpillar")</span>
<span id="cb105-1485"><a href="#cb105-1485" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Problem**: Lines show trends (increasing or decreasing over iterations) → **increase `maxit`**</span>
<span id="cb105-1486"><a href="#cb105-1486" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Problem**: Lines are smooth or separated by chain → **check imputation model specification**</span>
<span id="cb105-1487"><a href="#cb105-1487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1488"><a href="#cb105-1488" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Checking Specific Variables</span></span>
<span id="cb105-1489"><a href="#cb105-1489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1490"><a href="#cb105-1490" aria-hidden="true" tabindex="-1"></a>If you have many variables, focus on those with the most missingness:</span>
<span id="cb105-1491"><a href="#cb105-1491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1494"><a href="#cb105-1494" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1495"><a href="#cb105-1495" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-mi-diag-2</span></span>
<span id="cb105-1496"><a href="#cb105-1496" aria-hidden="true" tabindex="-1"></a><span class="co"># Focus on specific variables with high missingness</span></span>
<span id="cb105-1497"><a href="#cb105-1497" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(imp, <span class="st">"age"</span>)</span>
<span id="cb105-1498"><a href="#cb105-1498" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1499"><a href="#cb105-1499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1500"><a href="#cb105-1500" aria-hidden="true" tabindex="-1"></a>**When to increase iterations**:</span>
<span id="cb105-1501"><a href="#cb105-1501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1502"><a href="#cb105-1502" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If you see trends in the first 10–20 iterations, try <span class="in">`maxit = 50`</span> or <span class="in">`maxit = 100`</span></span>
<span id="cb105-1503"><a href="#cb105-1503" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Modern guidance: <span class="in">`maxit = 20–50`</span> is usually sufficient for MCAR/MAR data</span>
<span id="cb105-1504"><a href="#cb105-1504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1505"><a href="#cb105-1505" aria-hidden="true" tabindex="-1"></a><span class="fu">### Diagnostic 2: Imputed vs. Observed Distributions</span></span>
<span id="cb105-1506"><a href="#cb105-1506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1507"><a href="#cb105-1507" aria-hidden="true" tabindex="-1"></a>Imputed values should **resemble** the observed data distribution (but not be identical). Large discrepancies suggest model misspecification.</span>
<span id="cb105-1508"><a href="#cb105-1508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1509"><a href="#cb105-1509" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Density Plots</span></span>
<span id="cb105-1510"><a href="#cb105-1510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1513"><a href="#cb105-1513" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1514"><a href="#cb105-1514" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-mi-diag-3</span></span>
<span id="cb105-1515"><a href="#cb105-1515" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare density plots: blue = observed, red = imputed</span></span>
<span id="cb105-1516"><a href="#cb105-1516" aria-hidden="true" tabindex="-1"></a><span class="fu">densityplot</span>(imp)</span>
<span id="cb105-1517"><a href="#cb105-1517" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1518"><a href="#cb105-1518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1519"><a href="#cb105-1519" aria-hidden="true" tabindex="-1"></a>**Interpretation**:</span>
<span id="cb105-1520"><a href="#cb105-1520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1521"><a href="#cb105-1521" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Good**: Imputed (red) and observed (blue) distributions overlap substantially</span>
<span id="cb105-1522"><a href="#cb105-1522" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Red flag**: Imputed values are all at one value (e.g., the mean) → model too restrictive (try <span class="in">`method = "pmm"`</span> for predictive mean matching)</span>
<span id="cb105-1523"><a href="#cb105-1523" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Red flag**: Imputed values fall far outside observed range → model misspecified (e.g., using linear imputation for bounded variables)</span>
<span id="cb105-1524"><a href="#cb105-1524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1525"><a href="#cb105-1525" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Strip Plots (Univariate)</span></span>
<span id="cb105-1526"><a href="#cb105-1526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1527"><a href="#cb105-1527" aria-hidden="true" tabindex="-1"></a>Strip plots show individual imputed values (red) alongside observed values (blue):</span>
<span id="cb105-1528"><a href="#cb105-1528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1531"><a href="#cb105-1531" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1532"><a href="#cb105-1532" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-mi-diag-4</span></span>
<span id="cb105-1533"><a href="#cb105-1533" aria-hidden="true" tabindex="-1"></a><span class="co"># Strip plots for each variable</span></span>
<span id="cb105-1534"><a href="#cb105-1534" aria-hidden="true" tabindex="-1"></a><span class="fu">stripplot</span>(imp, age <span class="sc">~</span> .imp, <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">cex =</span> <span class="fl">1.5</span>)</span>
<span id="cb105-1535"><a href="#cb105-1535" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1536"><a href="#cb105-1536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1537"><a href="#cb105-1537" aria-hidden="true" tabindex="-1"></a>**Interpretation**:</span>
<span id="cb105-1538"><a href="#cb105-1538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1539"><a href="#cb105-1539" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Imputed values (red dots) should "fill in" gaps in the observed data (blue dots)</span>
<span id="cb105-1540"><a href="#cb105-1540" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Look for outliers: Are any imputed values far outside the observed range?</span>
<span id="cb105-1541"><a href="#cb105-1541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1542"><a href="#cb105-1542" aria-hidden="true" tabindex="-1"></a><span class="fu">### Diagnostic 3: Sensitivity to m (Number of Imputations)</span></span>
<span id="cb105-1543"><a href="#cb105-1543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1544"><a href="#cb105-1544" aria-hidden="true" tabindex="-1"></a>The number of imputations (m) affects the precision of pooled estimates. With more imputations, pooled estimates become more stable and standard errors more accurate.</span>
<span id="cb105-1545"><a href="#cb105-1545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1546"><a href="#cb105-1546" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Rule of Thumb for m</span></span>
<span id="cb105-1547"><a href="#cb105-1547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1548"><a href="#cb105-1548" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Fraction of missing information (FMI)** determines required m:</span>
<span id="cb105-1549"><a href="#cb105-1549" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>FMI &lt; 10%: m = 5–10 sufficient</span>
<span id="cb105-1550"><a href="#cb105-1550" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>FMI = 10–30%: m = 20 recommended</span>
<span id="cb105-1551"><a href="#cb105-1551" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>FMI &gt; 30%: m = 50–100 may be needed</span>
<span id="cb105-1552"><a href="#cb105-1552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1553"><a href="#cb105-1553" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**White, Royston, and Wood (2011)** suggest: $m \geq 100 \times \text{FMI}$</span>
<span id="cb105-1554"><a href="#cb105-1554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1555"><a href="#cb105-1555" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Testing Sensitivity</span></span>
<span id="cb105-1556"><a href="#cb105-1556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1559"><a href="#cb105-1559" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1560"><a href="#cb105-1560" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-mi-diag-5</span></span>
<span id="cb105-1561"><a href="#cb105-1561" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate larger dataset for demonstration</span></span>
<span id="cb105-1562"><a href="#cb105-1562" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb105-1563"><a href="#cb105-1563" aria-hidden="true" tabindex="-1"></a>mi_data_large <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb105-1564"><a href="#cb105-1564" aria-hidden="true" tabindex="-1"></a>  <span class="at">age =</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">25</span><span class="sc">:</span><span class="dv">50</span>, <span class="cn">NA</span>), <span class="dv">50</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="fl">0.03</span>, <span class="dv">26</span>), <span class="fl">0.22</span>)),</span>
<span id="cb105-1565"><a href="#cb105-1565" aria-hidden="true" tabindex="-1"></a>  <span class="at">income =</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">30</span><span class="sc">:</span><span class="dv">70</span>, <span class="cn">NA</span>), <span class="dv">50</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="fl">0.024</span>, <span class="dv">41</span>), <span class="fl">0.02</span>)),</span>
<span id="cb105-1566"><a href="#cb105-1566" aria-hidden="true" tabindex="-1"></a>  <span class="at">satisfaction =</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="cn">NA</span>), <span class="dv">50</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="fl">0.18</span>, <span class="dv">5</span>), <span class="fl">0.1</span>))</span>
<span id="cb105-1567"><a href="#cb105-1567" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb105-1568"><a href="#cb105-1568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1569"><a href="#cb105-1569" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute with varying m</span></span>
<span id="cb105-1570"><a href="#cb105-1570" aria-hidden="true" tabindex="-1"></a>imp_m5 <span class="ot">&lt;-</span> <span class="fu">mice</span>(mi_data_large, <span class="at">m =</span> <span class="dv">5</span>, <span class="at">maxit =</span> <span class="dv">20</span>, <span class="at">seed =</span> <span class="dv">2025</span>, <span class="at">print =</span> <span class="cn">FALSE</span>)</span>
<span id="cb105-1571"><a href="#cb105-1571" aria-hidden="true" tabindex="-1"></a>imp_m20 <span class="ot">&lt;-</span> <span class="fu">mice</span>(mi_data_large, <span class="at">m =</span> <span class="dv">20</span>, <span class="at">maxit =</span> <span class="dv">20</span>, <span class="at">seed =</span> <span class="dv">2025</span>, <span class="at">print =</span> <span class="cn">FALSE</span>)</span>
<span id="cb105-1572"><a href="#cb105-1572" aria-hidden="true" tabindex="-1"></a>imp_m50 <span class="ot">&lt;-</span> <span class="fu">mice</span>(mi_data_large, <span class="at">m =</span> <span class="dv">50</span>, <span class="at">maxit =</span> <span class="dv">20</span>, <span class="at">seed =</span> <span class="dv">2025</span>, <span class="at">print =</span> <span class="cn">FALSE</span>)</span>
<span id="cb105-1573"><a href="#cb105-1573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1574"><a href="#cb105-1574" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model and pool results</span></span>
<span id="cb105-1575"><a href="#cb105-1575" aria-hidden="true" tabindex="-1"></a>fit_m5 <span class="ot">&lt;-</span> <span class="fu">with</span>(imp_m5, <span class="fu">lm</span>(satisfaction <span class="sc">~</span> age <span class="sc">+</span> income))</span>
<span id="cb105-1576"><a href="#cb105-1576" aria-hidden="true" tabindex="-1"></a>fit_m20 <span class="ot">&lt;-</span> <span class="fu">with</span>(imp_m20, <span class="fu">lm</span>(satisfaction <span class="sc">~</span> age <span class="sc">+</span> income))</span>
<span id="cb105-1577"><a href="#cb105-1577" aria-hidden="true" tabindex="-1"></a>fit_m50 <span class="ot">&lt;-</span> <span class="fu">with</span>(imp_m50, <span class="fu">lm</span>(satisfaction <span class="sc">~</span> age <span class="sc">+</span> income))</span>
<span id="cb105-1578"><a href="#cb105-1578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1579"><a href="#cb105-1579" aria-hidden="true" tabindex="-1"></a>pooled_m5 <span class="ot">&lt;-</span> <span class="fu">pool</span>(fit_m5)</span>
<span id="cb105-1580"><a href="#cb105-1580" aria-hidden="true" tabindex="-1"></a>pooled_m20 <span class="ot">&lt;-</span> <span class="fu">pool</span>(fit_m20)</span>
<span id="cb105-1581"><a href="#cb105-1581" aria-hidden="true" tabindex="-1"></a>pooled_m50 <span class="ot">&lt;-</span> <span class="fu">pool</span>(fit_m50)</span>
<span id="cb105-1582"><a href="#cb105-1582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1583"><a href="#cb105-1583" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare coefficient estimates and SEs</span></span>
<span id="cb105-1584"><a href="#cb105-1584" aria-hidden="true" tabindex="-1"></a>compare_m <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb105-1585"><a href="#cb105-1585" aria-hidden="true" tabindex="-1"></a>  <span class="at">m =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">20</span>, <span class="dv">50</span>),</span>
<span id="cb105-1586"><a href="#cb105-1586" aria-hidden="true" tabindex="-1"></a>  <span class="at">age_coef =</span> <span class="fu">c</span>(</span>
<span id="cb105-1587"><a href="#cb105-1587" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>(pooled_m5)<span class="sc">$</span>estimate[<span class="dv">2</span>],</span>
<span id="cb105-1588"><a href="#cb105-1588" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>(pooled_m20)<span class="sc">$</span>estimate[<span class="dv">2</span>],</span>
<span id="cb105-1589"><a href="#cb105-1589" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>(pooled_m50)<span class="sc">$</span>estimate[<span class="dv">2</span>]</span>
<span id="cb105-1590"><a href="#cb105-1590" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb105-1591"><a href="#cb105-1591" aria-hidden="true" tabindex="-1"></a>  <span class="at">age_se =</span> <span class="fu">c</span>(</span>
<span id="cb105-1592"><a href="#cb105-1592" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>(pooled_m5)<span class="sc">$</span>std.error[<span class="dv">2</span>],</span>
<span id="cb105-1593"><a href="#cb105-1593" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>(pooled_m20)<span class="sc">$</span>std.error[<span class="dv">2</span>],</span>
<span id="cb105-1594"><a href="#cb105-1594" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>(pooled_m50)<span class="sc">$</span>std.error[<span class="dv">2</span>]</span>
<span id="cb105-1595"><a href="#cb105-1595" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb105-1596"><a href="#cb105-1596" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb105-1597"><a href="#cb105-1597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1598"><a href="#cb105-1598" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(compare_m)</span>
<span id="cb105-1599"><a href="#cb105-1599" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1600"><a href="#cb105-1600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1601"><a href="#cb105-1601" aria-hidden="true" tabindex="-1"></a>**Interpretation**:</span>
<span id="cb105-1602"><a href="#cb105-1602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1603"><a href="#cb105-1603" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Coefficients** should be similar across m (small differences are expected due to Monte Carlo error)</span>
<span id="cb105-1604"><a href="#cb105-1604" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Standard errors** should stabilize as m increases</span>
<span id="cb105-1605"><a href="#cb105-1605" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If estimates change substantially (e.g., &gt; 10% difference in coefficients), use larger m</span>
<span id="cb105-1606"><a href="#cb105-1606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1607"><a href="#cb105-1607" aria-hidden="true" tabindex="-1"></a><span class="fu">#### When to Use Larger m</span></span>
<span id="cb105-1608"><a href="#cb105-1608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1609"><a href="#cb105-1609" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**High missingness** (&gt; 20%): Use m ≥ 20</span>
<span id="cb105-1610"><a href="#cb105-1610" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Small samples** (n &lt; 50): Larger m reduces Monte Carlo error</span>
<span id="cb105-1611"><a href="#cb105-1611" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Sensitive analyses** (e.g., clinical trials): Use m ≥ 50 for conservative inference</span>
<span id="cb105-1612"><a href="#cb105-1612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1613"><a href="#cb105-1613" aria-hidden="true" tabindex="-1"></a><span class="fu">### Diagnostic 4: Checking Imputation Model Assumptions</span></span>
<span id="cb105-1614"><a href="#cb105-1614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1615"><a href="#cb105-1615" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Inspect Imputation Methods</span></span>
<span id="cb105-1616"><a href="#cb105-1616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1619"><a href="#cb105-1619" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1620"><a href="#cb105-1620" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-mi-diag-6</span></span>
<span id="cb105-1621"><a href="#cb105-1621" aria-hidden="true" tabindex="-1"></a><span class="co"># Check which imputation methods were used</span></span>
<span id="cb105-1622"><a href="#cb105-1622" aria-hidden="true" tabindex="-1"></a>imp<span class="sc">$</span>method</span>
<span id="cb105-1623"><a href="#cb105-1623" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1624"><a href="#cb105-1624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1625"><a href="#cb105-1625" aria-hidden="true" tabindex="-1"></a>**Common methods**:</span>
<span id="cb105-1626"><a href="#cb105-1626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1627"><a href="#cb105-1627" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`pmm`</span>: Predictive mean matching (robust, preserves distribution)</span>
<span id="cb105-1628"><a href="#cb105-1628" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`norm`</span>: Bayesian linear regression (assumes normality)</span>
<span id="cb105-1629"><a href="#cb105-1629" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`logreg`</span>: Logistic regression (for binary variables)</span>
<span id="cb105-1630"><a href="#cb105-1630" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`polyreg`</span>: Multinomial logistic regression (for categorical variables)</span>
<span id="cb105-1631"><a href="#cb105-1631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1632"><a href="#cb105-1632" aria-hidden="true" tabindex="-1"></a>**Best practice**: Use <span class="in">`pmm`</span> for continuous variables unless you have strong reasons to assume normality.</span>
<span id="cb105-1633"><a href="#cb105-1633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1634"><a href="#cb105-1634" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Check Predictor Matrix</span></span>
<span id="cb105-1635"><a href="#cb105-1635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1638"><a href="#cb105-1638" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1639"><a href="#cb105-1639" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-mi-diag-7</span></span>
<span id="cb105-1640"><a href="#cb105-1640" aria-hidden="true" tabindex="-1"></a><span class="co"># See which variables predict each other</span></span>
<span id="cb105-1641"><a href="#cb105-1641" aria-hidden="true" tabindex="-1"></a>imp<span class="sc">$</span>predictorMatrix</span>
<span id="cb105-1642"><a href="#cb105-1642" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1643"><a href="#cb105-1643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1644"><a href="#cb105-1644" aria-hidden="true" tabindex="-1"></a>**Interpretation**:</span>
<span id="cb105-1645"><a href="#cb105-1645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1646"><a href="#cb105-1646" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Rows = variables to impute</span>
<span id="cb105-1647"><a href="#cb105-1647" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Columns = predictor variables</span>
<span id="cb105-1648"><a href="#cb105-1648" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`1`</span> = use as predictor, <span class="in">`0`</span> = do not use</span>
<span id="cb105-1649"><a href="#cb105-1649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1650"><a href="#cb105-1650" aria-hidden="true" tabindex="-1"></a>**Modify if needed**:</span>
<span id="cb105-1651"><a href="#cb105-1651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1654"><a href="#cb105-1654" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1655"><a href="#cb105-1655" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-mi-diag-8</span></span>
<span id="cb105-1656"><a href="#cb105-1656" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb105-1657"><a href="#cb105-1657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1658"><a href="#cb105-1658" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Exclude a variable from predicting another</span></span>
<span id="cb105-1659"><a href="#cb105-1659" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> imp<span class="sc">$</span>predictorMatrix</span>
<span id="cb105-1660"><a href="#cb105-1660" aria-hidden="true" tabindex="-1"></a>pred[<span class="st">"age"</span>, <span class="st">"satisfaction"</span>] <span class="ot">&lt;-</span> <span class="dv">0</span>  <span class="co"># Don't use satisfaction to predict age</span></span>
<span id="cb105-1661"><a href="#cb105-1661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1662"><a href="#cb105-1662" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run imputation with modified predictor matrix</span></span>
<span id="cb105-1663"><a href="#cb105-1663" aria-hidden="true" tabindex="-1"></a>imp_modified <span class="ot">&lt;-</span> <span class="fu">mice</span>(mi_data, <span class="at">m =</span> <span class="dv">5</span>, <span class="at">predictorMatrix =</span> pred, <span class="at">print =</span> <span class="cn">FALSE</span>)</span>
<span id="cb105-1664"><a href="#cb105-1664" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1665"><a href="#cb105-1665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1666"><a href="#cb105-1666" aria-hidden="true" tabindex="-1"></a><span class="fu">### Diagnostic 5: Fraction of Missing Information (FMI)</span></span>
<span id="cb105-1667"><a href="#cb105-1667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1668"><a href="#cb105-1668" aria-hidden="true" tabindex="-1"></a>The FMI quantifies how much uncertainty is introduced by imputation. It is automatically reported by <span class="in">`pool()`</span>:</span>
<span id="cb105-1669"><a href="#cb105-1669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1672"><a href="#cb105-1672" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1673"><a href="#cb105-1673" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-mi-diag-9</span></span>
<span id="cb105-1674"><a href="#cb105-1674" aria-hidden="true" tabindex="-1"></a><span class="co"># Pool results and examine FMI</span></span>
<span id="cb105-1675"><a href="#cb105-1675" aria-hidden="true" tabindex="-1"></a>pooled_result <span class="ot">&lt;-</span> <span class="fu">pool</span>(fit_m20)</span>
<span id="cb105-1676"><a href="#cb105-1676" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pooled_result)</span>
<span id="cb105-1677"><a href="#cb105-1677" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1678"><a href="#cb105-1678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1679"><a href="#cb105-1679" aria-hidden="true" tabindex="-1"></a>**Columns to examine**:</span>
<span id="cb105-1680"><a href="#cb105-1680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1681"><a href="#cb105-1681" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**fmi**: Fraction of missing information for each coefficient</span>
<span id="cb105-1682"><a href="#cb105-1682" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**lambda**: Proportion of total variance due to missingness</span>
<span id="cb105-1683"><a href="#cb105-1683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1684"><a href="#cb105-1684" aria-hidden="true" tabindex="-1"></a>**Interpretation**:</span>
<span id="cb105-1685"><a href="#cb105-1685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1686"><a href="#cb105-1686" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**FMI &lt; 0.10**: Low missing information; m = 5–10 sufficient</span>
<span id="cb105-1687"><a href="#cb105-1687" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**FMI = 0.10–0.30**: Moderate; use m = 20–50</span>
<span id="cb105-1688"><a href="#cb105-1688" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**FMI &gt; 0.30**: High; consider whether MI is appropriate (may need m = 50–100)</span>
<span id="cb105-1689"><a href="#cb105-1689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1690"><a href="#cb105-1690" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example: Full Diagnostic Workflow</span></span>
<span id="cb105-1691"><a href="#cb105-1691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1694"><a href="#cb105-1694" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1695"><a href="#cb105-1695" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-mi-diag-10</span></span>
<span id="cb105-1696"><a href="#cb105-1696" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Describe missingness</span></span>
<span id="cb105-1697"><a href="#cb105-1697" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(naniar)</span>
<span id="cb105-1698"><a href="#cb105-1698" aria-hidden="true" tabindex="-1"></a><span class="fu">miss_var_summary</span>(mi_data_large)</span>
<span id="cb105-1699"><a href="#cb105-1699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1700"><a href="#cb105-1700" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Perform MI with adequate m and maxit</span></span>
<span id="cb105-1701"><a href="#cb105-1701" aria-hidden="true" tabindex="-1"></a>imp_final <span class="ot">&lt;-</span> <span class="fu">mice</span>(mi_data_large, <span class="at">m =</span> <span class="dv">20</span>, <span class="at">maxit =</span> <span class="dv">30</span>, <span class="at">seed =</span> <span class="dv">2025</span>, <span class="at">print =</span> <span class="cn">FALSE</span>)</span>
<span id="cb105-1702"><a href="#cb105-1702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1703"><a href="#cb105-1703" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Check convergence</span></span>
<span id="cb105-1704"><a href="#cb105-1704" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(imp_final, <span class="fu">c</span>(<span class="st">"age"</span>, <span class="st">"income"</span>, <span class="st">"satisfaction"</span>))</span>
<span id="cb105-1705"><a href="#cb105-1705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1706"><a href="#cb105-1706" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Compare distributions</span></span>
<span id="cb105-1707"><a href="#cb105-1707" aria-hidden="true" tabindex="-1"></a><span class="fu">densityplot</span>(imp_final)</span>
<span id="cb105-1708"><a href="#cb105-1708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1709"><a href="#cb105-1709" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5: Fit model and pool</span></span>
<span id="cb105-1710"><a href="#cb105-1710" aria-hidden="true" tabindex="-1"></a>fit_final <span class="ot">&lt;-</span> <span class="fu">with</span>(imp_final, <span class="fu">lm</span>(satisfaction <span class="sc">~</span> age <span class="sc">+</span> income))</span>
<span id="cb105-1711"><a href="#cb105-1711" aria-hidden="true" tabindex="-1"></a>pooled_final <span class="ot">&lt;-</span> <span class="fu">pool</span>(fit_final)</span>
<span id="cb105-1712"><a href="#cb105-1712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1713"><a href="#cb105-1713" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 6: Check FMI</span></span>
<span id="cb105-1714"><a href="#cb105-1714" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pooled_final)</span>
<span id="cb105-1715"><a href="#cb105-1715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1716"><a href="#cb105-1716" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 7: Report results</span></span>
<span id="cb105-1717"><a href="#cb105-1717" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Pooled regression results (m = 20 imputations):</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb105-1718"><a href="#cb105-1718" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pooled_final)</span>
<span id="cb105-1719"><a href="#cb105-1719" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1720"><a href="#cb105-1720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1721"><a href="#cb105-1721" aria-hidden="true" tabindex="-1"></a><span class="fu">### Red Flags and Troubleshooting</span></span>
<span id="cb105-1722"><a href="#cb105-1722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1723"><a href="#cb105-1723" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Problem** | **Symptom** | **Solution** <span class="pp">|</span></span>
<span id="cb105-1724"><a href="#cb105-1724" aria-hidden="true" tabindex="-1"></a><span class="pp">|-------------|-------------|--------------|</span></span>
<span id="cb105-1725"><a href="#cb105-1725" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Non-convergence** <span class="pp">|</span> Trace plots show trends <span class="pp">|</span> Increase <span class="in">`maxit`</span> (try 50–100) <span class="pp">|</span></span>
<span id="cb105-1726"><a href="#cb105-1726" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Imputed values at one value** <span class="pp">|</span> Density plot shows spike <span class="pp">|</span> Use <span class="in">`method = "pmm"`</span> instead of <span class="in">`norm`</span> <span class="pp">|</span></span>
<span id="cb105-1727"><a href="#cb105-1727" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Imputed values out of range** <span class="pp">|</span> Strip plot shows outliers <span class="pp">|</span> Check variable type (e.g., use <span class="in">`logreg`</span> for binary) <span class="pp">|</span></span>
<span id="cb105-1728"><a href="#cb105-1728" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Unstable estimates across m** <span class="pp">|</span> Coefficients vary &gt; 10% <span class="pp">|</span> Increase m (try 50–100) <span class="pp">|</span></span>
<span id="cb105-1729"><a href="#cb105-1729" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **High FMI (&gt; 0.50)** <span class="pp">|</span> Large uncertainty <span class="pp">|</span> Consider whether MI is appropriate; may need auxiliary variables or accept wider CIs <span class="pp">|</span></span>
<span id="cb105-1730"><a href="#cb105-1730" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Separation warnings (logistic regression)** <span class="pp">|</span> Model fails to converge <span class="pp">|</span> Use penalized imputation methods or increase sample size <span class="pp">|</span></span>
<span id="cb105-1731"><a href="#cb105-1731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1732"><a href="#cb105-1732" aria-hidden="true" tabindex="-1"></a><span class="fu">### Reporting MI Diagnostics</span></span>
<span id="cb105-1733"><a href="#cb105-1733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1734"><a href="#cb105-1734" aria-hidden="true" tabindex="-1"></a>When reporting MI results, include:</span>
<span id="cb105-1735"><a href="#cb105-1735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1736"><a href="#cb105-1736" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Missingness pattern**: "Three variables had missing data (age: 20%, income: 18%, satisfaction: 10%)"</span>
<span id="cb105-1737"><a href="#cb105-1737" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Imputation model**: "We used predictive mean matching with m = 20 imputations and maxit = 30"</span>
<span id="cb105-1738"><a href="#cb105-1738" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Convergence**: "Trace plots showed convergence after 20 iterations (see Supplementary Figure S1)"</span>
<span id="cb105-1739"><a href="#cb105-1739" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Plausibility**: "Imputed values were visually consistent with observed distributions (density plots in Supplementary Figure S2)"</span>
<span id="cb105-1740"><a href="#cb105-1740" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Sensitivity**: "Results were stable across m = 5, 20, and 50 imputations (coefficient differences &lt; 5%)"</span>
<span id="cb105-1741"><a href="#cb105-1741" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**FMI**: "Fraction of missing information ranged from 0.12 to 0.25, indicating moderate impact of missingness"</span>
<span id="cb105-1742"><a href="#cb105-1742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1743"><a href="#cb105-1743" aria-hidden="true" tabindex="-1"></a><span class="fu">### Key Takeaways</span></span>
<span id="cb105-1744"><a href="#cb105-1744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1745"><a href="#cb105-1745" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Convergence checks** (trace plots) ensure the imputation algorithm has stabilised; increase <span class="in">`maxit`</span> if trends are visible</span>
<span id="cb105-1746"><a href="#cb105-1746" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Density and strip plots** compare imputed vs. observed distributions; imputed values should resemble observed data</span>
<span id="cb105-1747"><a href="#cb105-1747" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Number of imputations (m)** should match the fraction of missing information: m ≥ 20 for FMI = 10–30%</span>
<span id="cb105-1748"><a href="#cb105-1748" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Sensitivity analyses** test whether results are stable across different values of m</span>
<span id="cb105-1749"><a href="#cb105-1749" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Fraction of Missing Information (FMI)** quantifies uncertainty from imputation; FMI &gt; 0.30 suggests high impact</span>
<span id="cb105-1750"><a href="#cb105-1750" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Red flags**: Imputed values at one value, outliers, non-convergence, unstable estimates → revise imputation model</span>
<span id="cb105-1751"><a href="#cb105-1751" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Transparency**: Report convergence, plausibility checks, and sensitivity analyses in supplementary materials</span>
<span id="cb105-1752"><a href="#cb105-1752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1753"><a href="#cb105-1753" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1754"><a href="#cb105-1754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1755"><a href="#cb105-1755" aria-hidden="true" tabindex="-1"></a><span class="fu">### Self-Assessment Quiz</span></span>
<span id="cb105-1756"><a href="#cb105-1756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1757"><a href="#cb105-1757" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb105-1758"><a href="#cb105-1758" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Chapter 12 Questions</span></span>
<span id="cb105-1759"><a href="#cb105-1759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1760"><a href="#cb105-1760" aria-hidden="true" tabindex="-1"></a>**Q1.** What is the difference between MCAR (Missing Completely At Random) and MAR (Missing At Random)?</span>
<span id="cb105-1761"><a href="#cb105-1761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1762"><a href="#cb105-1762" aria-hidden="true" tabindex="-1"></a>A) MCAR means no data are missing; MAR means some data are missing  </span>
<span id="cb105-1763"><a href="#cb105-1763" aria-hidden="true" tabindex="-1"></a>B) MCAR means missingness is unrelated to any variables; MAR means missingness is related to observed variables but not the missing values themselves  </span>
<span id="cb105-1764"><a href="#cb105-1764" aria-hidden="true" tabindex="-1"></a>C) MCAR and MAR are identical terms  </span>
<span id="cb105-1765"><a href="#cb105-1765" aria-hidden="true" tabindex="-1"></a>D) MCAR applies to small samples; MAR applies to large samples</span>
<span id="cb105-1766"><a href="#cb105-1766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1767"><a href="#cb105-1767" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1768"><a href="#cb105-1768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1769"><a href="#cb105-1769" aria-hidden="true" tabindex="-1"></a>**Q2.** Why is mean imputation (replacing missing values with the variable mean) generally not recommended?</span>
<span id="cb105-1770"><a href="#cb105-1770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1771"><a href="#cb105-1771" aria-hidden="true" tabindex="-1"></a>A) It requires specialized software  </span>
<span id="cb105-1772"><a href="#cb105-1772" aria-hidden="true" tabindex="-1"></a>B) It artificially reduces variance and distorts correlations  </span>
<span id="cb105-1773"><a href="#cb105-1773" aria-hidden="true" tabindex="-1"></a>C) It only works with categorical variables  </span>
<span id="cb105-1774"><a href="#cb105-1774" aria-hidden="true" tabindex="-1"></a>D) It is too computationally expensive</span>
<span id="cb105-1775"><a href="#cb105-1775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1776"><a href="#cb105-1776" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1777"><a href="#cb105-1777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1778"><a href="#cb105-1778" aria-hidden="true" tabindex="-1"></a>**Q3.** If you have 20% missingness on variable X and 20% missingness on variable Y (independently), approximately what percentage of cases will be lost with listwise deletion?</span>
<span id="cb105-1779"><a href="#cb105-1779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1780"><a href="#cb105-1780" aria-hidden="true" tabindex="-1"></a>A) 20%  </span>
<span id="cb105-1781"><a href="#cb105-1781" aria-hidden="true" tabindex="-1"></a>B) 36%  </span>
<span id="cb105-1782"><a href="#cb105-1782" aria-hidden="true" tabindex="-1"></a>C) 40%  </span>
<span id="cb105-1783"><a href="#cb105-1783" aria-hidden="true" tabindex="-1"></a>D) 64%</span>
<span id="cb105-1784"><a href="#cb105-1784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1785"><a href="#cb105-1785" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1786"><a href="#cb105-1786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1787"><a href="#cb105-1787" aria-hidden="true" tabindex="-1"></a>**Q4.** What does MNAR (Missing Not At Random) mean?</span>
<span id="cb105-1788"><a href="#cb105-1788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1789"><a href="#cb105-1789" aria-hidden="true" tabindex="-1"></a>A) Missingness is unrelated to any variables  </span>
<span id="cb105-1790"><a href="#cb105-1790" aria-hidden="true" tabindex="-1"></a>B) Missingness is related to observed variables only  </span>
<span id="cb105-1791"><a href="#cb105-1791" aria-hidden="true" tabindex="-1"></a>C) Missingness is related to the unobserved (missing) values themselves  </span>
<span id="cb105-1792"><a href="#cb105-1792" aria-hidden="true" tabindex="-1"></a>D) Missing data occur randomly due to software errors</span>
<span id="cb105-1793"><a href="#cb105-1793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1794"><a href="#cb105-1794" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1795"><a href="#cb105-1795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1796"><a href="#cb105-1796" aria-hidden="true" tabindex="-1"></a>**Q5.** What is the primary limitation of using multiple imputation with very small samples (n &lt; 30)?</span>
<span id="cb105-1797"><a href="#cb105-1797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1798"><a href="#cb105-1798" aria-hidden="true" tabindex="-1"></a>A) Multiple imputation cannot handle small samples  </span>
<span id="cb105-1799"><a href="#cb105-1799" aria-hidden="true" tabindex="-1"></a>B) The imputation model is estimated from limited data and may be unstable or yield implausible values  </span>
<span id="cb105-1800"><a href="#cb105-1800" aria-hidden="true" tabindex="-1"></a>C) Multiple imputation requires at least 1,000 observations  </span>
<span id="cb105-1801"><a href="#cb105-1801" aria-hidden="true" tabindex="-1"></a>D) Multiple imputation only works with MNAR data</span>
<span id="cb105-1802"><a href="#cb105-1802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1803"><a href="#cb105-1803" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1804"><a href="#cb105-1804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1805"><a href="#cb105-1805" aria-hidden="true" tabindex="-1"></a>**Q6.** In multiple imputation diagnostics, what do trace plots check?</span>
<span id="cb105-1806"><a href="#cb105-1806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1807"><a href="#cb105-1807" aria-hidden="true" tabindex="-1"></a>A) The distribution of imputed values  </span>
<span id="cb105-1808"><a href="#cb105-1808" aria-hidden="true" tabindex="-1"></a>B) Whether the imputation algorithm has converged (stabilized) across iterations  </span>
<span id="cb105-1809"><a href="#cb105-1809" aria-hidden="true" tabindex="-1"></a>C) The correlation between variables  </span>
<span id="cb105-1810"><a href="#cb105-1810" aria-hidden="true" tabindex="-1"></a>D) The sample size required for analysis</span>
<span id="cb105-1811"><a href="#cb105-1811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1812"><a href="#cb105-1812" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1813"><a href="#cb105-1813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1814"><a href="#cb105-1814" aria-hidden="true" tabindex="-1"></a>**Q7.** When comparing imputed (red) vs. observed (blue) distributions in density plots, what is a "red flag"?</span>
<span id="cb105-1815"><a href="#cb105-1815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1816"><a href="#cb105-1816" aria-hidden="true" tabindex="-1"></a>A) The distributions overlap substantially  </span>
<span id="cb105-1817"><a href="#cb105-1817" aria-hidden="true" tabindex="-1"></a>B) Imputed values fall far outside the observed range or all cluster at one value  </span>
<span id="cb105-1818"><a href="#cb105-1818" aria-hidden="true" tabindex="-1"></a>C) Both distributions are normally distributed  </span>
<span id="cb105-1819"><a href="#cb105-1819" aria-hidden="true" tabindex="-1"></a>D) The imputed values have slightly different means</span>
<span id="cb105-1820"><a href="#cb105-1820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1821"><a href="#cb105-1821" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1822"><a href="#cb105-1822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1823"><a href="#cb105-1823" aria-hidden="true" tabindex="-1"></a>**Q8.** What is the rule of thumb for choosing the number of imputations (m) based on the fraction of missing information (FMI)?</span>
<span id="cb105-1824"><a href="#cb105-1824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1825"><a href="#cb105-1825" aria-hidden="true" tabindex="-1"></a>A) Always use m = 5 regardless of FMI  </span>
<span id="cb105-1826"><a href="#cb105-1826" aria-hidden="true" tabindex="-1"></a>B) Use m ≥ 100 × FMI (e.g., FMI = 0.20 requires m ≥ 20)  </span>
<span id="cb105-1827"><a href="#cb105-1827" aria-hidden="true" tabindex="-1"></a>C) Use m = 1000 for all analyses  </span>
<span id="cb105-1828"><a href="#cb105-1828" aria-hidden="true" tabindex="-1"></a>D) m should equal the sample size</span>
<span id="cb105-1829"><a href="#cb105-1829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1830"><a href="#cb105-1830" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1831"><a href="#cb105-1831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1832"><a href="#cb105-1832" aria-hidden="true" tabindex="-1"></a>**Q9.** What does Little's MCAR test evaluate?</span>
<span id="cb105-1833"><a href="#cb105-1833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1834"><a href="#cb105-1834" aria-hidden="true" tabindex="-1"></a>A) Whether the sample size is adequate  </span>
<span id="cb105-1835"><a href="#cb105-1835" aria-hidden="true" tabindex="-1"></a>B) Whether missingness is consistent with the MCAR mechanism by comparing observed means across missing-data patterns  </span>
<span id="cb105-1836"><a href="#cb105-1836" aria-hidden="true" tabindex="-1"></a>C) Whether multiple imputation has converged  </span>
<span id="cb105-1837"><a href="#cb105-1837" aria-hidden="true" tabindex="-1"></a>D) Whether variables are normally distributed</span>
<span id="cb105-1838"><a href="#cb105-1838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1839"><a href="#cb105-1839" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1840"><a href="#cb105-1840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1841"><a href="#cb105-1841" aria-hidden="true" tabindex="-1"></a>**Q10.** Why is prevention the best approach to missing data?</span>
<span id="cb105-1842"><a href="#cb105-1842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1843"><a href="#cb105-1843" aria-hidden="true" tabindex="-1"></a>A) Prevention is cheaper than imputation software  </span>
<span id="cb105-1844"><a href="#cb105-1844" aria-hidden="true" tabindex="-1"></a>B) Even sophisticated imputation methods have limitations and cannot fully recover information lost to missingness; prevention avoids the problem  </span>
<span id="cb105-1845"><a href="#cb105-1845" aria-hidden="true" tabindex="-1"></a>C) Prevention is only relevant for large samples  </span>
<span id="cb105-1846"><a href="#cb105-1846" aria-hidden="true" tabindex="-1"></a>D) Multiple imputation cannot handle any missing data</span>
<span id="cb105-1847"><a href="#cb105-1847" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1848"><a href="#cb105-1848" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb105-1849"><a href="#cb105-1849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1850"><a href="#cb105-1850" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb105-1851"><a href="#cb105-1851" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Answers and Explanations</span></span>
<span id="cb105-1852"><a href="#cb105-1852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1853"><a href="#cb105-1853" aria-hidden="true" tabindex="-1"></a>**A1. B)** "MCAR (Missing Completely At Random): Missingness is unrelated to any observed or unobserved variables... MAR (Missing At Random): Missingness is related to observed variables but not to the missing values themselves."  </span>
<span id="cb105-1854"><a href="#cb105-1854" aria-hidden="true" tabindex="-1"></a>MCAR is a stricter assumption where missingness is completely random, while MAR allows missingness to depend on observed data.</span>
<span id="cb105-1855"><a href="#cb105-1855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1856"><a href="#cb105-1856" aria-hidden="true" tabindex="-1"></a>**A2. B)** "Mean imputation replaces missing values with the variable mean. This approach artificially reduces variance and distorts correlations."  </span>
<span id="cb105-1857"><a href="#cb105-1857" aria-hidden="true" tabindex="-1"></a>By replacing all missing values with the mean, you reduce the variability in the data and bias correlation estimates downward.</span>
<span id="cb105-1858"><a href="#cb105-1858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1859"><a href="#cb105-1859" aria-hidden="true" tabindex="-1"></a>**A3. B)** "With 20% missing on x and 20% on y (independent), you lose ~36% of cases—Formula: (1 - p_x) × (1 - p_y) = 0.8 × 0.8 = 0.64 → 64% remain, 36% lost"  </span>
<span id="cb105-1860"><a href="#cb105-1860" aria-hidden="true" tabindex="-1"></a>When missingness patterns are independent, the compound effect removes (1 - 0.8 × 0.8) = 36% of cases.</span>
<span id="cb105-1861"><a href="#cb105-1861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1862"><a href="#cb105-1862" aria-hidden="true" tabindex="-1"></a>**A4. C)** "MNAR (Missing Not At Random): Missingness is related to the unobserved values themselves."  </span>
<span id="cb105-1863"><a href="#cb105-1863" aria-hidden="true" tabindex="-1"></a>For example, individuals with high depression scores being more likely to drop out of a study.</span>
<span id="cb105-1864"><a href="#cb105-1864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1865"><a href="#cb105-1865" aria-hidden="true" tabindex="-1"></a>**A5. B)** "With very small samples (n &lt; 30) or many missing values (&gt; 20%), MI can be unstable or yield implausible imputations."  </span>
<span id="cb105-1866"><a href="#cb105-1866" aria-hidden="true" tabindex="-1"></a>The imputation model requires sufficient data to estimate relationships reliably; very small samples provide limited information.</span>
<span id="cb105-1867"><a href="#cb105-1867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1868"><a href="#cb105-1868" aria-hidden="true" tabindex="-1"></a>**A6. B)** "Trace plots show the mean and SD of imputed values across iterations for each variable... Convergence occurs when these iterations stabilise."  </span>
<span id="cb105-1869"><a href="#cb105-1869" aria-hidden="true" tabindex="-1"></a>Good convergence shows random fluctuation without systematic trends (upward or downward drift).</span>
<span id="cb105-1870"><a href="#cb105-1870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1871"><a href="#cb105-1871" aria-hidden="true" tabindex="-1"></a>**A7. B)** "Imputed values fall far outside observed range → model misspecified... Imputed values are all at one value (e.g., the mean) → model too restrictive."  </span>
<span id="cb105-1872"><a href="#cb105-1872" aria-hidden="true" tabindex="-1"></a>Large discrepancies between imputed and observed distributions suggest problems with the imputation model specification.</span>
<span id="cb105-1873"><a href="#cb105-1873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1874"><a href="#cb105-1874" aria-hidden="true" tabindex="-1"></a>**A8. B)** "White, Royston, and Wood (2011) suggest: m ≥ 100 × FMI"  </span>
<span id="cb105-1875"><a href="#cb105-1875" aria-hidden="true" tabindex="-1"></a>For example, if FMI = 0.20 (20% missing information), you should use m ≥ 20 imputations.</span>
<span id="cb105-1876"><a href="#cb105-1876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1877"><a href="#cb105-1877" aria-hidden="true" tabindex="-1"></a>**A9. B)** "Little's MCAR test evaluates whether missingness is consistent with the MCAR mechanism. The test compares observed means across missing-data patterns."  </span>
<span id="cb105-1878"><a href="#cb105-1878" aria-hidden="true" tabindex="-1"></a>A large p-value suggests MCAR is plausible; a small p-value indicates missingness likely depends on observed data.</span>
<span id="cb105-1879"><a href="#cb105-1879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1880"><a href="#cb105-1880" aria-hidden="true" tabindex="-1"></a>**A10. B)** "The best approach to missing data is prevention... Pilot test procedures to identify confusing or burdensome items. Build rapport and trust with participants."  </span>
<span id="cb105-1881"><a href="#cb105-1881" aria-hidden="true" tabindex="-1"></a>No imputation method can fully recover the information lost to missingness, so preventing missing data through good design is always preferable.</span>
<span id="cb105-1882"><a href="#cb105-1882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1883"><a href="#cb105-1883" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb105-1884"><a href="#cb105-1884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1885"><a href="#cb105-1885" aria-hidden="true" tabindex="-1"></a><span class="fu">### Key Takeaways</span></span>
<span id="cb105-1886"><a href="#cb105-1886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1887"><a href="#cb105-1887" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Missing data reduce effective sample size and can bias estimates, particularly with small samples.</span>
<span id="cb105-1888"><a href="#cb105-1888" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Describe missingness patterns (proportion missing, complete vs. incomplete case characteristics) before choosing a method.</span>
<span id="cb105-1889"><a href="#cb105-1889" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Complete-case analysis is simple and valid if missingness is minimal or MCAR, but wastes information and loses power.</span>
<span id="cb105-1890"><a href="#cb105-1890" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Mean imputation and LOCF are not recommended; they distort variance and correlations.</span>
<span id="cb105-1891"><a href="#cb105-1891" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Multiple imputation is the gold standard with adequate samples (n ≥ 30, missingness &lt; 20%) but may be unstable with very small samples.</span>
<span id="cb105-1892"><a href="#cb105-1892" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Sensitivity analyses compare results under different assumptions about the missing data mechanism.</span>
<span id="cb105-1893"><a href="#cb105-1893" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Prevention through careful study design is the best strategy for minimising missing data.</span>
<span id="cb105-1894"><a href="#cb105-1894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1895"><a href="#cb105-1895" aria-hidden="true" tabindex="-1"></a><span class="fu">### Smoke Test</span></span>
<span id="cb105-1896"><a href="#cb105-1896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1899"><a href="#cb105-1899" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb105-1900"><a href="#cb105-1900" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: part-b-chunk-18</span></span>
<span id="cb105-1901"><a href="#cb105-1901" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run missing data summary</span></span>
<span id="cb105-1902"><a href="#cb105-1902" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb105-1903"><a href="#cb105-1903" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">6</span>, <span class="cn">NA</span>, <span class="dv">8</span>, <span class="dv">7</span>, <span class="cn">NA</span>, <span class="dv">9</span>)</span>
<span id="cb105-1904"><a href="#cb105-1904" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">is.na</span>(x))</span>
<span id="cb105-1905"><a href="#cb105-1905" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">is.na</span>(x))</span>
<span id="cb105-1906"><a href="#cb105-1906" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb105-1907"><a href="#cb105-1907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1908"><a href="#cb105-1908" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb105-1909"><a href="#cb105-1909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1910"><a href="#cb105-1910" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary of Part B</span></span>
<span id="cb105-1911"><a href="#cb105-1911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-1912"><a href="#cb105-1912" aria-hidden="true" tabindex="-1"></a>In Part B, we addressed practical challenges in collecting and preparing data for small-sample studies. Chapter 9 covered sampling strategies (probability, stratified, purposive, quota sampling) and power analyses to understand detectability given sample size constraints. Chapter 10 discussed measurement quality and scale development, including item analysis, cognitive interviews, and reliability assessment with short scales. Chapter 11 presented data screening and diagnostic checks (outlier detection, normality assessment, regression diagnostics) to identify problems before analysis. Chapter 12 addressed missing data patterns, simple and advanced imputation methods, and the importance of transparency and prevention. Each chapter included learning objectives, method descriptions, runnable R examples, interpretations, key takeaways, and smoke tests. All code uses only approved packages and runs cleanly in a fresh R session. The guidance emphasises transparency, caution, and appropriate method selection given small-sample constraints.</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>